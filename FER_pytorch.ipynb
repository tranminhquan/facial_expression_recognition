{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zipfile import ZipFile\n",
    "from PIL import Image\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "from skimage.io import imread\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import transforms, datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transform = transforms.Compose([\n",
    "        transforms.Grayscale(num_output_channels=1),\n",
    "        # transforms.RandomSizedCrop(224),\n",
    "#         transforms.RandomHorizontalFlip(),\n",
    "#         transforms.RandomVerticalFlip(),\n",
    "#         transforms.RandomRotation(degrees=180),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,), (0.5,))\n",
    "    ])\n",
    "\n",
    "train_fer = datasets.ImageFolder(root='/tf/data/Quan/fer2013/data/train', transform=data_transform)\n",
    "val_fer = datasets.ImageFolder(root='/tf/data/Quan/fer2013/data/val', transform=data_transform)\n",
    "test_fer = datasets.ImageFolder(root='/tf/data/Quan/fer2013/data/test', transform=data_transform)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_fer,\n",
    "                                             batch_size=128, shuffle=True,\n",
    "                                             num_workers=8)\n",
    "val_loader = torch.utils.data.DataLoader(val_fer,\n",
    "                                             batch_size=128, shuffle=True,\n",
    "                                             num_workers=8)\n",
    "test_loader = torch.utils.data.DataLoader(test_fer,\n",
    "                                             batch_size=128, shuffle=True,\n",
    "                                             num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SVblock(nn.Module):\n",
    "    def __init__(self, in_neurons, nb_neurons, kernel_size=(3,3), batch_norm=True, activation='relu', **kwargs):\n",
    "        '''\n",
    "        in_neurons: C_in\n",
    "        nb_neurons: n_filters of conv2d\n",
    "        '''\n",
    "        super(SVblock, self).__init__()\n",
    "\n",
    "        self.index = kwargs['index'] if 'index' in kwargs else None\n",
    "        self.in_neurons = in_neurons\n",
    "        self.nb_neurons = nb_neurons\n",
    "        self.conv1 = nn.Conv2d(self.in_neurons, self.nb_neurons, kernel_size=kernel_size, padding=1, stride=1)\n",
    "        self.conv2 = nn.Conv2d(self.nb_neurons, self.nb_neurons, kernel_size=kernel_size, padding=1, stride=1)\n",
    "        self.batchnorm1 = nn.BatchNorm2d(nb_neurons)\n",
    "        self.batchnorm2 = nn.BatchNorm2d(nb_neurons)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=(2,2), stride=2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        '''\n",
    "        x: single output layer of list \n",
    "        '''\n",
    "\n",
    "        x = torch.cat(x, dim=1) if type(x) is list else x\n",
    "        # print('x in svblock: ', x.is_cuda)\n",
    "\n",
    "        x = x.to(device)\n",
    "\n",
    "        # 1st\n",
    "        x = self.conv1(x)\n",
    "        x = self.batchnorm1(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.batchnorm2(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "\n",
    "        # #2nd\n",
    "        # x = self.conv2(x)\n",
    "        # x = self.batchnorm(x)\n",
    "        # x = self.relu(x)\n",
    "\n",
    "        # x = self.conv2(x)\n",
    "        # x = self.batchnorm(x)\n",
    "        # x = self.relu(x)\n",
    "\n",
    "        # maxpooling\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DownSampling(nn.Module):\n",
    "    def __init__(self, in_size, out_size):\n",
    "        '''\n",
    "        in_size: input size (H_in x W_in)\n",
    "        out_size: output size (H_out x W_out)\n",
    "        '''\n",
    "\n",
    "        super(DownSampling, self).__init__()\n",
    "\n",
    "        self.in_size = in_size\n",
    "        self.out_size = out_size\n",
    "\n",
    "        h_crop = (in_size[0] - out_size[0])\n",
    "        w_crop = (in_size[1] - out_size[1])\n",
    "\n",
    "        self.h_top = h_crop // 2\n",
    "        self.h_bottom = h_crop // 2 if not h_crop % 2 else (h_crop // 2) + 1\n",
    "\n",
    "        self.w_left = w_crop // 2\n",
    "        self.w_right = w_crop // 2 if not w_crop % 2 else (w_crop // 2) + 1\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return x[:,:, self.h_top : (x.size(-2) - self.h_bottom) , self.w_left : (x.size(-1) - self.w_right)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DownIncreaseDepth(nn.Module):\n",
    "    def __init__(self, out_size, in_depth, out_depth):\n",
    "        super(DownIncreaseDepth, self).__init__()\n",
    "        \n",
    "        self.out_size = out_size\n",
    "        self.in_depth = in_depth\n",
    "        self.out_depth = out_depth\n",
    "        \n",
    "        self.iconv = nn.Conv2d(self.in_depth, self.out_depth, kernel_size=1, padding=0, stride=1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.batchnorm = nn.BatchNorm2d(self.out_depth)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.interpolate(x, self.out_size)\n",
    "        x = self.iconv(x)\n",
    "        x = self.relu(x)\n",
    "        x - self.batchnorm(x)\n",
    "        \n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 256, 16, 16])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer = DownIncreaseDepth((16,16), 64, 256)\n",
    "\n",
    "t = layer(torch.rand(64, 64, 48, 48))\n",
    "t.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[5.2505e-01, 6.9117e-02, 9.4545e-01,  ..., 3.7437e-01,\n",
       "           5.6068e-01, 9.7229e-01],\n",
       "          [2.4384e-01, 5.8731e-01, 5.8246e-01,  ..., 4.4137e-02,\n",
       "           7.4270e-01, 9.9532e-02],\n",
       "          [3.5889e-01, 3.5253e-01, 8.9325e-01,  ..., 9.6012e-01,\n",
       "           5.2550e-01, 8.3826e-01],\n",
       "          ...,\n",
       "          [7.0460e-01, 2.0373e-01, 6.7805e-01,  ..., 1.4819e-01,\n",
       "           5.8890e-01, 4.7762e-01],\n",
       "          [2.7905e-01, 4.6535e-01, 7.3626e-01,  ..., 3.2057e-02,\n",
       "           9.8646e-01, 8.6765e-01],\n",
       "          [6.9949e-01, 6.7878e-02, 5.8984e-02,  ..., 8.1515e-01,\n",
       "           7.1082e-01, 8.0648e-01]],\n",
       "\n",
       "         [[9.2451e-01, 3.5965e-01, 6.4952e-01,  ..., 6.2631e-01,\n",
       "           5.3915e-02, 1.9383e-01],\n",
       "          [3.1127e-01, 6.3249e-01, 9.4133e-01,  ..., 2.6083e-01,\n",
       "           3.7129e-01, 2.4450e-01],\n",
       "          [5.1830e-01, 3.5714e-01, 1.2137e-01,  ..., 8.1343e-01,\n",
       "           2.4743e-01, 5.7108e-01],\n",
       "          ...,\n",
       "          [9.9282e-01, 5.7083e-02, 7.5685e-01,  ..., 8.4810e-02,\n",
       "           5.3737e-01, 7.4464e-01],\n",
       "          [4.9113e-01, 3.4715e-01, 5.0287e-01,  ..., 4.2030e-01,\n",
       "           5.5111e-01, 4.3211e-01],\n",
       "          [3.3552e-01, 5.9536e-01, 4.6600e-01,  ..., 9.2166e-01,\n",
       "           9.8406e-01, 8.2591e-01]],\n",
       "\n",
       "         [[8.8771e-01, 3.2618e-02, 5.8685e-03,  ..., 5.0628e-01,\n",
       "           6.4407e-01, 4.8567e-01],\n",
       "          [7.4004e-01, 5.7660e-01, 4.4381e-01,  ..., 1.5055e-01,\n",
       "           8.1604e-01, 6.6482e-01],\n",
       "          [9.0888e-01, 9.2094e-02, 2.8920e-01,  ..., 1.6429e-01,\n",
       "           9.6336e-01, 8.2010e-01],\n",
       "          ...,\n",
       "          [1.4433e-01, 9.4779e-01, 2.2026e-01,  ..., 5.9067e-01,\n",
       "           1.0416e-01, 2.6418e-01],\n",
       "          [9.9699e-01, 7.7653e-01, 5.5344e-01,  ..., 5.0299e-01,\n",
       "           1.2191e-01, 5.6031e-01],\n",
       "          [4.7377e-02, 2.8082e-01, 9.8305e-01,  ..., 8.1210e-01,\n",
       "           3.1898e-02, 3.3443e-01]]],\n",
       "\n",
       "\n",
       "        [[[2.1126e-01, 8.1767e-01, 1.4858e-01,  ..., 9.7321e-01,\n",
       "           3.0021e-01, 1.4430e-02],\n",
       "          [2.3664e-01, 9.1996e-02, 6.2027e-01,  ..., 3.8318e-01,\n",
       "           4.1640e-02, 7.2478e-01],\n",
       "          [4.3524e-01, 4.0708e-02, 7.6763e-01,  ..., 8.8396e-01,\n",
       "           7.5413e-01, 3.7344e-01],\n",
       "          ...,\n",
       "          [7.8312e-01, 5.1194e-03, 8.2108e-01,  ..., 8.6803e-01,\n",
       "           5.5271e-01, 5.0211e-01],\n",
       "          [4.6578e-01, 5.3734e-01, 4.4985e-01,  ..., 2.8815e-01,\n",
       "           6.5882e-01, 9.6357e-01],\n",
       "          [6.1998e-01, 5.3105e-01, 9.1535e-01,  ..., 4.7841e-01,\n",
       "           8.8117e-01, 2.1806e-01]],\n",
       "\n",
       "         [[8.6549e-01, 7.0144e-01, 2.4032e-01,  ..., 9.0019e-01,\n",
       "           8.4697e-01, 4.2942e-01],\n",
       "          [2.1781e-01, 8.3405e-01, 5.4021e-01,  ..., 9.5558e-01,\n",
       "           6.9079e-01, 8.3276e-01],\n",
       "          [5.2394e-01, 6.4452e-01, 8.7178e-01,  ..., 9.3018e-01,\n",
       "           2.0551e-02, 4.0205e-02],\n",
       "          ...,\n",
       "          [2.1380e-02, 3.2660e-01, 1.1021e-01,  ..., 7.8088e-01,\n",
       "           2.5695e-01, 8.0696e-02],\n",
       "          [6.8306e-01, 3.7340e-01, 4.2926e-02,  ..., 5.7201e-01,\n",
       "           3.9556e-01, 3.0347e-02],\n",
       "          [4.7869e-01, 8.0257e-01, 4.0751e-01,  ..., 8.9093e-02,\n",
       "           3.9835e-01, 2.0638e-01]],\n",
       "\n",
       "         [[5.7934e-01, 1.3803e-01, 5.6285e-01,  ..., 1.3835e-01,\n",
       "           7.8146e-01, 9.6696e-01],\n",
       "          [5.3013e-01, 7.1800e-02, 7.6062e-02,  ..., 1.1810e-01,\n",
       "           9.4611e-01, 6.3111e-01],\n",
       "          [2.4838e-03, 3.1858e-02, 7.4316e-01,  ..., 1.5059e-01,\n",
       "           7.6802e-01, 2.5393e-01],\n",
       "          ...,\n",
       "          [7.7253e-01, 9.4674e-01, 6.3152e-01,  ..., 6.6991e-02,\n",
       "           8.9165e-01, 8.3431e-02],\n",
       "          [9.8158e-01, 5.8033e-01, 3.0775e-01,  ..., 7.9209e-01,\n",
       "           9.6506e-02, 8.8758e-01],\n",
       "          [7.8433e-01, 6.4931e-01, 8.6273e-01,  ..., 8.7268e-01,\n",
       "           5.9498e-01, 5.3725e-01]]],\n",
       "\n",
       "\n",
       "        [[[1.0511e-01, 5.4086e-02, 9.3346e-01,  ..., 7.5554e-01,\n",
       "           3.5614e-01, 8.7280e-01],\n",
       "          [9.1712e-01, 3.9101e-01, 9.6100e-01,  ..., 8.6895e-01,\n",
       "           8.6730e-01, 8.4826e-01],\n",
       "          [2.4767e-01, 8.8796e-01, 7.9812e-01,  ..., 4.8235e-01,\n",
       "           2.4244e-01, 1.4050e-01],\n",
       "          ...,\n",
       "          [9.3523e-02, 4.6186e-01, 3.4590e-01,  ..., 2.0343e-01,\n",
       "           3.3288e-02, 8.6140e-01],\n",
       "          [7.7675e-01, 6.5511e-01, 5.7429e-01,  ..., 9.4338e-01,\n",
       "           5.0458e-01, 2.8617e-01],\n",
       "          [4.6500e-01, 6.0251e-01, 2.6631e-01,  ..., 5.3719e-01,\n",
       "           2.4507e-01, 6.9781e-01]],\n",
       "\n",
       "         [[1.1870e-01, 3.6073e-01, 8.1392e-01,  ..., 1.2012e-01,\n",
       "           6.7324e-01, 9.1704e-01],\n",
       "          [2.5354e-01, 5.2951e-02, 5.0862e-01,  ..., 3.7927e-01,\n",
       "           7.9828e-01, 9.4208e-02],\n",
       "          [1.7871e-01, 5.5897e-01, 8.6652e-01,  ..., 2.4872e-01,\n",
       "           6.9326e-01, 3.4605e-01],\n",
       "          ...,\n",
       "          [7.6443e-02, 1.0815e-02, 8.0734e-01,  ..., 3.3523e-01,\n",
       "           7.1314e-01, 1.8242e-01],\n",
       "          [1.5615e-01, 2.9260e-01, 8.7457e-01,  ..., 9.5683e-01,\n",
       "           3.1847e-01, 6.8903e-01],\n",
       "          [9.4065e-01, 3.5086e-01, 1.5713e-01,  ..., 7.5888e-01,\n",
       "           9.4740e-01, 4.4971e-01]],\n",
       "\n",
       "         [[9.7727e-01, 2.4210e-02, 2.4385e-01,  ..., 7.2611e-01,\n",
       "           3.7415e-01, 5.9808e-01],\n",
       "          [2.8176e-01, 7.1673e-01, 2.3828e-01,  ..., 4.3122e-01,\n",
       "           4.8314e-01, 4.7195e-02],\n",
       "          [6.2274e-01, 1.5968e-01, 9.7042e-02,  ..., 6.0805e-01,\n",
       "           8.6628e-01, 9.5223e-01],\n",
       "          ...,\n",
       "          [4.8870e-01, 5.8259e-01, 7.6916e-01,  ..., 5.5301e-01,\n",
       "           4.5996e-01, 3.4096e-01],\n",
       "          [9.3281e-01, 9.3716e-01, 1.7853e-01,  ..., 9.9620e-01,\n",
       "           1.0899e-01, 5.1114e-01],\n",
       "          [1.0762e-01, 5.5326e-01, 1.9404e-02,  ..., 7.9904e-02,\n",
       "           4.5827e-01, 6.0561e-01]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[1.6514e-01, 2.5272e-01, 4.1411e-01,  ..., 6.5132e-01,\n",
       "           6.4625e-01, 7.3649e-01],\n",
       "          [1.9860e-02, 8.9391e-01, 7.1829e-01,  ..., 6.9220e-01,\n",
       "           5.3079e-02, 2.0992e-01],\n",
       "          [8.9434e-01, 6.5033e-01, 5.1484e-01,  ..., 3.5342e-01,\n",
       "           4.8046e-01, 1.8536e-01],\n",
       "          ...,\n",
       "          [1.6990e-01, 4.3007e-01, 4.0016e-01,  ..., 2.2408e-01,\n",
       "           8.1705e-01, 5.3534e-01],\n",
       "          [4.6785e-01, 8.6537e-01, 2.8713e-01,  ..., 5.6321e-01,\n",
       "           9.2628e-01, 3.0221e-01],\n",
       "          [7.9556e-01, 1.2691e-01, 2.2287e-02,  ..., 6.1058e-03,\n",
       "           3.4096e-01, 1.4957e-01]],\n",
       "\n",
       "         [[3.1888e-01, 4.0402e-02, 6.1992e-02,  ..., 1.8159e-01,\n",
       "           3.8404e-01, 1.7422e-01],\n",
       "          [1.5010e-01, 8.1573e-01, 5.8395e-02,  ..., 4.7389e-01,\n",
       "           6.4267e-01, 6.0330e-01],\n",
       "          [6.0852e-02, 7.1225e-01, 9.8989e-01,  ..., 7.6623e-01,\n",
       "           1.0393e-01, 8.8173e-01],\n",
       "          ...,\n",
       "          [8.9019e-01, 1.7221e-01, 6.8341e-02,  ..., 7.2671e-01,\n",
       "           8.0720e-01, 4.4695e-01],\n",
       "          [9.7403e-01, 5.5483e-01, 2.7505e-01,  ..., 9.7991e-01,\n",
       "           9.6679e-01, 1.5001e-01],\n",
       "          [1.1325e-01, 3.7977e-01, 8.8031e-01,  ..., 7.2538e-01,\n",
       "           3.0057e-01, 2.7931e-01]],\n",
       "\n",
       "         [[4.8484e-01, 4.1193e-01, 4.3951e-01,  ..., 7.3454e-01,\n",
       "           3.8776e-01, 1.1056e-01],\n",
       "          [7.7287e-01, 3.6299e-01, 8.6545e-01,  ..., 1.9916e-01,\n",
       "           1.7705e-01, 5.6120e-01],\n",
       "          [8.1341e-01, 8.6575e-01, 8.5046e-01,  ..., 2.6923e-01,\n",
       "           1.6092e-01, 9.5765e-01],\n",
       "          ...,\n",
       "          [8.9188e-01, 9.6243e-01, 3.0037e-01,  ..., 7.2444e-01,\n",
       "           8.9780e-01, 3.8186e-01],\n",
       "          [3.5638e-01, 5.6134e-01, 1.0439e-01,  ..., 9.9199e-01,\n",
       "           7.7905e-01, 3.7292e-01],\n",
       "          [1.0399e-01, 6.6173e-01, 3.6642e-01,  ..., 3.3710e-01,\n",
       "           8.8725e-01, 3.4243e-02]]],\n",
       "\n",
       "\n",
       "        [[[3.7116e-02, 2.1899e-01, 1.4250e-01,  ..., 2.9030e-01,\n",
       "           6.7177e-01, 9.4996e-01],\n",
       "          [9.2921e-01, 8.2266e-01, 4.7589e-01,  ..., 7.3961e-01,\n",
       "           1.7908e-01, 1.7933e-02],\n",
       "          [9.4283e-01, 4.9746e-01, 7.6217e-01,  ..., 4.5515e-02,\n",
       "           8.3969e-01, 1.4233e-01],\n",
       "          ...,\n",
       "          [4.8186e-01, 3.6650e-01, 7.7759e-01,  ..., 1.4404e-02,\n",
       "           9.4359e-02, 7.3024e-01],\n",
       "          [7.5986e-01, 8.7064e-01, 4.0436e-01,  ..., 7.9720e-01,\n",
       "           9.0212e-01, 1.1680e-02],\n",
       "          [3.1179e-02, 3.2103e-01, 6.2028e-01,  ..., 4.9888e-01,\n",
       "           4.1905e-01, 8.7887e-01]],\n",
       "\n",
       "         [[3.0131e-01, 7.5279e-01, 4.6608e-01,  ..., 6.3314e-01,\n",
       "           6.4611e-01, 7.6008e-01],\n",
       "          [6.6412e-01, 2.4074e-04, 5.6724e-01,  ..., 6.6940e-01,\n",
       "           9.6948e-01, 4.4375e-01],\n",
       "          [8.5928e-01, 2.1956e-01, 1.5793e-01,  ..., 3.2499e-01,\n",
       "           3.2265e-01, 7.0733e-01],\n",
       "          ...,\n",
       "          [4.5847e-01, 8.2353e-01, 1.6927e-01,  ..., 5.5739e-02,\n",
       "           6.1007e-01, 2.4780e-01],\n",
       "          [8.3094e-01, 7.2072e-01, 8.8246e-01,  ..., 6.8668e-01,\n",
       "           8.4305e-01, 2.7943e-01],\n",
       "          [2.6930e-01, 5.5869e-01, 7.0331e-01,  ..., 2.3697e-01,\n",
       "           1.1822e-01, 7.5542e-01]],\n",
       "\n",
       "         [[8.4402e-01, 7.7431e-01, 8.4865e-01,  ..., 8.3498e-01,\n",
       "           2.0290e-01, 6.3805e-01],\n",
       "          [7.9715e-01, 1.8721e-01, 4.5279e-02,  ..., 1.4216e-01,\n",
       "           1.9370e-01, 9.3792e-01],\n",
       "          [2.0959e-01, 1.3511e-01, 9.5904e-01,  ..., 4.9528e-01,\n",
       "           7.3309e-01, 1.7724e-01],\n",
       "          ...,\n",
       "          [6.4026e-01, 2.6017e-02, 8.2277e-01,  ..., 4.0279e-01,\n",
       "           6.6295e-01, 4.7122e-01],\n",
       "          [1.2475e-01, 6.3718e-01, 9.2334e-01,  ..., 7.5069e-01,\n",
       "           3.9843e-01, 9.8362e-01],\n",
       "          [2.0441e-01, 7.8237e-01, 7.6179e-01,  ..., 2.9158e-01,\n",
       "           2.9795e-01, 1.5314e-01]]],\n",
       "\n",
       "\n",
       "        [[[2.1697e-01, 2.5919e-01, 7.6270e-01,  ..., 3.1649e-01,\n",
       "           1.7165e-01, 3.4895e-01],\n",
       "          [1.4130e-01, 6.2604e-02, 7.5561e-01,  ..., 9.3511e-01,\n",
       "           1.7393e-01, 6.9183e-01],\n",
       "          [2.0040e-03, 8.7164e-01, 7.9871e-01,  ..., 9.9360e-01,\n",
       "           8.1968e-01, 6.3783e-01],\n",
       "          ...,\n",
       "          [2.2155e-01, 6.0516e-01, 6.3074e-01,  ..., 8.3909e-01,\n",
       "           6.9115e-01, 1.7672e-01],\n",
       "          [9.9128e-01, 7.5199e-01, 7.6505e-01,  ..., 6.9635e-01,\n",
       "           2.1111e-01, 6.0620e-01],\n",
       "          [4.2260e-01, 5.7474e-01, 3.8698e-01,  ..., 3.8613e-01,\n",
       "           8.7634e-01, 3.7680e-01]],\n",
       "\n",
       "         [[3.1048e-01, 5.1405e-01, 7.1351e-01,  ..., 1.6619e-01,\n",
       "           1.7251e-01, 4.8713e-01],\n",
       "          [4.0227e-01, 7.4328e-01, 2.7230e-01,  ..., 9.3619e-01,\n",
       "           7.8683e-01, 3.2526e-01],\n",
       "          [7.5359e-01, 1.1551e-01, 2.1819e-01,  ..., 3.2114e-01,\n",
       "           7.0084e-01, 1.5537e-02],\n",
       "          ...,\n",
       "          [6.3164e-02, 5.9077e-01, 3.7274e-01,  ..., 9.5861e-01,\n",
       "           6.0702e-01, 8.2881e-01],\n",
       "          [5.6586e-02, 6.7011e-01, 4.8762e-01,  ..., 5.3439e-01,\n",
       "           2.3064e-01, 3.3089e-01],\n",
       "          [3.7663e-01, 8.2829e-01, 3.0624e-01,  ..., 6.9617e-01,\n",
       "           6.0937e-01, 3.4235e-01]],\n",
       "\n",
       "         [[7.1155e-01, 2.4057e-01, 5.7026e-01,  ..., 5.6190e-01,\n",
       "           7.9884e-01, 3.1148e-01],\n",
       "          [4.8081e-01, 7.7881e-01, 5.1233e-02,  ..., 7.5417e-01,\n",
       "           4.8231e-01, 5.9813e-01],\n",
       "          [6.0177e-01, 7.5882e-01, 2.7850e-01,  ..., 1.8477e-01,\n",
       "           3.1630e-02, 6.3207e-01],\n",
       "          ...,\n",
       "          [5.8515e-01, 4.8345e-01, 1.4983e-01,  ..., 6.7458e-01,\n",
       "           2.9378e-01, 9.3518e-01],\n",
       "          [5.8657e-01, 1.0070e-01, 7.1454e-01,  ..., 7.8775e-01,\n",
       "           2.5985e-01, 9.2503e-01],\n",
       "          [4.1777e-01, 4.8108e-01, 6.4698e-01,  ..., 2.2216e-01,\n",
       "           5.2966e-01, 6.2566e-01]]]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.interpolate(torch.rand(100, 3, 48,48), (24,24))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SkippedVGG(nn.Module):\n",
    "    def __init__(self, in_size, nb_blocks, n_classes, **kwargs):\n",
    "        '''\n",
    "        in_size (without batch size): (C, H, W)\n",
    "\n",
    "        '''\n",
    "        super(SkippedVGG, self).__init__()\n",
    "\n",
    "        # init power of filters\n",
    "        init_pf = kwargs['init_pf'] if 'init_pf' in kwargs else 6\n",
    "        self.device = torch.device('cpu') if not 'device' in kwargs else kwargs['device']\n",
    "\n",
    "        self.nb_blocks = nb_blocks\n",
    "        self.n_classes = n_classes\n",
    "\n",
    "        self.ln = nn.Linear(1920, 512)\n",
    "        self.batchnorm = nn.BatchNorm1d(512)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.ln2 = nn.Linear(512, self.n_classes)\n",
    "        self.batchnorm2 = nn.BatchNorm1d(7)\n",
    "\n",
    "        self.init_conv = nn.Conv2d(in_size[0], 64, kernel_size=(3,3), padding=1, stride=1)\n",
    "        self.sv_blocks = []\n",
    "\n",
    "        # init crop layers\n",
    "        self.crop_layers = []\n",
    "        for i in range(self.nb_blocks):\n",
    "            self.crop_layers.append([])\n",
    "\n",
    "        cur_size = (in_size[1], in_size[2])\n",
    "\n",
    "        out_last_block = 0\n",
    "        for i in range(self.nb_blocks):\n",
    "            if i == 0:\n",
    "                self.sv_blocks.append(SVblock(in_size[0], 2**(init_pf)).to(self.device))\n",
    "                out_last_block += 2**(init_pf)\n",
    "            \n",
    "            else:\n",
    "                # self.sv_blocks.append(SVblock(2**(init_pf+i-1), 2**(init_pf+i)))\n",
    "                self.sv_blocks.append(SVblock(out_last_block, 2**(init_pf+i)).to(self.device))\n",
    "                out_last_block += 2**(init_pf+i)\n",
    "        \n",
    "            out_block_size = (cur_size[0] // 2, cur_size[1] // 2)\n",
    "            \n",
    "            for k, j in enumerate(range(i+1, self.nb_blocks)):\n",
    "                target_size = (out_block_size[0] // (2**(k+1)), out_block_size[1] // (2**(k+1)))\n",
    "\n",
    "                crop_layer = DownSampling(out_block_size, target_size).to(self.device)\n",
    "#                 crop_layer = DownIncreaseDepth(target_size, 2**(init_pf+i), out_last_block + (2**(init_pf+k))).to(self.device)\n",
    "\n",
    "                self.crop_layers[j].append(crop_layer.to(self.device))\n",
    "                \n",
    "            cur_size = out_block_size\n",
    "  \n",
    "    def forward(self, x):\n",
    "        outs = []\n",
    "        for i in range(self.nb_blocks):\n",
    "            \n",
    "            _crops = self.crop_layers[i-1] if i >=1 else []\n",
    "            \n",
    "            for j, clayer in enumerate(_crops):\n",
    "                # print(clayer(x).size())\n",
    "                x = torch.cat((x, clayer(outs[j])), dim=1)\n",
    "\n",
    "            x = self.sv_blocks[i](x)\n",
    "            outs.append(x)\n",
    "\n",
    "        _crops = self.crop_layers[-1]\n",
    "        for j, clayer in enumerate(_crops):\n",
    "            # print(j)\n",
    "            # print(x.size())\n",
    "            # print(outs[j].size())\n",
    "            # print(clayer)\n",
    "            x = torch.cat((x, clayer(outs[j])), dim=1)\n",
    "\n",
    "        x = nn.AvgPool2d(kernel_size=(x.size(-2), x.size(-1)))(x)\n",
    "        x = nn.Flatten()(x)\n",
    "#         print(x.size())\n",
    "        x = self.ln(x)\n",
    "        x = self.batchnorm(x)\n",
    "        # x = self.relu(x)\n",
    "        x = self.ln2(x)\n",
    "        x = self.batchnorm2(x)\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SkippedVGG(nn.Module):\n",
    "    def __init__(self, in_size, nb_blocks, n_classes, **kwargs):\n",
    "        '''\n",
    "        in_size (without batch size): (C, H, W)\n",
    "\n",
    "        '''\n",
    "        super(SkippedVGG, self).__init__()\n",
    "\n",
    "        # init power of filters\n",
    "        init_pf = kwargs['init_pf'] if 'init_pf' in kwargs else 6\n",
    "        self.device = torch.device('cpu') if not 'device' in kwargs else kwargs['device']\n",
    "\n",
    "        self.nb_blocks = nb_blocks\n",
    "        self.n_classes = n_classes\n",
    "\n",
    "        self.ln = nn.Linear(1920, 512)\n",
    "        self.batchnorm = nn.BatchNorm1d(512)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.ln2 = nn.Linear(512, self.n_classes)\n",
    "        self.batchnorm2 = nn.BatchNorm1d(7)\n",
    "\n",
    "        self.init_conv = nn.Conv2d(in_size[0], 64, kernel_size=(3,3), padding=1, stride=1)\n",
    "        self.sv_blocks = []\n",
    "\n",
    "        # init crop layers\n",
    "        self.crop_layers = []\n",
    "        for i in range(self.nb_blocks):\n",
    "            self.crop_layers.append([])\n",
    "\n",
    "        \n",
    "\n",
    "        out_last_block = 0\n",
    "        for i in range(self.nb_blocks):\n",
    "            if i == 0:\n",
    "                self.sv_blocks.append(SVblock(in_size[0], 2**(init_pf)).to(self.device))\n",
    "                out_last_block += 2**(init_pf)\n",
    "            \n",
    "            else:\n",
    "                # self.sv_blocks.append(SVblock(2**(init_pf+i-1), 2**(init_pf+i)))\n",
    "                self.sv_blocks.append(SVblock(out_last_block, 2**(init_pf+i)).to(self.device))\n",
    "                out_last_block += 2**(init_pf+i)\n",
    "                \n",
    "        \n",
    "        cur_size = (in_size[1], in_size[2])\n",
    "        \n",
    "        for i in range(self.nb_blocks):\n",
    "            out_block_size = (cur_size[0] // 2, cur_size[1] // 2)\n",
    "            \n",
    "            for k, j in enumerate(range(i, self.nb_blocks)):\n",
    "                target_size = (out_block_size[0] // (2**(k+1)), out_block_size[1] // (2**(k+1)))\n",
    "                \n",
    "                crop_layer = DownIncreaseDepth(target_size, self.sv_blocks[i+1].nb_neurons, self.sv_blocks[j].in_neurons).to(self.device)\n",
    "                \n",
    "                print('Block ', i+1, ': ', self.sv_blocks[i].nb_neurons, ' -- ', self.sv_blocks[j].in_neurons, ' down to block ', j, ': ', target_size)\n",
    "\n",
    "                self.crop_layers[j].append(crop_layer.to(self.device))\n",
    "                \n",
    "            cur_size = out_block_size\n",
    "  \n",
    "    def forward(self, x):\n",
    "        outs = []\n",
    "        for i in range(self.nb_blocks):\n",
    "            \n",
    "            _crops = self.crop_layers[i-1] if i >=1 else []\n",
    "            \n",
    "            for j, clayer in enumerate(_crops):\n",
    "                # print(clayer(x).size())\n",
    "                x = torch.cat((x, clayer(outs[j])), dim=1)\n",
    "\n",
    "            x = self.sv_blocks[i](x)\n",
    "            outs.append(x)\n",
    "\n",
    "        _crops = self.crop_layers[-1]\n",
    "        for j, clayer in enumerate(_crops):\n",
    "            # print(j)\n",
    "            # print(x.size())\n",
    "            # print(outs[j].size())\n",
    "            # print(clayer)\n",
    "            x = torch.cat((x, clayer(outs[j])), dim=1)\n",
    "\n",
    "        x = nn.AvgPool2d(kernel_size=(x.size(-2), x.size(-1)))(x)\n",
    "        x = nn.Flatten()(x)\n",
    "#         print(x.size())\n",
    "        x = self.ln(x)\n",
    "        x = self.batchnorm(x)\n",
    "        # x = self.relu(x)\n",
    "        x = self.ln2(x)\n",
    "        x = self.batchnorm2(x)\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda')\n",
    "print(device)\n",
    "\n",
    "model = SkippedVGG(in_size=(1,48,48), nb_blocks=4, n_classes=7, init_pf=7, device=device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.008)\n",
    "\n",
    "# model.train()\n",
    "\n",
    "# model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SVblock(\n",
       "   (conv1): Conv2d(1, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "   (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "   (batchnorm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (relu): ReLU()\n",
       "   (maxpool): MaxPool2d(kernel_size=(2, 2), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       " ), SVblock(\n",
       "   (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "   (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "   (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (relu): ReLU()\n",
       "   (maxpool): MaxPool2d(kernel_size=(2, 2), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       " ), SVblock(\n",
       "   (conv1): Conv2d(384, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "   (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "   (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (relu): ReLU()\n",
       "   (maxpool): MaxPool2d(kernel_size=(2, 2), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       " ), SVblock(\n",
       "   (conv1): Conv2d(896, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "   (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "   (batchnorm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (relu): ReLU()\n",
       "   (maxpool): MaxPool2d(kernel_size=(2, 2), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       " )]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.sv_blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model(torch.rand(64,1,48,48).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1\n",
      "\t - Step 1: loss: 2.376 acc: 0.172\n",
      "\t - Step 2: loss: 2.098 acc: 0.188\n",
      "\t - Step 3: loss: 2.153 acc: 0.219\n",
      "\t - Step 4: loss: 2.368 acc: 0.133\n",
      "\t - Step 5: loss: 2.116 acc: 0.188\n",
      "\t - Step 6: loss: 2.220 acc: 0.234\n",
      "\t - Step 7: loss: 2.178 acc: 0.172\n",
      "\t - Step 8: loss: 2.000 acc: 0.234\n",
      "\t - Step 9: loss: 2.144 acc: 0.180\n",
      "\t - Step 10: loss: 2.051 acc: 0.211\n",
      "\t - Step 11: loss: 2.162 acc: 0.180\n",
      "\t - Step 12: loss: 2.109 acc: 0.219\n",
      "\t - Step 13: loss: 2.125 acc: 0.203\n",
      "\t - Step 14: loss: 1.958 acc: 0.297\n",
      "\t - Step 15: loss: 1.942 acc: 0.234\n",
      "\t - Step 16: loss: 2.112 acc: 0.188\n",
      "\t - Step 17: loss: 2.020 acc: 0.188\n",
      "\t - Step 18: loss: 1.933 acc: 0.211\n",
      "\t - Step 19: loss: 2.047 acc: 0.211\n",
      "\t - Step 20: loss: 1.840 acc: 0.297\n",
      "\t - Step 21: loss: 2.053 acc: 0.180\n",
      "\t - Step 22: loss: 1.957 acc: 0.258\n",
      "\t - Step 23: loss: 1.888 acc: 0.312\n",
      "\t - Step 24: loss: 1.828 acc: 0.289\n",
      "\t - Step 25: loss: 1.852 acc: 0.250\n",
      "\t - Step 26: loss: 1.893 acc: 0.273\n",
      "\t - Step 27: loss: 1.877 acc: 0.266\n",
      "\t - Step 28: loss: 1.856 acc: 0.266\n",
      "\t - Step 29: loss: 1.922 acc: 0.211\n",
      "\t - Step 30: loss: 1.853 acc: 0.242\n",
      "\t - Step 31: loss: 1.880 acc: 0.258\n",
      "\t - Step 32: loss: 1.842 acc: 0.305\n",
      "\t - Step 33: loss: 1.792 acc: 0.336\n",
      "\t - Step 34: loss: 1.869 acc: 0.266\n",
      "\t - Step 35: loss: 1.859 acc: 0.258\n",
      "\t - Step 36: loss: 1.849 acc: 0.266\n",
      "\t - Step 37: loss: 1.831 acc: 0.312\n",
      "\t - Step 38: loss: 1.878 acc: 0.227\n",
      "\t - Step 39: loss: 1.878 acc: 0.234\n",
      "\t - Step 40: loss: 1.827 acc: 0.312\n",
      "\t - Step 41: loss: 1.872 acc: 0.219\n",
      "\t - Step 42: loss: 1.831 acc: 0.250\n",
      "\t - Step 43: loss: 1.867 acc: 0.227\n",
      "\t - Step 44: loss: 1.814 acc: 0.281\n",
      "\t - Step 45: loss: 1.819 acc: 0.344\n",
      "\t - Step 46: loss: 1.821 acc: 0.336\n",
      "\t - Step 47: loss: 1.833 acc: 0.305\n",
      "\t - Step 48: loss: 1.824 acc: 0.258\n",
      "\t - Step 49: loss: 1.806 acc: 0.273\n",
      "\t - Step 50: loss: 1.823 acc: 0.289\n",
      "\t - Step 51: loss: 1.813 acc: 0.289\n",
      "\t - Step 52: loss: 1.816 acc: 0.289\n",
      "\t - Step 53: loss: 1.854 acc: 0.258\n",
      "\t - Step 54: loss: 1.807 acc: 0.281\n",
      "\t - Step 55: loss: 1.801 acc: 0.289\n",
      "\t - Step 56: loss: 1.814 acc: 0.297\n",
      "\t - Step 57: loss: 1.744 acc: 0.359\n",
      "\t - Step 58: loss: 1.760 acc: 0.289\n",
      "\t - Step 59: loss: 1.771 acc: 0.250\n",
      "\t - Step 60: loss: 1.771 acc: 0.320\n",
      "\t - Step 61: loss: 1.741 acc: 0.328\n",
      "\t - Step 62: loss: 1.730 acc: 0.383\n",
      "\t - Step 63: loss: 1.802 acc: 0.289\n",
      "\t - Step 64: loss: 1.758 acc: 0.328\n",
      "\t - Step 65: loss: 1.807 acc: 0.242\n",
      "\t - Step 66: loss: 1.759 acc: 0.359\n",
      "\t - Step 67: loss: 1.743 acc: 0.336\n",
      "\t - Step 68: loss: 1.786 acc: 0.289\n",
      "\t - Step 69: loss: 1.772 acc: 0.312\n",
      "\t - Step 70: loss: 1.775 acc: 0.289\n",
      "\t - Step 71: loss: 1.822 acc: 0.273\n",
      "\t - Step 72: loss: 1.784 acc: 0.352\n",
      "\t - Step 73: loss: 1.786 acc: 0.242\n",
      "\t - Step 74: loss: 1.724 acc: 0.391\n",
      "\t - Step 75: loss: 1.741 acc: 0.289\n",
      "\t - Step 76: loss: 1.759 acc: 0.312\n",
      "\t - Step 77: loss: 1.800 acc: 0.266\n",
      "\t - Step 78: loss: 1.718 acc: 0.305\n",
      "\t - Step 79: loss: 1.775 acc: 0.281\n",
      "\t - Step 80: loss: 1.754 acc: 0.328\n",
      "\t - Step 81: loss: 1.689 acc: 0.383\n",
      "\t - Step 82: loss: 1.726 acc: 0.289\n",
      "\t - Step 83: loss: 1.736 acc: 0.289\n",
      "\t - Step 84: loss: 1.818 acc: 0.297\n",
      "\t - Step 85: loss: 1.664 acc: 0.359\n",
      "\t - Step 86: loss: 1.696 acc: 0.305\n",
      "\t - Step 87: loss: 1.689 acc: 0.344\n",
      "\t - Step 88: loss: 1.642 acc: 0.422\n",
      "\t - Step 89: loss: 1.656 acc: 0.359\n",
      "\t - Step 90: loss: 1.751 acc: 0.352\n",
      "\t - Step 91: loss: 1.757 acc: 0.305\n",
      "\t - Step 92: loss: 1.711 acc: 0.359\n",
      "\t - Step 93: loss: 1.626 acc: 0.352\n",
      "\t - Step 94: loss: 1.718 acc: 0.312\n",
      "\t - Step 95: loss: 1.689 acc: 0.391\n",
      "\t - Step 96: loss: 1.748 acc: 0.359\n",
      "\t - Step 97: loss: 1.711 acc: 0.266\n",
      "\t - Step 98: loss: 1.712 acc: 0.305\n",
      "\t - Step 99: loss: 1.730 acc: 0.320\n",
      "\t - Step 100: loss: 1.637 acc: 0.352\n",
      "\t - Step 101: loss: 1.644 acc: 0.430\n",
      "\t - Step 102: loss: 1.632 acc: 0.383\n",
      "\t - Step 103: loss: 1.668 acc: 0.352\n",
      "\t - Step 104: loss: 1.636 acc: 0.352\n",
      "\t - Step 105: loss: 1.743 acc: 0.250\n",
      "\t - Step 106: loss: 1.726 acc: 0.352\n",
      "\t - Step 107: loss: 1.593 acc: 0.383\n",
      "\t - Step 108: loss: 1.619 acc: 0.375\n",
      "\t - Step 109: loss: 1.642 acc: 0.398\n",
      "\t - Step 110: loss: 1.679 acc: 0.328\n",
      "\t - Step 111: loss: 1.530 acc: 0.453\n",
      "\t - Step 112: loss: 1.634 acc: 0.328\n",
      "\t - Step 113: loss: 1.607 acc: 0.406\n",
      "\t - Step 114: loss: 1.666 acc: 0.305\n",
      "\t - Step 115: loss: 1.682 acc: 0.328\n",
      "\t - Step 116: loss: 1.560 acc: 0.375\n",
      "\t - Step 117: loss: 1.623 acc: 0.414\n",
      "\t - Step 118: loss: 1.626 acc: 0.383\n",
      "\t - Step 119: loss: 1.791 acc: 0.289\n",
      "\t - Step 120: loss: 1.735 acc: 0.305\n",
      "\t - Step 121: loss: 1.599 acc: 0.391\n",
      "\t - Step 122: loss: 1.624 acc: 0.328\n",
      "\t - Step 123: loss: 1.566 acc: 0.414\n",
      "\t - Step 124: loss: 1.689 acc: 0.297\n",
      "\t - Step 125: loss: 1.567 acc: 0.406\n",
      "\t - Step 126: loss: 1.738 acc: 0.383\n",
      "\t - Step 127: loss: 1.613 acc: 0.305\n",
      "\t - Step 128: loss: 1.582 acc: 0.391\n",
      "\t - Step 129: loss: 1.647 acc: 0.367\n",
      "\t - Step 130: loss: 1.650 acc: 0.383\n",
      "\t - Step 131: loss: 1.660 acc: 0.352\n",
      "\t - Step 132: loss: 1.641 acc: 0.336\n",
      "\t - Step 133: loss: 1.638 acc: 0.406\n",
      "\t - Step 134: loss: 1.633 acc: 0.359\n",
      "\t - Step 135: loss: 1.671 acc: 0.406\n",
      "\t - Step 136: loss: 1.492 acc: 0.461\n",
      "\t - Step 137: loss: 1.653 acc: 0.305\n",
      "\t - Step 138: loss: 1.633 acc: 0.352\n",
      "\t - Step 139: loss: 1.628 acc: 0.406\n",
      "\t - Step 140: loss: 1.619 acc: 0.375\n",
      "\t - Step 141: loss: 1.670 acc: 0.391\n",
      "\t - Step 142: loss: 1.614 acc: 0.383\n",
      "\t - Step 143: loss: 1.599 acc: 0.375\n",
      "\t - Step 144: loss: 1.657 acc: 0.383\n",
      "\t - Step 145: loss: 1.670 acc: 0.422\n",
      "\t - Step 146: loss: 1.570 acc: 0.367\n",
      "\t - Step 147: loss: 1.677 acc: 0.336\n",
      "\t - Step 148: loss: 1.667 acc: 0.359\n",
      "\t - Step 149: loss: 1.615 acc: 0.391\n",
      "\t - Step 150: loss: 1.614 acc: 0.344\n",
      "\t - Step 151: loss: 1.546 acc: 0.422\n",
      "\t - Step 152: loss: 1.683 acc: 0.320\n",
      "\t - Step 153: loss: 1.659 acc: 0.375\n",
      "\t - Step 154: loss: 1.669 acc: 0.328\n",
      "\t - Step 155: loss: 1.636 acc: 0.344\n",
      "\t - Step 156: loss: 1.637 acc: 0.414\n",
      "\t - Step 157: loss: 1.578 acc: 0.398\n",
      "\t - Step 158: loss: 1.598 acc: 0.398\n",
      "\t - Step 159: loss: 1.558 acc: 0.367\n",
      "\t - Step 160: loss: 1.524 acc: 0.414\n",
      "\t - Step 161: loss: 1.643 acc: 0.352\n",
      "\t - Step 162: loss: 1.612 acc: 0.336\n",
      "\t - Step 163: loss: 1.489 acc: 0.461\n",
      "\t - Step 164: loss: 1.557 acc: 0.383\n",
      "\t - Step 165: loss: 1.578 acc: 0.422\n",
      "\t - Step 166: loss: 1.599 acc: 0.312\n",
      "\t - Step 167: loss: 1.545 acc: 0.414\n",
      "\t - Step 168: loss: 1.646 acc: 0.352\n",
      "\t - Step 169: loss: 1.544 acc: 0.391\n",
      "\t - Step 170: loss: 1.600 acc: 0.391\n",
      "\t - Step 171: loss: 1.588 acc: 0.383\n",
      "\t - Step 172: loss: 1.655 acc: 0.320\n",
      "\t - Step 173: loss: 1.614 acc: 0.391\n",
      "\t - Step 174: loss: 1.549 acc: 0.438\n",
      "\t - Step 175: loss: 1.586 acc: 0.359\n",
      "\t - Step 176: loss: 1.542 acc: 0.391\n",
      "\t - Step 177: loss: 1.609 acc: 0.383\n",
      "\t - Step 178: loss: 1.476 acc: 0.375\n",
      "\t - Step 179: loss: 1.571 acc: 0.422\n",
      "\t - Step 180: loss: 1.592 acc: 0.414\n",
      "\t - Step 181: loss: 1.599 acc: 0.398\n",
      "\t - Step 182: loss: 1.642 acc: 0.367\n",
      "\t - Step 183: loss: 1.576 acc: 0.430\n",
      "\t - Step 184: loss: 1.595 acc: 0.391\n",
      "\t - Step 185: loss: 1.594 acc: 0.375\n",
      "\t - Step 186: loss: 1.602 acc: 0.359\n",
      "\t - Step 187: loss: 1.528 acc: 0.414\n",
      "\t - Step 188: loss: 1.546 acc: 0.391\n",
      "\t - Step 189: loss: 1.641 acc: 0.359\n",
      "\t - Step 190: loss: 1.505 acc: 0.430\n",
      "\t - Step 191: loss: 1.620 acc: 0.375\n",
      "\t - Step 192: loss: 1.456 acc: 0.477\n",
      "\t - Step 193: loss: 1.561 acc: 0.367\n",
      "\t - Step 194: loss: 1.536 acc: 0.422\n",
      "\t - Step 195: loss: 1.681 acc: 0.312\n",
      "\t - Step 196: loss: 1.446 acc: 0.453\n",
      "\t - Step 197: loss: 1.585 acc: 0.383\n",
      "\t - Step 198: loss: 1.592 acc: 0.383\n",
      "\t - Step 199: loss: 1.535 acc: 0.430\n",
      "\t - Step 200: loss: 1.615 acc: 0.398\n",
      "\t - Step 201: loss: 1.555 acc: 0.430\n",
      "\t - Step 202: loss: 1.700 acc: 0.328\n",
      "\t - Step 203: loss: 1.617 acc: 0.352\n",
      "\t - Step 204: loss: 1.582 acc: 0.352\n",
      "\t - Step 205: loss: 1.485 acc: 0.414\n",
      "\t - Step 206: loss: 1.625 acc: 0.359\n",
      "\t - Step 207: loss: 1.616 acc: 0.422\n",
      "\t - Step 208: loss: 1.568 acc: 0.398\n",
      "\t - Step 209: loss: 1.516 acc: 0.422\n",
      "\t - Step 210: loss: 1.639 acc: 0.352\n",
      "\t - Step 211: loss: 1.523 acc: 0.422\n",
      "\t - Step 212: loss: 1.631 acc: 0.383\n",
      "\t - Step 213: loss: 1.615 acc: 0.406\n",
      "\t - Step 214: loss: 1.505 acc: 0.391\n",
      "\t - Step 215: loss: 1.541 acc: 0.453\n",
      "\t - Step 216: loss: 1.602 acc: 0.359\n",
      "\t - Step 217: loss: 1.498 acc: 0.406\n",
      "\t - Step 218: loss: 1.545 acc: 0.398\n",
      "\t - Step 219: loss: 1.589 acc: 0.414\n",
      "\t - Step 220: loss: 1.581 acc: 0.391\n",
      "\t - Step 221: loss: 1.546 acc: 0.484\n",
      "\t - Step 222: loss: 1.574 acc: 0.406\n",
      "\t - Step 223: loss: 1.572 acc: 0.359\n",
      "\t - Step 224: loss: 1.578 acc: 0.414\n",
      "\t - Step 225: loss: 1.570 acc: 0.432\n",
      "- Avg.loss: 1.714  | Avg.acc: 0.337\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Avg. val_loss: 1.856  | Avg. val_acc: 0.306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:360: UserWarning: Couldn't retrieve source code for container of type SkippedVGG. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:360: UserWarning: Couldn't retrieve source code for container of type SVblock. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:360: UserWarning: Couldn't retrieve source code for container of type DownSampling. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Update optimal model\n",
      "Epoch:  2\n",
      "\t - Step 1: loss: 1.555 acc: 0.352\n",
      "\t - Step 2: loss: 1.580 acc: 0.414\n",
      "\t - Step 3: loss: 1.521 acc: 0.383\n",
      "\t - Step 4: loss: 1.426 acc: 0.484\n",
      "\t - Step 5: loss: 1.508 acc: 0.391\n",
      "\t - Step 6: loss: 1.573 acc: 0.398\n",
      "\t - Step 7: loss: 1.521 acc: 0.406\n",
      "\t - Step 8: loss: 1.513 acc: 0.445\n",
      "\t - Step 9: loss: 1.596 acc: 0.391\n",
      "\t - Step 10: loss: 1.697 acc: 0.359\n",
      "\t - Step 11: loss: 1.486 acc: 0.359\n",
      "\t - Step 12: loss: 1.577 acc: 0.406\n",
      "\t - Step 13: loss: 1.592 acc: 0.398\n",
      "\t - Step 14: loss: 1.672 acc: 0.312\n",
      "\t - Step 15: loss: 1.584 acc: 0.367\n",
      "\t - Step 16: loss: 1.501 acc: 0.406\n",
      "\t - Step 17: loss: 1.498 acc: 0.406\n",
      "\t - Step 18: loss: 1.551 acc: 0.391\n",
      "\t - Step 19: loss: 1.523 acc: 0.414\n",
      "\t - Step 20: loss: 1.614 acc: 0.367\n",
      "\t - Step 21: loss: 1.583 acc: 0.422\n",
      "\t - Step 22: loss: 1.505 acc: 0.469\n",
      "\t - Step 23: loss: 1.524 acc: 0.406\n",
      "\t - Step 24: loss: 1.594 acc: 0.398\n",
      "\t - Step 25: loss: 1.468 acc: 0.414\n",
      "\t - Step 26: loss: 1.603 acc: 0.336\n",
      "\t - Step 27: loss: 1.515 acc: 0.438\n",
      "\t - Step 28: loss: 1.513 acc: 0.391\n",
      "\t - Step 29: loss: 1.579 acc: 0.430\n",
      "\t - Step 30: loss: 1.460 acc: 0.445\n",
      "\t - Step 31: loss: 1.576 acc: 0.406\n",
      "\t - Step 32: loss: 1.636 acc: 0.383\n",
      "\t - Step 33: loss: 1.679 acc: 0.305\n",
      "\t - Step 34: loss: 1.632 acc: 0.375\n",
      "\t - Step 35: loss: 1.524 acc: 0.453\n",
      "\t - Step 36: loss: 1.608 acc: 0.367\n",
      "\t - Step 37: loss: 1.560 acc: 0.398\n",
      "\t - Step 38: loss: 1.619 acc: 0.414\n",
      "\t - Step 39: loss: 1.551 acc: 0.344\n",
      "\t - Step 40: loss: 1.432 acc: 0.484\n",
      "\t - Step 41: loss: 1.567 acc: 0.406\n",
      "\t - Step 42: loss: 1.548 acc: 0.430\n",
      "\t - Step 43: loss: 1.601 acc: 0.391\n",
      "\t - Step 44: loss: 1.469 acc: 0.484\n",
      "\t - Step 45: loss: 1.510 acc: 0.453\n",
      "\t - Step 46: loss: 1.536 acc: 0.367\n",
      "\t - Step 47: loss: 1.562 acc: 0.398\n",
      "\t - Step 48: loss: 1.511 acc: 0.484\n",
      "\t - Step 49: loss: 1.569 acc: 0.438\n",
      "\t - Step 50: loss: 1.514 acc: 0.414\n",
      "\t - Step 51: loss: 1.546 acc: 0.414\n",
      "\t - Step 52: loss: 1.588 acc: 0.375\n",
      "\t - Step 53: loss: 1.501 acc: 0.406\n",
      "\t - Step 54: loss: 1.528 acc: 0.422\n",
      "\t - Step 55: loss: 1.461 acc: 0.445\n",
      "\t - Step 56: loss: 1.575 acc: 0.383\n",
      "\t - Step 57: loss: 1.575 acc: 0.336\n",
      "\t - Step 58: loss: 1.495 acc: 0.438\n",
      "\t - Step 59: loss: 1.537 acc: 0.352\n",
      "\t - Step 60: loss: 1.461 acc: 0.438\n",
      "\t - Step 61: loss: 1.421 acc: 0.430\n",
      "\t - Step 62: loss: 1.522 acc: 0.438\n",
      "\t - Step 63: loss: 1.596 acc: 0.430\n",
      "\t - Step 64: loss: 1.585 acc: 0.352\n",
      "\t - Step 65: loss: 1.518 acc: 0.406\n",
      "\t - Step 66: loss: 1.531 acc: 0.422\n",
      "\t - Step 67: loss: 1.527 acc: 0.492\n",
      "\t - Step 68: loss: 1.536 acc: 0.328\n",
      "\t - Step 69: loss: 1.443 acc: 0.430\n",
      "\t - Step 70: loss: 1.628 acc: 0.320\n",
      "\t - Step 71: loss: 1.525 acc: 0.336\n",
      "\t - Step 72: loss: 1.499 acc: 0.461\n",
      "\t - Step 73: loss: 1.553 acc: 0.359\n",
      "\t - Step 74: loss: 1.446 acc: 0.484\n",
      "\t - Step 75: loss: 1.491 acc: 0.453\n",
      "\t - Step 76: loss: 1.578 acc: 0.383\n",
      "\t - Step 77: loss: 1.418 acc: 0.422\n",
      "\t - Step 78: loss: 1.665 acc: 0.336\n",
      "\t - Step 79: loss: 1.511 acc: 0.438\n",
      "\t - Step 80: loss: 1.550 acc: 0.406\n",
      "\t - Step 81: loss: 1.603 acc: 0.383\n",
      "\t - Step 82: loss: 1.493 acc: 0.414\n",
      "\t - Step 83: loss: 1.583 acc: 0.359\n",
      "\t - Step 84: loss: 1.509 acc: 0.414\n",
      "\t - Step 85: loss: 1.587 acc: 0.359\n",
      "\t - Step 86: loss: 1.523 acc: 0.406\n",
      "\t - Step 87: loss: 1.476 acc: 0.453\n",
      "\t - Step 88: loss: 1.578 acc: 0.391\n",
      "\t - Step 89: loss: 1.636 acc: 0.359\n",
      "\t - Step 90: loss: 1.557 acc: 0.359\n",
      "\t - Step 91: loss: 1.399 acc: 0.461\n",
      "\t - Step 92: loss: 1.603 acc: 0.398\n",
      "\t - Step 93: loss: 1.551 acc: 0.391\n",
      "\t - Step 94: loss: 1.483 acc: 0.398\n",
      "\t - Step 95: loss: 1.617 acc: 0.305\n",
      "\t - Step 96: loss: 1.585 acc: 0.383\n",
      "\t - Step 97: loss: 1.479 acc: 0.453\n",
      "\t - Step 98: loss: 1.556 acc: 0.445\n",
      "\t - Step 99: loss: 1.501 acc: 0.422\n",
      "\t - Step 100: loss: 1.646 acc: 0.398\n",
      "\t - Step 101: loss: 1.432 acc: 0.484\n",
      "\t - Step 102: loss: 1.537 acc: 0.500\n",
      "\t - Step 103: loss: 1.585 acc: 0.406\n",
      "\t - Step 104: loss: 1.334 acc: 0.531\n",
      "\t - Step 105: loss: 1.444 acc: 0.492\n",
      "\t - Step 106: loss: 1.519 acc: 0.336\n",
      "\t - Step 107: loss: 1.472 acc: 0.461\n",
      "\t - Step 108: loss: 1.637 acc: 0.359\n",
      "\t - Step 109: loss: 1.529 acc: 0.406\n",
      "\t - Step 110: loss: 1.464 acc: 0.461\n",
      "\t - Step 111: loss: 1.517 acc: 0.367\n",
      "\t - Step 112: loss: 1.517 acc: 0.398\n",
      "\t - Step 113: loss: 1.496 acc: 0.398\n",
      "\t - Step 114: loss: 1.487 acc: 0.398\n",
      "\t - Step 115: loss: 1.574 acc: 0.391\n",
      "\t - Step 116: loss: 1.540 acc: 0.422\n",
      "\t - Step 117: loss: 1.446 acc: 0.453\n",
      "\t - Step 118: loss: 1.557 acc: 0.422\n",
      "\t - Step 119: loss: 1.465 acc: 0.383\n",
      "\t - Step 120: loss: 1.652 acc: 0.336\n",
      "\t - Step 121: loss: 1.478 acc: 0.484\n",
      "\t - Step 122: loss: 1.512 acc: 0.398\n",
      "\t - Step 123: loss: 1.567 acc: 0.383\n",
      "\t - Step 124: loss: 1.695 acc: 0.320\n",
      "\t - Step 125: loss: 1.600 acc: 0.344\n",
      "\t - Step 126: loss: 1.497 acc: 0.422\n",
      "\t - Step 127: loss: 1.564 acc: 0.375\n",
      "\t - Step 128: loss: 1.502 acc: 0.438\n",
      "\t - Step 129: loss: 1.457 acc: 0.438\n",
      "\t - Step 130: loss: 1.557 acc: 0.406\n",
      "\t - Step 131: loss: 1.414 acc: 0.461\n",
      "\t - Step 132: loss: 1.560 acc: 0.414\n",
      "\t - Step 133: loss: 1.475 acc: 0.445\n",
      "\t - Step 134: loss: 1.478 acc: 0.453\n",
      "\t - Step 135: loss: 1.535 acc: 0.453\n",
      "\t - Step 136: loss: 1.498 acc: 0.398\n",
      "\t - Step 137: loss: 1.447 acc: 0.438\n",
      "\t - Step 138: loss: 1.484 acc: 0.383\n",
      "\t - Step 139: loss: 1.446 acc: 0.430\n",
      "\t - Step 140: loss: 1.538 acc: 0.461\n",
      "\t - Step 141: loss: 1.455 acc: 0.414\n",
      "\t - Step 142: loss: 1.660 acc: 0.328\n",
      "\t - Step 143: loss: 1.490 acc: 0.367\n",
      "\t - Step 144: loss: 1.475 acc: 0.398\n",
      "\t - Step 145: loss: 1.374 acc: 0.492\n",
      "\t - Step 146: loss: 1.436 acc: 0.492\n",
      "\t - Step 147: loss: 1.494 acc: 0.398\n",
      "\t - Step 148: loss: 1.524 acc: 0.453\n",
      "\t - Step 149: loss: 1.489 acc: 0.430\n",
      "\t - Step 150: loss: 1.472 acc: 0.414\n",
      "\t - Step 151: loss: 1.486 acc: 0.438\n",
      "\t - Step 152: loss: 1.509 acc: 0.438\n",
      "\t - Step 153: loss: 1.425 acc: 0.477\n",
      "\t - Step 154: loss: 1.578 acc: 0.328\n",
      "\t - Step 155: loss: 1.465 acc: 0.438\n",
      "\t - Step 156: loss: 1.439 acc: 0.438\n",
      "\t - Step 157: loss: 1.438 acc: 0.414\n",
      "\t - Step 158: loss: 1.541 acc: 0.422\n",
      "\t - Step 159: loss: 1.433 acc: 0.469\n",
      "\t - Step 160: loss: 1.519 acc: 0.398\n",
      "\t - Step 161: loss: 1.553 acc: 0.367\n",
      "\t - Step 162: loss: 1.501 acc: 0.422\n",
      "\t - Step 163: loss: 1.488 acc: 0.414\n",
      "\t - Step 164: loss: 1.436 acc: 0.492\n",
      "\t - Step 165: loss: 1.459 acc: 0.508\n",
      "\t - Step 166: loss: 1.511 acc: 0.367\n",
      "\t - Step 167: loss: 1.481 acc: 0.375\n",
      "\t - Step 168: loss: 1.466 acc: 0.414\n",
      "\t - Step 169: loss: 1.535 acc: 0.414\n",
      "\t - Step 170: loss: 1.516 acc: 0.445\n",
      "\t - Step 171: loss: 1.537 acc: 0.375\n",
      "\t - Step 172: loss: 1.440 acc: 0.477\n",
      "\t - Step 173: loss: 1.556 acc: 0.414\n",
      "\t - Step 174: loss: 1.462 acc: 0.430\n",
      "\t - Step 175: loss: 1.622 acc: 0.336\n",
      "\t - Step 176: loss: 1.562 acc: 0.406\n",
      "\t - Step 177: loss: 1.536 acc: 0.352\n",
      "\t - Step 178: loss: 1.483 acc: 0.430\n",
      "\t - Step 179: loss: 1.480 acc: 0.422\n",
      "\t - Step 180: loss: 1.450 acc: 0.430\n",
      "\t - Step 181: loss: 1.675 acc: 0.320\n",
      "\t - Step 182: loss: 1.550 acc: 0.406\n",
      "\t - Step 183: loss: 1.534 acc: 0.398\n",
      "\t - Step 184: loss: 1.537 acc: 0.367\n",
      "\t - Step 185: loss: 1.626 acc: 0.414\n",
      "\t - Step 186: loss: 1.405 acc: 0.539\n",
      "\t - Step 187: loss: 1.645 acc: 0.328\n",
      "\t - Step 188: loss: 1.503 acc: 0.398\n",
      "\t - Step 189: loss: 1.448 acc: 0.414\n",
      "\t - Step 190: loss: 1.540 acc: 0.430\n",
      "\t - Step 191: loss: 1.709 acc: 0.336\n",
      "\t - Step 192: loss: 1.365 acc: 0.492\n",
      "\t - Step 193: loss: 1.413 acc: 0.469\n",
      "\t - Step 194: loss: 1.510 acc: 0.469\n",
      "\t - Step 195: loss: 1.493 acc: 0.422\n",
      "\t - Step 196: loss: 1.440 acc: 0.422\n",
      "\t - Step 197: loss: 1.565 acc: 0.359\n",
      "\t - Step 198: loss: 1.428 acc: 0.477\n",
      "\t - Step 199: loss: 1.489 acc: 0.445\n",
      "\t - Step 200: loss: 1.438 acc: 0.477\n",
      "\t - Step 201: loss: 1.462 acc: 0.430\n",
      "\t - Step 202: loss: 1.427 acc: 0.492\n",
      "\t - Step 203: loss: 1.453 acc: 0.375\n",
      "\t - Step 204: loss: 1.579 acc: 0.406\n",
      "\t - Step 205: loss: 1.465 acc: 0.445\n",
      "\t - Step 206: loss: 1.576 acc: 0.359\n",
      "\t - Step 207: loss: 1.578 acc: 0.383\n",
      "\t - Step 208: loss: 1.380 acc: 0.500\n",
      "\t - Step 209: loss: 1.557 acc: 0.398\n",
      "\t - Step 210: loss: 1.513 acc: 0.430\n",
      "\t - Step 211: loss: 1.519 acc: 0.398\n",
      "\t - Step 212: loss: 1.474 acc: 0.367\n",
      "\t - Step 213: loss: 1.586 acc: 0.406\n",
      "\t - Step 214: loss: 1.440 acc: 0.461\n",
      "\t - Step 215: loss: 1.422 acc: 0.430\n",
      "\t - Step 216: loss: 1.658 acc: 0.367\n",
      "\t - Step 217: loss: 1.621 acc: 0.336\n",
      "\t - Step 218: loss: 1.501 acc: 0.477\n",
      "\t - Step 219: loss: 1.557 acc: 0.461\n",
      "\t - Step 220: loss: 1.533 acc: 0.438\n",
      "\t - Step 221: loss: 1.484 acc: 0.414\n",
      "\t - Step 222: loss: 1.598 acc: 0.414\n",
      "\t - Step 223: loss: 1.534 acc: 0.469\n",
      "\t - Step 224: loss: 1.653 acc: 0.375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t - Step 225: loss: 1.362 acc: 0.432\n",
      "- Avg.loss: 1.524  | Avg.acc: 0.412\n",
      "- Avg. val_loss: 1.579  | Avg. val_acc: 0.396\n",
      "* Update optimal model\n",
      "Epoch:  3\n",
      "\t - Step 1: loss: 1.517 acc: 0.492\n",
      "\t - Step 2: loss: 1.481 acc: 0.438\n",
      "\t - Step 3: loss: 1.358 acc: 0.523\n",
      "\t - Step 4: loss: 1.279 acc: 0.570\n",
      "\t - Step 5: loss: 1.426 acc: 0.477\n",
      "\t - Step 6: loss: 1.433 acc: 0.461\n",
      "\t - Step 7: loss: 1.510 acc: 0.453\n",
      "\t - Step 8: loss: 1.553 acc: 0.367\n",
      "\t - Step 9: loss: 1.381 acc: 0.477\n",
      "\t - Step 10: loss: 1.557 acc: 0.391\n",
      "\t - Step 11: loss: 1.317 acc: 0.484\n",
      "\t - Step 12: loss: 1.382 acc: 0.523\n",
      "\t - Step 13: loss: 1.460 acc: 0.477\n",
      "\t - Step 14: loss: 1.372 acc: 0.484\n",
      "\t - Step 15: loss: 1.610 acc: 0.406\n",
      "\t - Step 16: loss: 1.385 acc: 0.461\n",
      "\t - Step 17: loss: 1.324 acc: 0.492\n",
      "\t - Step 18: loss: 1.581 acc: 0.375\n",
      "\t - Step 19: loss: 1.466 acc: 0.406\n",
      "\t - Step 20: loss: 1.459 acc: 0.461\n",
      "\t - Step 21: loss: 1.529 acc: 0.445\n",
      "\t - Step 22: loss: 1.466 acc: 0.406\n",
      "\t - Step 23: loss: 1.329 acc: 0.523\n",
      "\t - Step 24: loss: 1.423 acc: 0.477\n",
      "\t - Step 25: loss: 1.461 acc: 0.383\n",
      "\t - Step 26: loss: 1.419 acc: 0.469\n",
      "\t - Step 27: loss: 1.568 acc: 0.469\n",
      "\t - Step 28: loss: 1.633 acc: 0.359\n",
      "\t - Step 29: loss: 1.425 acc: 0.461\n",
      "\t - Step 30: loss: 1.469 acc: 0.422\n",
      "\t - Step 31: loss: 1.506 acc: 0.414\n",
      "\t - Step 32: loss: 1.487 acc: 0.414\n",
      "\t - Step 33: loss: 1.493 acc: 0.398\n",
      "\t - Step 34: loss: 1.501 acc: 0.438\n",
      "\t - Step 35: loss: 1.437 acc: 0.406\n",
      "\t - Step 36: loss: 1.428 acc: 0.461\n",
      "\t - Step 37: loss: 1.466 acc: 0.445\n",
      "\t - Step 38: loss: 1.474 acc: 0.430\n",
      "\t - Step 39: loss: 1.444 acc: 0.445\n",
      "\t - Step 40: loss: 1.512 acc: 0.359\n",
      "\t - Step 41: loss: 1.424 acc: 0.469\n",
      "\t - Step 42: loss: 1.483 acc: 0.422\n",
      "\t - Step 43: loss: 1.461 acc: 0.469\n",
      "\t - Step 44: loss: 1.383 acc: 0.492\n",
      "\t - Step 45: loss: 1.463 acc: 0.430\n",
      "\t - Step 46: loss: 1.531 acc: 0.469\n",
      "\t - Step 47: loss: 1.467 acc: 0.414\n",
      "\t - Step 48: loss: 1.394 acc: 0.461\n",
      "\t - Step 49: loss: 1.479 acc: 0.422\n",
      "\t - Step 50: loss: 1.454 acc: 0.500\n",
      "\t - Step 51: loss: 1.434 acc: 0.469\n",
      "\t - Step 52: loss: 1.517 acc: 0.461\n",
      "\t - Step 53: loss: 1.490 acc: 0.438\n",
      "\t - Step 54: loss: 1.408 acc: 0.492\n",
      "\t - Step 55: loss: 1.523 acc: 0.422\n",
      "\t - Step 56: loss: 1.469 acc: 0.500\n",
      "\t - Step 57: loss: 1.469 acc: 0.469\n",
      "\t - Step 58: loss: 1.345 acc: 0.508\n",
      "\t - Step 59: loss: 1.396 acc: 0.500\n",
      "\t - Step 60: loss: 1.329 acc: 0.508\n",
      "\t - Step 61: loss: 1.447 acc: 0.484\n",
      "\t - Step 62: loss: 1.463 acc: 0.445\n",
      "\t - Step 63: loss: 1.394 acc: 0.477\n",
      "\t - Step 64: loss: 1.459 acc: 0.469\n",
      "\t - Step 65: loss: 1.550 acc: 0.391\n",
      "\t - Step 66: loss: 1.472 acc: 0.445\n",
      "\t - Step 67: loss: 1.522 acc: 0.438\n",
      "\t - Step 68: loss: 1.353 acc: 0.484\n",
      "\t - Step 69: loss: 1.555 acc: 0.445\n",
      "\t - Step 70: loss: 1.452 acc: 0.438\n",
      "\t - Step 71: loss: 1.312 acc: 0.531\n",
      "\t - Step 72: loss: 1.389 acc: 0.453\n",
      "\t - Step 73: loss: 1.588 acc: 0.414\n",
      "\t - Step 74: loss: 1.582 acc: 0.375\n",
      "\t - Step 75: loss: 1.462 acc: 0.461\n",
      "\t - Step 76: loss: 1.490 acc: 0.414\n",
      "\t - Step 77: loss: 1.456 acc: 0.453\n",
      "\t - Step 78: loss: 1.334 acc: 0.508\n",
      "\t - Step 79: loss: 1.386 acc: 0.477\n",
      "\t - Step 80: loss: 1.391 acc: 0.508\n",
      "\t - Step 81: loss: 1.437 acc: 0.453\n",
      "\t - Step 82: loss: 1.428 acc: 0.438\n",
      "\t - Step 83: loss: 1.543 acc: 0.375\n",
      "\t - Step 84: loss: 1.413 acc: 0.461\n",
      "\t - Step 85: loss: 1.392 acc: 0.500\n",
      "\t - Step 86: loss: 1.557 acc: 0.438\n",
      "\t - Step 87: loss: 1.587 acc: 0.438\n",
      "\t - Step 88: loss: 1.536 acc: 0.406\n",
      "\t - Step 89: loss: 1.587 acc: 0.438\n",
      "\t - Step 90: loss: 1.526 acc: 0.438\n",
      "\t - Step 91: loss: 1.381 acc: 0.430\n",
      "\t - Step 92: loss: 1.405 acc: 0.547\n",
      "\t - Step 93: loss: 1.539 acc: 0.367\n",
      "\t - Step 94: loss: 1.503 acc: 0.453\n",
      "\t - Step 95: loss: 1.488 acc: 0.414\n",
      "\t - Step 96: loss: 1.414 acc: 0.469\n",
      "\t - Step 97: loss: 1.444 acc: 0.461\n",
      "\t - Step 98: loss: 1.481 acc: 0.469\n",
      "\t - Step 99: loss: 1.469 acc: 0.414\n",
      "\t - Step 100: loss: 1.540 acc: 0.438\n",
      "\t - Step 101: loss: 1.552 acc: 0.406\n",
      "\t - Step 102: loss: 1.551 acc: 0.398\n",
      "\t - Step 103: loss: 1.442 acc: 0.438\n",
      "\t - Step 104: loss: 1.489 acc: 0.406\n",
      "\t - Step 105: loss: 1.582 acc: 0.391\n",
      "\t - Step 106: loss: 1.604 acc: 0.367\n",
      "\t - Step 107: loss: 1.521 acc: 0.406\n",
      "\t - Step 108: loss: 1.529 acc: 0.352\n",
      "\t - Step 109: loss: 1.382 acc: 0.453\n",
      "\t - Step 110: loss: 1.374 acc: 0.484\n",
      "\t - Step 111: loss: 1.382 acc: 0.508\n",
      "\t - Step 112: loss: 1.392 acc: 0.484\n",
      "\t - Step 113: loss: 1.626 acc: 0.344\n",
      "\t - Step 114: loss: 1.474 acc: 0.375\n",
      "\t - Step 115: loss: 1.538 acc: 0.430\n",
      "\t - Step 116: loss: 1.342 acc: 0.516\n",
      "\t - Step 117: loss: 1.498 acc: 0.406\n",
      "\t - Step 118: loss: 1.489 acc: 0.422\n",
      "\t - Step 119: loss: 1.475 acc: 0.453\n",
      "\t - Step 120: loss: 1.536 acc: 0.484\n",
      "\t - Step 121: loss: 1.413 acc: 0.477\n",
      "\t - Step 122: loss: 1.559 acc: 0.398\n",
      "\t - Step 123: loss: 1.412 acc: 0.469\n",
      "\t - Step 124: loss: 1.585 acc: 0.406\n",
      "\t - Step 125: loss: 1.386 acc: 0.500\n",
      "\t - Step 126: loss: 1.505 acc: 0.438\n",
      "\t - Step 127: loss: 1.464 acc: 0.453\n",
      "\t - Step 128: loss: 1.434 acc: 0.398\n",
      "\t - Step 129: loss: 1.418 acc: 0.453\n",
      "\t - Step 130: loss: 1.513 acc: 0.414\n",
      "\t - Step 131: loss: 1.439 acc: 0.500\n",
      "\t - Step 132: loss: 1.507 acc: 0.391\n",
      "\t - Step 133: loss: 1.386 acc: 0.469\n",
      "\t - Step 134: loss: 1.462 acc: 0.453\n",
      "\t - Step 135: loss: 1.446 acc: 0.375\n",
      "\t - Step 136: loss: 1.440 acc: 0.438\n",
      "\t - Step 137: loss: 1.489 acc: 0.484\n",
      "\t - Step 138: loss: 1.495 acc: 0.461\n",
      "\t - Step 139: loss: 1.440 acc: 0.453\n",
      "\t - Step 140: loss: 1.599 acc: 0.406\n",
      "\t - Step 141: loss: 1.540 acc: 0.406\n",
      "\t - Step 142: loss: 1.388 acc: 0.516\n",
      "\t - Step 143: loss: 1.561 acc: 0.359\n",
      "\t - Step 144: loss: 1.410 acc: 0.508\n",
      "\t - Step 145: loss: 1.415 acc: 0.477\n",
      "\t - Step 146: loss: 1.451 acc: 0.391\n",
      "\t - Step 147: loss: 1.638 acc: 0.352\n",
      "\t - Step 148: loss: 1.393 acc: 0.523\n",
      "\t - Step 149: loss: 1.413 acc: 0.414\n",
      "\t - Step 150: loss: 1.496 acc: 0.414\n",
      "\t - Step 151: loss: 1.494 acc: 0.461\n",
      "\t - Step 152: loss: 1.470 acc: 0.469\n",
      "\t - Step 153: loss: 1.297 acc: 0.531\n",
      "\t - Step 154: loss: 1.431 acc: 0.453\n",
      "\t - Step 155: loss: 1.581 acc: 0.406\n",
      "\t - Step 156: loss: 1.540 acc: 0.414\n",
      "\t - Step 157: loss: 1.450 acc: 0.438\n",
      "\t - Step 158: loss: 1.485 acc: 0.406\n",
      "\t - Step 159: loss: 1.498 acc: 0.461\n",
      "\t - Step 160: loss: 1.535 acc: 0.383\n",
      "\t - Step 161: loss: 1.331 acc: 0.531\n",
      "\t - Step 162: loss: 1.581 acc: 0.398\n",
      "\t - Step 163: loss: 1.423 acc: 0.492\n",
      "\t - Step 164: loss: 1.406 acc: 0.461\n",
      "\t - Step 165: loss: 1.454 acc: 0.422\n",
      "\t - Step 166: loss: 1.532 acc: 0.461\n",
      "\t - Step 167: loss: 1.445 acc: 0.469\n",
      "\t - Step 168: loss: 1.330 acc: 0.523\n",
      "\t - Step 169: loss: 1.498 acc: 0.414\n",
      "\t - Step 170: loss: 1.550 acc: 0.383\n",
      "\t - Step 171: loss: 1.483 acc: 0.430\n",
      "\t - Step 172: loss: 1.440 acc: 0.469\n",
      "\t - Step 173: loss: 1.539 acc: 0.422\n",
      "\t - Step 174: loss: 1.449 acc: 0.406\n",
      "\t - Step 175: loss: 1.515 acc: 0.438\n",
      "\t - Step 176: loss: 1.377 acc: 0.469\n",
      "\t - Step 177: loss: 1.381 acc: 0.508\n",
      "\t - Step 178: loss: 1.491 acc: 0.414\n",
      "\t - Step 179: loss: 1.505 acc: 0.406\n",
      "\t - Step 180: loss: 1.514 acc: 0.383\n",
      "\t - Step 181: loss: 1.562 acc: 0.438\n",
      "\t - Step 182: loss: 1.480 acc: 0.477\n",
      "\t - Step 183: loss: 1.323 acc: 0.555\n",
      "\t - Step 184: loss: 1.500 acc: 0.469\n",
      "\t - Step 185: loss: 1.372 acc: 0.523\n",
      "\t - Step 186: loss: 1.372 acc: 0.461\n",
      "\t - Step 187: loss: 1.560 acc: 0.422\n",
      "\t - Step 188: loss: 1.487 acc: 0.406\n",
      "\t - Step 189: loss: 1.440 acc: 0.461\n",
      "\t - Step 190: loss: 1.443 acc: 0.445\n",
      "\t - Step 191: loss: 1.422 acc: 0.477\n",
      "\t - Step 192: loss: 1.470 acc: 0.383\n",
      "\t - Step 193: loss: 1.532 acc: 0.438\n",
      "\t - Step 194: loss: 1.416 acc: 0.438\n",
      "\t - Step 195: loss: 1.437 acc: 0.469\n",
      "\t - Step 196: loss: 1.472 acc: 0.508\n",
      "\t - Step 197: loss: 1.421 acc: 0.469\n",
      "\t - Step 198: loss: 1.513 acc: 0.445\n",
      "\t - Step 199: loss: 1.390 acc: 0.484\n",
      "\t - Step 200: loss: 1.545 acc: 0.352\n",
      "\t - Step 201: loss: 1.393 acc: 0.492\n",
      "\t - Step 202: loss: 1.414 acc: 0.484\n",
      "\t - Step 203: loss: 1.461 acc: 0.477\n",
      "\t - Step 204: loss: 1.431 acc: 0.430\n",
      "\t - Step 205: loss: 1.477 acc: 0.445\n",
      "\t - Step 206: loss: 1.403 acc: 0.391\n",
      "\t - Step 207: loss: 1.442 acc: 0.422\n",
      "\t - Step 208: loss: 1.334 acc: 0.492\n",
      "\t - Step 209: loss: 1.470 acc: 0.438\n",
      "\t - Step 210: loss: 1.478 acc: 0.430\n",
      "\t - Step 211: loss: 1.437 acc: 0.414\n",
      "\t - Step 212: loss: 1.356 acc: 0.469\n",
      "\t - Step 213: loss: 1.743 acc: 0.305\n",
      "\t - Step 214: loss: 1.680 acc: 0.312\n",
      "\t - Step 215: loss: 1.496 acc: 0.422\n",
      "\t - Step 216: loss: 1.371 acc: 0.492\n",
      "\t - Step 217: loss: 1.395 acc: 0.508\n",
      "\t - Step 218: loss: 1.475 acc: 0.422\n",
      "\t - Step 219: loss: 1.448 acc: 0.477\n",
      "\t - Step 220: loss: 1.463 acc: 0.406\n",
      "\t - Step 221: loss: 1.367 acc: 0.477\n",
      "\t - Step 222: loss: 1.419 acc: 0.531\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t - Step 223: loss: 1.272 acc: 0.477\n",
      "\t - Step 224: loss: 1.426 acc: 0.438\n",
      "\t - Step 225: loss: 1.756 acc: 0.405\n",
      "- Avg.loss: 1.464  | Avg.acc: 0.446\n",
      "- Avg. val_loss: 1.541  | Avg. val_acc: 0.411\n",
      "* Update optimal model\n",
      "Epoch:  4\n",
      "\t - Step 1: loss: 1.437 acc: 0.477\n",
      "\t - Step 2: loss: 1.320 acc: 0.547\n",
      "\t - Step 3: loss: 1.484 acc: 0.398\n",
      "\t - Step 4: loss: 1.428 acc: 0.453\n",
      "\t - Step 5: loss: 1.516 acc: 0.430\n",
      "\t - Step 6: loss: 1.346 acc: 0.422\n",
      "\t - Step 7: loss: 1.416 acc: 0.422\n",
      "\t - Step 8: loss: 1.418 acc: 0.422\n",
      "\t - Step 9: loss: 1.394 acc: 0.461\n",
      "\t - Step 10: loss: 1.522 acc: 0.391\n",
      "\t - Step 11: loss: 1.409 acc: 0.453\n",
      "\t - Step 12: loss: 1.468 acc: 0.453\n",
      "\t - Step 13: loss: 1.338 acc: 0.492\n",
      "\t - Step 14: loss: 1.449 acc: 0.422\n",
      "\t - Step 15: loss: 1.355 acc: 0.508\n",
      "\t - Step 16: loss: 1.471 acc: 0.508\n",
      "\t - Step 17: loss: 1.390 acc: 0.469\n",
      "\t - Step 18: loss: 1.478 acc: 0.430\n",
      "\t - Step 19: loss: 1.309 acc: 0.508\n",
      "\t - Step 20: loss: 1.393 acc: 0.469\n",
      "\t - Step 21: loss: 1.352 acc: 0.469\n",
      "\t - Step 22: loss: 1.365 acc: 0.461\n",
      "\t - Step 23: loss: 1.399 acc: 0.461\n",
      "\t - Step 24: loss: 1.421 acc: 0.461\n",
      "\t - Step 25: loss: 1.417 acc: 0.477\n",
      "\t - Step 26: loss: 1.348 acc: 0.477\n",
      "\t - Step 27: loss: 1.476 acc: 0.461\n",
      "\t - Step 28: loss: 1.398 acc: 0.438\n",
      "\t - Step 29: loss: 1.434 acc: 0.438\n",
      "\t - Step 30: loss: 1.342 acc: 0.500\n",
      "\t - Step 31: loss: 1.312 acc: 0.523\n",
      "\t - Step 32: loss: 1.307 acc: 0.523\n",
      "\t - Step 33: loss: 1.461 acc: 0.438\n",
      "\t - Step 34: loss: 1.485 acc: 0.453\n",
      "\t - Step 35: loss: 1.671 acc: 0.367\n",
      "\t - Step 36: loss: 1.354 acc: 0.508\n",
      "\t - Step 37: loss: 1.432 acc: 0.523\n",
      "\t - Step 38: loss: 1.256 acc: 0.531\n",
      "\t - Step 39: loss: 1.454 acc: 0.461\n",
      "\t - Step 40: loss: 1.311 acc: 0.562\n",
      "\t - Step 41: loss: 1.449 acc: 0.422\n",
      "\t - Step 42: loss: 1.306 acc: 0.531\n",
      "\t - Step 43: loss: 1.397 acc: 0.516\n",
      "\t - Step 44: loss: 1.313 acc: 0.500\n",
      "\t - Step 45: loss: 1.497 acc: 0.430\n",
      "\t - Step 46: loss: 1.529 acc: 0.422\n",
      "\t - Step 47: loss: 1.408 acc: 0.461\n",
      "\t - Step 48: loss: 1.344 acc: 0.469\n",
      "\t - Step 49: loss: 1.338 acc: 0.492\n",
      "\t - Step 50: loss: 1.328 acc: 0.469\n",
      "\t - Step 51: loss: 1.360 acc: 0.477\n",
      "\t - Step 52: loss: 1.433 acc: 0.414\n",
      "\t - Step 53: loss: 1.479 acc: 0.453\n",
      "\t - Step 54: loss: 1.330 acc: 0.492\n",
      "\t - Step 55: loss: 1.422 acc: 0.445\n",
      "\t - Step 56: loss: 1.275 acc: 0.555\n",
      "\t - Step 57: loss: 1.497 acc: 0.398\n",
      "\t - Step 58: loss: 1.557 acc: 0.438\n",
      "\t - Step 59: loss: 1.324 acc: 0.539\n",
      "\t - Step 60: loss: 1.535 acc: 0.445\n",
      "\t - Step 61: loss: 1.491 acc: 0.438\n",
      "\t - Step 62: loss: 1.417 acc: 0.453\n",
      "\t - Step 63: loss: 1.495 acc: 0.406\n",
      "\t - Step 64: loss: 1.405 acc: 0.430\n",
      "\t - Step 65: loss: 1.384 acc: 0.508\n",
      "\t - Step 66: loss: 1.406 acc: 0.438\n",
      "\t - Step 67: loss: 1.556 acc: 0.391\n",
      "\t - Step 68: loss: 1.518 acc: 0.383\n",
      "\t - Step 69: loss: 1.551 acc: 0.391\n",
      "\t - Step 70: loss: 1.384 acc: 0.492\n",
      "\t - Step 71: loss: 1.325 acc: 0.531\n",
      "\t - Step 72: loss: 1.499 acc: 0.398\n",
      "\t - Step 73: loss: 1.481 acc: 0.500\n",
      "\t - Step 74: loss: 1.391 acc: 0.469\n",
      "\t - Step 75: loss: 1.484 acc: 0.477\n",
      "\t - Step 76: loss: 1.514 acc: 0.438\n",
      "\t - Step 77: loss: 1.469 acc: 0.422\n",
      "\t - Step 78: loss: 1.450 acc: 0.438\n",
      "\t - Step 79: loss: 1.472 acc: 0.422\n",
      "\t - Step 80: loss: 1.333 acc: 0.539\n",
      "\t - Step 81: loss: 1.405 acc: 0.531\n",
      "\t - Step 82: loss: 1.424 acc: 0.430\n",
      "\t - Step 83: loss: 1.478 acc: 0.469\n",
      "\t - Step 84: loss: 1.563 acc: 0.391\n",
      "\t - Step 85: loss: 1.540 acc: 0.445\n",
      "\t - Step 86: loss: 1.353 acc: 0.508\n",
      "\t - Step 87: loss: 1.431 acc: 0.445\n",
      "\t - Step 88: loss: 1.465 acc: 0.453\n",
      "\t - Step 89: loss: 1.482 acc: 0.445\n",
      "\t - Step 90: loss: 1.496 acc: 0.391\n",
      "\t - Step 91: loss: 1.503 acc: 0.414\n",
      "\t - Step 92: loss: 1.336 acc: 0.555\n",
      "\t - Step 93: loss: 1.391 acc: 0.422\n",
      "\t - Step 94: loss: 1.365 acc: 0.508\n",
      "\t - Step 95: loss: 1.449 acc: 0.453\n",
      "\t - Step 96: loss: 1.323 acc: 0.508\n",
      "\t - Step 97: loss: 1.358 acc: 0.484\n",
      "\t - Step 98: loss: 1.521 acc: 0.422\n",
      "\t - Step 99: loss: 1.372 acc: 0.469\n",
      "\t - Step 100: loss: 1.404 acc: 0.461\n",
      "\t - Step 101: loss: 1.338 acc: 0.461\n",
      "\t - Step 102: loss: 1.372 acc: 0.492\n",
      "\t - Step 103: loss: 1.402 acc: 0.477\n",
      "\t - Step 104: loss: 1.343 acc: 0.562\n",
      "\t - Step 105: loss: 1.689 acc: 0.344\n",
      "\t - Step 106: loss: 1.433 acc: 0.469\n",
      "\t - Step 107: loss: 1.466 acc: 0.422\n",
      "\t - Step 108: loss: 1.434 acc: 0.453\n",
      "\t - Step 109: loss: 1.452 acc: 0.422\n",
      "\t - Step 110: loss: 1.260 acc: 0.516\n",
      "\t - Step 111: loss: 1.543 acc: 0.391\n",
      "\t - Step 112: loss: 1.419 acc: 0.484\n",
      "\t - Step 113: loss: 1.328 acc: 0.555\n",
      "\t - Step 114: loss: 1.452 acc: 0.523\n",
      "\t - Step 115: loss: 1.438 acc: 0.492\n",
      "\t - Step 116: loss: 1.372 acc: 0.492\n",
      "\t - Step 117: loss: 1.449 acc: 0.438\n",
      "\t - Step 118: loss: 1.285 acc: 0.555\n",
      "\t - Step 119: loss: 1.315 acc: 0.508\n",
      "\t - Step 120: loss: 1.338 acc: 0.500\n",
      "\t - Step 121: loss: 1.385 acc: 0.500\n",
      "\t - Step 122: loss: 1.285 acc: 0.523\n",
      "\t - Step 123: loss: 1.509 acc: 0.438\n",
      "\t - Step 124: loss: 1.592 acc: 0.406\n",
      "\t - Step 125: loss: 1.531 acc: 0.414\n",
      "\t - Step 126: loss: 1.314 acc: 0.539\n",
      "\t - Step 127: loss: 1.578 acc: 0.414\n",
      "\t - Step 128: loss: 1.493 acc: 0.445\n",
      "\t - Step 129: loss: 1.320 acc: 0.531\n",
      "\t - Step 130: loss: 1.347 acc: 0.469\n",
      "\t - Step 131: loss: 1.393 acc: 0.453\n",
      "\t - Step 132: loss: 1.431 acc: 0.398\n",
      "\t - Step 133: loss: 1.413 acc: 0.430\n",
      "\t - Step 134: loss: 1.428 acc: 0.438\n",
      "\t - Step 135: loss: 1.338 acc: 0.508\n",
      "\t - Step 136: loss: 1.299 acc: 0.547\n",
      "\t - Step 137: loss: 1.436 acc: 0.445\n",
      "\t - Step 138: loss: 1.431 acc: 0.438\n",
      "\t - Step 139: loss: 1.412 acc: 0.500\n",
      "\t - Step 140: loss: 1.436 acc: 0.422\n",
      "\t - Step 141: loss: 1.403 acc: 0.445\n",
      "\t - Step 142: loss: 1.438 acc: 0.469\n",
      "\t - Step 143: loss: 1.633 acc: 0.438\n",
      "\t - Step 144: loss: 1.397 acc: 0.484\n",
      "\t - Step 145: loss: 1.514 acc: 0.391\n",
      "\t - Step 146: loss: 1.542 acc: 0.414\n",
      "\t - Step 147: loss: 1.407 acc: 0.523\n",
      "\t - Step 148: loss: 1.373 acc: 0.492\n",
      "\t - Step 149: loss: 1.487 acc: 0.375\n",
      "\t - Step 150: loss: 1.482 acc: 0.422\n",
      "\t - Step 151: loss: 1.383 acc: 0.516\n",
      "\t - Step 152: loss: 1.423 acc: 0.430\n",
      "\t - Step 153: loss: 1.331 acc: 0.531\n",
      "\t - Step 154: loss: 1.482 acc: 0.500\n",
      "\t - Step 155: loss: 1.458 acc: 0.477\n",
      "\t - Step 156: loss: 1.439 acc: 0.430\n",
      "\t - Step 157: loss: 1.302 acc: 0.516\n",
      "\t - Step 158: loss: 1.515 acc: 0.414\n",
      "\t - Step 159: loss: 1.448 acc: 0.438\n",
      "\t - Step 160: loss: 1.471 acc: 0.453\n",
      "\t - Step 161: loss: 1.569 acc: 0.453\n",
      "\t - Step 162: loss: 1.442 acc: 0.406\n",
      "\t - Step 163: loss: 1.404 acc: 0.422\n",
      "\t - Step 164: loss: 1.407 acc: 0.477\n",
      "\t - Step 165: loss: 1.486 acc: 0.469\n",
      "\t - Step 166: loss: 1.436 acc: 0.492\n",
      "\t - Step 167: loss: 1.469 acc: 0.445\n",
      "\t - Step 168: loss: 1.438 acc: 0.445\n",
      "\t - Step 169: loss: 1.426 acc: 0.438\n",
      "\t - Step 170: loss: 1.435 acc: 0.477\n",
      "\t - Step 171: loss: 1.336 acc: 0.500\n",
      "\t - Step 172: loss: 1.460 acc: 0.523\n",
      "\t - Step 173: loss: 1.311 acc: 0.523\n",
      "\t - Step 174: loss: 1.425 acc: 0.461\n",
      "\t - Step 175: loss: 1.424 acc: 0.414\n",
      "\t - Step 176: loss: 1.442 acc: 0.414\n",
      "\t - Step 177: loss: 1.416 acc: 0.461\n",
      "\t - Step 178: loss: 1.486 acc: 0.430\n",
      "\t - Step 179: loss: 1.221 acc: 0.570\n",
      "\t - Step 180: loss: 1.501 acc: 0.492\n",
      "\t - Step 181: loss: 1.569 acc: 0.438\n",
      "\t - Step 182: loss: 1.560 acc: 0.398\n",
      "\t - Step 183: loss: 1.623 acc: 0.367\n",
      "\t - Step 184: loss: 1.471 acc: 0.461\n",
      "\t - Step 185: loss: 1.519 acc: 0.414\n",
      "\t - Step 186: loss: 1.555 acc: 0.438\n",
      "\t - Step 187: loss: 1.501 acc: 0.406\n",
      "\t - Step 188: loss: 1.498 acc: 0.445\n",
      "\t - Step 189: loss: 1.375 acc: 0.500\n",
      "\t - Step 190: loss: 1.356 acc: 0.555\n",
      "\t - Step 191: loss: 1.505 acc: 0.438\n",
      "\t - Step 192: loss: 1.366 acc: 0.430\n",
      "\t - Step 193: loss: 1.453 acc: 0.430\n",
      "\t - Step 194: loss: 1.446 acc: 0.500\n",
      "\t - Step 195: loss: 1.505 acc: 0.438\n",
      "\t - Step 196: loss: 1.388 acc: 0.484\n",
      "\t - Step 197: loss: 1.409 acc: 0.414\n",
      "\t - Step 198: loss: 1.474 acc: 0.398\n",
      "\t - Step 199: loss: 1.562 acc: 0.453\n",
      "\t - Step 200: loss: 1.376 acc: 0.477\n",
      "\t - Step 201: loss: 1.369 acc: 0.461\n",
      "\t - Step 202: loss: 1.507 acc: 0.414\n",
      "\t - Step 203: loss: 1.489 acc: 0.430\n",
      "\t - Step 204: loss: 1.396 acc: 0.500\n",
      "\t - Step 205: loss: 1.317 acc: 0.508\n",
      "\t - Step 206: loss: 1.360 acc: 0.531\n",
      "\t - Step 207: loss: 1.366 acc: 0.453\n",
      "\t - Step 208: loss: 1.527 acc: 0.430\n",
      "\t - Step 209: loss: 1.278 acc: 0.508\n",
      "\t - Step 210: loss: 1.408 acc: 0.461\n",
      "\t - Step 211: loss: 1.409 acc: 0.445\n",
      "\t - Step 212: loss: 1.415 acc: 0.445\n",
      "\t - Step 213: loss: 1.387 acc: 0.500\n",
      "\t - Step 214: loss: 1.460 acc: 0.500\n",
      "\t - Step 215: loss: 1.499 acc: 0.391\n",
      "\t - Step 216: loss: 1.596 acc: 0.445\n",
      "\t - Step 217: loss: 1.439 acc: 0.383\n",
      "\t - Step 218: loss: 1.352 acc: 0.453\n",
      "\t - Step 219: loss: 1.443 acc: 0.469\n",
      "\t - Step 220: loss: 1.587 acc: 0.367\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t - Step 221: loss: 1.606 acc: 0.352\n",
      "\t - Step 222: loss: 1.467 acc: 0.406\n",
      "\t - Step 223: loss: 1.456 acc: 0.414\n",
      "\t - Step 224: loss: 1.432 acc: 0.430\n",
      "\t - Step 225: loss: 1.279 acc: 0.568\n",
      "- Avg.loss: 1.429  | Avg.acc: 0.461\n",
      "- Avg. val_loss: 1.628  | Avg. val_acc: 0.377\n",
      "Epoch:  5\n",
      "\t - Step 1: loss: 1.390 acc: 0.453\n",
      "\t - Step 2: loss: 1.328 acc: 0.523\n",
      "\t - Step 3: loss: 1.409 acc: 0.414\n",
      "\t - Step 4: loss: 1.467 acc: 0.492\n",
      "\t - Step 5: loss: 1.323 acc: 0.555\n",
      "\t - Step 6: loss: 1.319 acc: 0.469\n",
      "\t - Step 7: loss: 1.395 acc: 0.414\n",
      "\t - Step 8: loss: 1.379 acc: 0.500\n",
      "\t - Step 9: loss: 1.439 acc: 0.453\n",
      "\t - Step 10: loss: 1.310 acc: 0.516\n",
      "\t - Step 11: loss: 1.640 acc: 0.359\n",
      "\t - Step 12: loss: 1.329 acc: 0.531\n",
      "\t - Step 13: loss: 1.497 acc: 0.406\n",
      "\t - Step 14: loss: 1.496 acc: 0.414\n",
      "\t - Step 15: loss: 1.369 acc: 0.453\n",
      "\t - Step 16: loss: 1.376 acc: 0.477\n",
      "\t - Step 17: loss: 1.408 acc: 0.469\n",
      "\t - Step 18: loss: 1.353 acc: 0.516\n",
      "\t - Step 19: loss: 1.396 acc: 0.516\n",
      "\t - Step 20: loss: 1.428 acc: 0.453\n",
      "\t - Step 21: loss: 1.383 acc: 0.477\n",
      "\t - Step 22: loss: 1.395 acc: 0.477\n",
      "\t - Step 23: loss: 1.485 acc: 0.414\n",
      "\t - Step 24: loss: 1.573 acc: 0.383\n",
      "\t - Step 25: loss: 1.392 acc: 0.484\n",
      "\t - Step 26: loss: 1.273 acc: 0.547\n",
      "\t - Step 27: loss: 1.411 acc: 0.438\n",
      "\t - Step 28: loss: 1.473 acc: 0.469\n",
      "\t - Step 29: loss: 1.278 acc: 0.531\n",
      "\t - Step 30: loss: 1.358 acc: 0.477\n",
      "\t - Step 31: loss: 1.394 acc: 0.523\n",
      "\t - Step 32: loss: 1.473 acc: 0.438\n",
      "\t - Step 33: loss: 1.314 acc: 0.500\n",
      "\t - Step 34: loss: 1.498 acc: 0.422\n",
      "\t - Step 35: loss: 1.306 acc: 0.555\n",
      "\t - Step 36: loss: 1.245 acc: 0.523\n",
      "\t - Step 37: loss: 1.346 acc: 0.516\n",
      "\t - Step 38: loss: 1.392 acc: 0.445\n",
      "\t - Step 39: loss: 1.364 acc: 0.445\n",
      "\t - Step 40: loss: 1.398 acc: 0.430\n",
      "\t - Step 41: loss: 1.561 acc: 0.430\n",
      "\t - Step 42: loss: 1.337 acc: 0.516\n",
      "\t - Step 43: loss: 1.372 acc: 0.492\n",
      "\t - Step 44: loss: 1.472 acc: 0.469\n",
      "\t - Step 45: loss: 1.448 acc: 0.445\n",
      "\t - Step 46: loss: 1.385 acc: 0.477\n",
      "\t - Step 47: loss: 1.284 acc: 0.539\n",
      "\t - Step 48: loss: 1.247 acc: 0.500\n",
      "\t - Step 49: loss: 1.388 acc: 0.445\n",
      "\t - Step 50: loss: 1.446 acc: 0.438\n",
      "\t - Step 51: loss: 1.183 acc: 0.562\n",
      "\t - Step 52: loss: 1.409 acc: 0.445\n",
      "\t - Step 53: loss: 1.519 acc: 0.367\n",
      "\t - Step 54: loss: 1.439 acc: 0.477\n",
      "\t - Step 55: loss: 1.408 acc: 0.469\n",
      "\t - Step 56: loss: 1.429 acc: 0.461\n",
      "\t - Step 57: loss: 1.307 acc: 0.508\n",
      "\t - Step 58: loss: 1.322 acc: 0.477\n",
      "\t - Step 59: loss: 1.486 acc: 0.414\n",
      "\t - Step 60: loss: 1.539 acc: 0.367\n",
      "\t - Step 61: loss: 1.546 acc: 0.367\n",
      "\t - Step 62: loss: 1.304 acc: 0.508\n",
      "\t - Step 63: loss: 1.319 acc: 0.523\n",
      "\t - Step 64: loss: 1.431 acc: 0.469\n",
      "\t - Step 65: loss: 1.315 acc: 0.500\n",
      "\t - Step 66: loss: 1.356 acc: 0.516\n",
      "\t - Step 67: loss: 1.383 acc: 0.469\n",
      "\t - Step 68: loss: 1.407 acc: 0.492\n",
      "\t - Step 69: loss: 1.405 acc: 0.500\n",
      "\t - Step 70: loss: 1.383 acc: 0.461\n",
      "\t - Step 71: loss: 1.309 acc: 0.469\n",
      "\t - Step 72: loss: 1.560 acc: 0.422\n",
      "\t - Step 73: loss: 1.321 acc: 0.523\n",
      "\t - Step 74: loss: 1.442 acc: 0.492\n",
      "\t - Step 75: loss: 1.430 acc: 0.406\n",
      "\t - Step 76: loss: 1.313 acc: 0.453\n",
      "\t - Step 77: loss: 1.382 acc: 0.492\n",
      "\t - Step 78: loss: 1.417 acc: 0.430\n",
      "\t - Step 79: loss: 1.387 acc: 0.508\n",
      "\t - Step 80: loss: 1.453 acc: 0.414\n",
      "\t - Step 81: loss: 1.302 acc: 0.516\n",
      "\t - Step 82: loss: 1.324 acc: 0.484\n",
      "\t - Step 83: loss: 1.358 acc: 0.445\n",
      "\t - Step 84: loss: 1.424 acc: 0.523\n",
      "\t - Step 85: loss: 1.415 acc: 0.461\n",
      "\t - Step 86: loss: 1.463 acc: 0.469\n",
      "\t - Step 87: loss: 1.386 acc: 0.508\n",
      "\t - Step 88: loss: 1.460 acc: 0.445\n",
      "\t - Step 89: loss: 1.279 acc: 0.523\n",
      "\t - Step 90: loss: 1.320 acc: 0.516\n",
      "\t - Step 91: loss: 1.304 acc: 0.500\n",
      "\t - Step 92: loss: 1.416 acc: 0.492\n",
      "\t - Step 93: loss: 1.345 acc: 0.469\n",
      "\t - Step 94: loss: 1.528 acc: 0.383\n",
      "\t - Step 95: loss: 1.296 acc: 0.508\n",
      "\t - Step 96: loss: 1.539 acc: 0.453\n",
      "\t - Step 97: loss: 1.436 acc: 0.469\n",
      "\t - Step 98: loss: 1.374 acc: 0.492\n",
      "\t - Step 99: loss: 1.457 acc: 0.484\n",
      "\t - Step 100: loss: 1.580 acc: 0.445\n",
      "\t - Step 101: loss: 1.553 acc: 0.453\n",
      "\t - Step 102: loss: 1.368 acc: 0.445\n",
      "\t - Step 103: loss: 1.316 acc: 0.539\n",
      "\t - Step 104: loss: 1.385 acc: 0.492\n",
      "\t - Step 105: loss: 1.422 acc: 0.445\n",
      "\t - Step 106: loss: 1.645 acc: 0.391\n",
      "\t - Step 107: loss: 1.484 acc: 0.438\n",
      "\t - Step 108: loss: 1.401 acc: 0.453\n",
      "\t - Step 109: loss: 1.341 acc: 0.500\n",
      "\t - Step 110: loss: 1.513 acc: 0.422\n",
      "\t - Step 111: loss: 1.457 acc: 0.414\n",
      "\t - Step 112: loss: 1.503 acc: 0.438\n",
      "\t - Step 113: loss: 1.377 acc: 0.500\n",
      "\t - Step 114: loss: 1.462 acc: 0.461\n",
      "\t - Step 115: loss: 1.425 acc: 0.484\n",
      "\t - Step 116: loss: 1.496 acc: 0.492\n",
      "\t - Step 117: loss: 1.447 acc: 0.461\n",
      "\t - Step 118: loss: 1.384 acc: 0.453\n",
      "\t - Step 119: loss: 1.417 acc: 0.469\n",
      "\t - Step 120: loss: 1.260 acc: 0.547\n",
      "\t - Step 121: loss: 1.325 acc: 0.508\n",
      "\t - Step 122: loss: 1.140 acc: 0.617\n",
      "\t - Step 123: loss: 1.432 acc: 0.469\n",
      "\t - Step 124: loss: 1.537 acc: 0.430\n",
      "\t - Step 125: loss: 1.456 acc: 0.445\n",
      "\t - Step 126: loss: 1.480 acc: 0.375\n",
      "\t - Step 127: loss: 1.524 acc: 0.477\n",
      "\t - Step 128: loss: 1.284 acc: 0.539\n",
      "\t - Step 129: loss: 1.425 acc: 0.500\n",
      "\t - Step 130: loss: 1.469 acc: 0.438\n",
      "\t - Step 131: loss: 1.367 acc: 0.461\n",
      "\t - Step 132: loss: 1.399 acc: 0.469\n",
      "\t - Step 133: loss: 1.321 acc: 0.523\n",
      "\t - Step 134: loss: 1.316 acc: 0.461\n",
      "\t - Step 135: loss: 1.490 acc: 0.422\n",
      "\t - Step 136: loss: 1.251 acc: 0.555\n",
      "\t - Step 137: loss: 1.428 acc: 0.461\n",
      "\t - Step 138: loss: 1.338 acc: 0.492\n",
      "\t - Step 139: loss: 1.432 acc: 0.422\n",
      "\t - Step 140: loss: 1.452 acc: 0.422\n",
      "\t - Step 141: loss: 1.429 acc: 0.508\n",
      "\t - Step 142: loss: 1.454 acc: 0.461\n",
      "\t - Step 143: loss: 1.540 acc: 0.359\n",
      "\t - Step 144: loss: 1.484 acc: 0.453\n",
      "\t - Step 145: loss: 1.346 acc: 0.430\n",
      "\t - Step 146: loss: 1.359 acc: 0.492\n",
      "\t - Step 147: loss: 1.492 acc: 0.469\n",
      "\t - Step 148: loss: 1.329 acc: 0.477\n",
      "\t - Step 149: loss: 1.316 acc: 0.477\n",
      "\t - Step 150: loss: 1.387 acc: 0.484\n",
      "\t - Step 151: loss: 1.326 acc: 0.445\n",
      "\t - Step 152: loss: 1.432 acc: 0.430\n",
      "\t - Step 153: loss: 1.375 acc: 0.484\n",
      "\t - Step 154: loss: 1.498 acc: 0.445\n",
      "\t - Step 155: loss: 1.437 acc: 0.484\n",
      "\t - Step 156: loss: 1.290 acc: 0.539\n",
      "\t - Step 157: loss: 1.235 acc: 0.523\n",
      "\t - Step 158: loss: 1.446 acc: 0.430\n",
      "\t - Step 159: loss: 1.505 acc: 0.469\n",
      "\t - Step 160: loss: 1.395 acc: 0.445\n",
      "\t - Step 161: loss: 1.257 acc: 0.516\n",
      "\t - Step 162: loss: 1.171 acc: 0.539\n",
      "\t - Step 163: loss: 1.447 acc: 0.445\n",
      "\t - Step 164: loss: 1.509 acc: 0.422\n",
      "\t - Step 165: loss: 1.308 acc: 0.461\n",
      "\t - Step 166: loss: 1.486 acc: 0.438\n",
      "\t - Step 167: loss: 1.483 acc: 0.398\n",
      "\t - Step 168: loss: 1.430 acc: 0.453\n",
      "\t - Step 169: loss: 1.316 acc: 0.516\n",
      "\t - Step 170: loss: 1.320 acc: 0.508\n",
      "\t - Step 171: loss: 1.339 acc: 0.516\n",
      "\t - Step 172: loss: 1.497 acc: 0.398\n",
      "\t - Step 173: loss: 1.282 acc: 0.523\n",
      "\t - Step 174: loss: 1.357 acc: 0.430\n",
      "\t - Step 175: loss: 1.337 acc: 0.477\n",
      "\t - Step 176: loss: 1.356 acc: 0.469\n",
      "\t - Step 177: loss: 1.428 acc: 0.422\n",
      "\t - Step 178: loss: 1.500 acc: 0.453\n",
      "\t - Step 179: loss: 1.404 acc: 0.508\n",
      "\t - Step 180: loss: 1.474 acc: 0.398\n",
      "\t - Step 181: loss: 1.292 acc: 0.547\n",
      "\t - Step 182: loss: 1.276 acc: 0.492\n",
      "\t - Step 183: loss: 1.513 acc: 0.406\n",
      "\t - Step 184: loss: 1.457 acc: 0.508\n",
      "\t - Step 185: loss: 1.416 acc: 0.484\n",
      "\t - Step 186: loss: 1.455 acc: 0.453\n",
      "\t - Step 187: loss: 1.281 acc: 0.477\n",
      "\t - Step 188: loss: 1.368 acc: 0.492\n",
      "\t - Step 189: loss: 1.474 acc: 0.414\n",
      "\t - Step 190: loss: 1.478 acc: 0.430\n",
      "\t - Step 191: loss: 1.390 acc: 0.484\n",
      "\t - Step 192: loss: 1.477 acc: 0.469\n",
      "\t - Step 193: loss: 1.193 acc: 0.586\n",
      "\t - Step 194: loss: 1.310 acc: 0.453\n",
      "\t - Step 195: loss: 1.283 acc: 0.508\n",
      "\t - Step 196: loss: 1.313 acc: 0.508\n",
      "\t - Step 197: loss: 1.368 acc: 0.539\n",
      "\t - Step 198: loss: 1.486 acc: 0.383\n",
      "\t - Step 199: loss: 1.598 acc: 0.383\n",
      "\t - Step 200: loss: 1.443 acc: 0.406\n",
      "\t - Step 201: loss: 1.437 acc: 0.508\n",
      "\t - Step 202: loss: 1.445 acc: 0.477\n",
      "\t - Step 203: loss: 1.450 acc: 0.445\n",
      "\t - Step 204: loss: 1.503 acc: 0.398\n",
      "\t - Step 205: loss: 1.403 acc: 0.539\n",
      "\t - Step 206: loss: 1.446 acc: 0.438\n",
      "\t - Step 207: loss: 1.359 acc: 0.523\n",
      "\t - Step 208: loss: 1.274 acc: 0.508\n",
      "\t - Step 209: loss: 1.379 acc: 0.438\n",
      "\t - Step 210: loss: 1.479 acc: 0.406\n",
      "\t - Step 211: loss: 1.319 acc: 0.555\n",
      "\t - Step 212: loss: 1.374 acc: 0.484\n",
      "\t - Step 213: loss: 1.320 acc: 0.555\n",
      "\t - Step 214: loss: 1.435 acc: 0.492\n",
      "\t - Step 215: loss: 1.453 acc: 0.453\n",
      "\t - Step 216: loss: 1.400 acc: 0.453\n",
      "\t - Step 217: loss: 1.435 acc: 0.477\n",
      "\t - Step 218: loss: 1.336 acc: 0.523\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t - Step 219: loss: 1.470 acc: 0.414\n",
      "\t - Step 220: loss: 1.329 acc: 0.477\n",
      "\t - Step 221: loss: 1.453 acc: 0.453\n",
      "\t - Step 222: loss: 1.258 acc: 0.523\n",
      "\t - Step 223: loss: 1.496 acc: 0.398\n",
      "\t - Step 224: loss: 1.267 acc: 0.539\n",
      "\t - Step 225: loss: 1.376 acc: 0.541\n",
      "- Avg.loss: 1.399  | Avg.acc: 0.471\n",
      "- Avg. val_loss: 1.714  | Avg. val_acc: 0.353\n",
      "Epoch:  6\n",
      "\t - Step 1: loss: 1.273 acc: 0.531\n",
      "\t - Step 2: loss: 1.362 acc: 0.500\n",
      "\t - Step 3: loss: 1.432 acc: 0.422\n",
      "\t - Step 4: loss: 1.439 acc: 0.430\n",
      "\t - Step 5: loss: 1.338 acc: 0.484\n",
      "\t - Step 6: loss: 1.493 acc: 0.406\n",
      "\t - Step 7: loss: 1.415 acc: 0.430\n",
      "\t - Step 8: loss: 1.400 acc: 0.477\n",
      "\t - Step 9: loss: 1.319 acc: 0.477\n",
      "\t - Step 10: loss: 1.321 acc: 0.500\n",
      "\t - Step 11: loss: 1.389 acc: 0.492\n",
      "\t - Step 12: loss: 1.272 acc: 0.547\n",
      "\t - Step 13: loss: 1.318 acc: 0.531\n",
      "\t - Step 14: loss: 1.445 acc: 0.477\n",
      "\t - Step 15: loss: 1.497 acc: 0.398\n",
      "\t - Step 16: loss: 1.280 acc: 0.508\n",
      "\t - Step 17: loss: 1.350 acc: 0.477\n",
      "\t - Step 18: loss: 1.473 acc: 0.383\n",
      "\t - Step 19: loss: 1.285 acc: 0.508\n",
      "\t - Step 20: loss: 1.313 acc: 0.547\n",
      "\t - Step 21: loss: 1.357 acc: 0.484\n",
      "\t - Step 22: loss: 1.299 acc: 0.477\n",
      "\t - Step 23: loss: 1.419 acc: 0.477\n",
      "\t - Step 24: loss: 1.378 acc: 0.477\n",
      "\t - Step 25: loss: 1.218 acc: 0.539\n",
      "\t - Step 26: loss: 1.372 acc: 0.430\n",
      "\t - Step 27: loss: 1.334 acc: 0.508\n",
      "\t - Step 28: loss: 1.312 acc: 0.570\n",
      "\t - Step 29: loss: 1.434 acc: 0.469\n",
      "\t - Step 30: loss: 1.315 acc: 0.555\n",
      "\t - Step 31: loss: 1.353 acc: 0.469\n",
      "\t - Step 32: loss: 1.552 acc: 0.445\n",
      "\t - Step 33: loss: 1.376 acc: 0.469\n",
      "\t - Step 34: loss: 1.310 acc: 0.461\n",
      "\t - Step 35: loss: 1.252 acc: 0.492\n",
      "\t - Step 36: loss: 1.348 acc: 0.484\n",
      "\t - Step 37: loss: 1.260 acc: 0.539\n",
      "\t - Step 38: loss: 1.368 acc: 0.477\n",
      "\t - Step 39: loss: 1.402 acc: 0.438\n",
      "\t - Step 40: loss: 1.240 acc: 0.547\n",
      "\t - Step 41: loss: 1.306 acc: 0.531\n",
      "\t - Step 42: loss: 1.265 acc: 0.555\n",
      "\t - Step 43: loss: 1.311 acc: 0.562\n",
      "\t - Step 44: loss: 1.302 acc: 0.500\n",
      "\t - Step 45: loss: 1.406 acc: 0.461\n",
      "\t - Step 46: loss: 1.338 acc: 0.508\n",
      "\t - Step 47: loss: 1.322 acc: 0.508\n",
      "\t - Step 48: loss: 1.458 acc: 0.438\n",
      "\t - Step 49: loss: 1.330 acc: 0.453\n",
      "\t - Step 50: loss: 1.435 acc: 0.414\n",
      "\t - Step 51: loss: 1.339 acc: 0.531\n",
      "\t - Step 52: loss: 1.403 acc: 0.430\n",
      "\t - Step 53: loss: 1.345 acc: 0.516\n",
      "\t - Step 54: loss: 1.324 acc: 0.555\n",
      "\t - Step 55: loss: 1.451 acc: 0.430\n",
      "\t - Step 56: loss: 1.422 acc: 0.430\n",
      "\t - Step 57: loss: 1.346 acc: 0.484\n",
      "\t - Step 58: loss: 1.391 acc: 0.438\n",
      "\t - Step 59: loss: 1.408 acc: 0.469\n",
      "\t - Step 60: loss: 1.358 acc: 0.461\n",
      "\t - Step 61: loss: 1.354 acc: 0.430\n",
      "\t - Step 62: loss: 1.490 acc: 0.500\n",
      "\t - Step 63: loss: 1.455 acc: 0.445\n",
      "\t - Step 64: loss: 1.401 acc: 0.484\n",
      "\t - Step 65: loss: 1.442 acc: 0.492\n",
      "\t - Step 66: loss: 1.258 acc: 0.516\n",
      "\t - Step 67: loss: 1.560 acc: 0.477\n",
      "\t - Step 68: loss: 1.421 acc: 0.484\n",
      "\t - Step 69: loss: 1.374 acc: 0.438\n",
      "\t - Step 70: loss: 1.328 acc: 0.484\n",
      "\t - Step 71: loss: 1.356 acc: 0.438\n",
      "\t - Step 72: loss: 1.414 acc: 0.484\n",
      "\t - Step 73: loss: 1.307 acc: 0.508\n",
      "\t - Step 74: loss: 1.434 acc: 0.414\n",
      "\t - Step 75: loss: 1.426 acc: 0.453\n",
      "\t - Step 76: loss: 1.239 acc: 0.523\n",
      "\t - Step 77: loss: 1.421 acc: 0.430\n",
      "\t - Step 78: loss: 1.341 acc: 0.430\n",
      "\t - Step 79: loss: 1.330 acc: 0.461\n",
      "\t - Step 80: loss: 1.349 acc: 0.469\n",
      "\t - Step 81: loss: 1.481 acc: 0.445\n",
      "\t - Step 82: loss: 1.179 acc: 0.555\n",
      "\t - Step 83: loss: 1.444 acc: 0.414\n",
      "\t - Step 84: loss: 1.330 acc: 0.469\n",
      "\t - Step 85: loss: 1.255 acc: 0.500\n",
      "\t - Step 86: loss: 1.445 acc: 0.422\n",
      "\t - Step 87: loss: 1.397 acc: 0.484\n",
      "\t - Step 88: loss: 1.255 acc: 0.453\n",
      "\t - Step 89: loss: 1.286 acc: 0.547\n",
      "\t - Step 90: loss: 1.439 acc: 0.430\n",
      "\t - Step 91: loss: 1.311 acc: 0.508\n",
      "\t - Step 92: loss: 1.491 acc: 0.414\n",
      "\t - Step 93: loss: 1.360 acc: 0.500\n",
      "\t - Step 94: loss: 1.357 acc: 0.492\n",
      "\t - Step 95: loss: 1.321 acc: 0.508\n",
      "\t - Step 96: loss: 1.419 acc: 0.492\n",
      "\t - Step 97: loss: 1.328 acc: 0.477\n",
      "\t - Step 98: loss: 1.319 acc: 0.523\n",
      "\t - Step 99: loss: 1.355 acc: 0.469\n",
      "\t - Step 100: loss: 1.391 acc: 0.422\n",
      "\t - Step 101: loss: 1.380 acc: 0.516\n",
      "\t - Step 102: loss: 1.458 acc: 0.430\n",
      "\t - Step 103: loss: 1.290 acc: 0.539\n",
      "\t - Step 104: loss: 1.283 acc: 0.508\n",
      "\t - Step 105: loss: 1.304 acc: 0.492\n",
      "\t - Step 106: loss: 1.352 acc: 0.492\n",
      "\t - Step 107: loss: 1.440 acc: 0.461\n",
      "\t - Step 108: loss: 1.420 acc: 0.484\n",
      "\t - Step 109: loss: 1.357 acc: 0.477\n",
      "\t - Step 110: loss: 1.226 acc: 0.617\n",
      "\t - Step 111: loss: 1.308 acc: 0.492\n",
      "\t - Step 112: loss: 1.288 acc: 0.539\n",
      "\t - Step 113: loss: 1.283 acc: 0.492\n",
      "\t - Step 114: loss: 1.326 acc: 0.500\n",
      "\t - Step 115: loss: 1.449 acc: 0.469\n",
      "\t - Step 116: loss: 1.403 acc: 0.469\n",
      "\t - Step 117: loss: 1.346 acc: 0.516\n",
      "\t - Step 118: loss: 1.382 acc: 0.539\n",
      "\t - Step 119: loss: 1.422 acc: 0.422\n",
      "\t - Step 120: loss: 1.362 acc: 0.398\n",
      "\t - Step 121: loss: 1.421 acc: 0.453\n",
      "\t - Step 122: loss: 1.397 acc: 0.500\n",
      "\t - Step 123: loss: 1.339 acc: 0.555\n",
      "\t - Step 124: loss: 1.356 acc: 0.500\n",
      "\t - Step 125: loss: 1.387 acc: 0.508\n",
      "\t - Step 126: loss: 1.369 acc: 0.469\n",
      "\t - Step 127: loss: 1.359 acc: 0.445\n",
      "\t - Step 128: loss: 1.396 acc: 0.469\n",
      "\t - Step 129: loss: 1.298 acc: 0.461\n",
      "\t - Step 130: loss: 1.400 acc: 0.445\n",
      "\t - Step 131: loss: 1.323 acc: 0.523\n",
      "\t - Step 132: loss: 1.354 acc: 0.477\n",
      "\t - Step 133: loss: 1.502 acc: 0.406\n",
      "\t - Step 134: loss: 1.179 acc: 0.609\n",
      "\t - Step 135: loss: 1.313 acc: 0.492\n",
      "\t - Step 136: loss: 1.567 acc: 0.461\n",
      "\t - Step 137: loss: 1.293 acc: 0.523\n",
      "\t - Step 138: loss: 1.513 acc: 0.461\n",
      "\t - Step 139: loss: 1.287 acc: 0.547\n",
      "\t - Step 140: loss: 1.385 acc: 0.430\n",
      "\t - Step 141: loss: 1.414 acc: 0.398\n",
      "\t - Step 142: loss: 1.254 acc: 0.555\n",
      "\t - Step 143: loss: 1.346 acc: 0.508\n",
      "\t - Step 144: loss: 1.359 acc: 0.469\n",
      "\t - Step 145: loss: 1.289 acc: 0.531\n",
      "\t - Step 146: loss: 1.380 acc: 0.484\n",
      "\t - Step 147: loss: 1.438 acc: 0.484\n",
      "\t - Step 148: loss: 1.375 acc: 0.484\n",
      "\t - Step 149: loss: 1.336 acc: 0.484\n",
      "\t - Step 150: loss: 1.378 acc: 0.461\n",
      "\t - Step 151: loss: 1.355 acc: 0.516\n",
      "\t - Step 152: loss: 1.266 acc: 0.484\n",
      "\t - Step 153: loss: 1.349 acc: 0.492\n",
      "\t - Step 154: loss: 1.396 acc: 0.414\n",
      "\t - Step 155: loss: 1.375 acc: 0.445\n",
      "\t - Step 156: loss: 1.417 acc: 0.430\n",
      "\t - Step 157: loss: 1.467 acc: 0.438\n",
      "\t - Step 158: loss: 1.297 acc: 0.508\n",
      "\t - Step 159: loss: 1.303 acc: 0.500\n",
      "\t - Step 160: loss: 1.395 acc: 0.453\n",
      "\t - Step 161: loss: 1.455 acc: 0.430\n",
      "\t - Step 162: loss: 1.290 acc: 0.555\n",
      "\t - Step 163: loss: 1.474 acc: 0.453\n",
      "\t - Step 164: loss: 1.470 acc: 0.406\n",
      "\t - Step 165: loss: 1.324 acc: 0.469\n",
      "\t - Step 166: loss: 1.461 acc: 0.445\n",
      "\t - Step 167: loss: 1.329 acc: 0.523\n",
      "\t - Step 168: loss: 1.321 acc: 0.508\n",
      "\t - Step 169: loss: 1.311 acc: 0.469\n",
      "\t - Step 170: loss: 1.245 acc: 0.531\n",
      "\t - Step 171: loss: 1.291 acc: 0.523\n",
      "\t - Step 172: loss: 1.299 acc: 0.477\n",
      "\t - Step 173: loss: 1.557 acc: 0.422\n",
      "\t - Step 174: loss: 1.278 acc: 0.508\n",
      "\t - Step 175: loss: 1.380 acc: 0.523\n",
      "\t - Step 176: loss: 1.421 acc: 0.492\n",
      "\t - Step 177: loss: 1.464 acc: 0.469\n",
      "\t - Step 178: loss: 1.428 acc: 0.508\n",
      "\t - Step 179: loss: 1.317 acc: 0.500\n",
      "\t - Step 180: loss: 1.432 acc: 0.414\n",
      "\t - Step 181: loss: 1.385 acc: 0.492\n",
      "\t - Step 182: loss: 1.405 acc: 0.430\n",
      "\t - Step 183: loss: 1.453 acc: 0.453\n",
      "\t - Step 184: loss: 1.391 acc: 0.539\n",
      "\t - Step 185: loss: 1.462 acc: 0.438\n",
      "\t - Step 186: loss: 1.397 acc: 0.508\n",
      "\t - Step 187: loss: 1.552 acc: 0.422\n",
      "\t - Step 188: loss: 1.311 acc: 0.508\n",
      "\t - Step 189: loss: 1.522 acc: 0.359\n",
      "\t - Step 190: loss: 1.329 acc: 0.492\n",
      "\t - Step 191: loss: 1.474 acc: 0.508\n",
      "\t - Step 192: loss: 1.533 acc: 0.406\n",
      "\t - Step 193: loss: 1.437 acc: 0.422\n",
      "\t - Step 194: loss: 1.371 acc: 0.453\n",
      "\t - Step 195: loss: 1.489 acc: 0.438\n",
      "\t - Step 196: loss: 1.380 acc: 0.516\n",
      "\t - Step 197: loss: 1.397 acc: 0.484\n",
      "\t - Step 198: loss: 1.366 acc: 0.461\n",
      "\t - Step 199: loss: 1.409 acc: 0.508\n",
      "\t - Step 200: loss: 1.307 acc: 0.531\n",
      "\t - Step 201: loss: 1.571 acc: 0.438\n",
      "\t - Step 202: loss: 1.387 acc: 0.531\n",
      "\t - Step 203: loss: 1.263 acc: 0.539\n",
      "\t - Step 204: loss: 1.270 acc: 0.508\n",
      "\t - Step 205: loss: 1.362 acc: 0.453\n",
      "\t - Step 206: loss: 1.362 acc: 0.469\n",
      "\t - Step 207: loss: 1.377 acc: 0.422\n",
      "\t - Step 208: loss: 1.332 acc: 0.461\n",
      "\t - Step 209: loss: 1.416 acc: 0.492\n",
      "\t - Step 210: loss: 1.206 acc: 0.516\n",
      "\t - Step 211: loss: 1.437 acc: 0.461\n",
      "\t - Step 212: loss: 1.417 acc: 0.484\n",
      "\t - Step 213: loss: 1.483 acc: 0.445\n",
      "\t - Step 214: loss: 1.425 acc: 0.430\n",
      "\t - Step 215: loss: 1.336 acc: 0.523\n",
      "\t - Step 216: loss: 1.391 acc: 0.461\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t - Step 217: loss: 1.259 acc: 0.531\n",
      "\t - Step 218: loss: 1.353 acc: 0.500\n",
      "\t - Step 219: loss: 1.539 acc: 0.367\n",
      "\t - Step 220: loss: 1.429 acc: 0.453\n",
      "\t - Step 221: loss: 1.590 acc: 0.367\n",
      "\t - Step 222: loss: 1.512 acc: 0.398\n",
      "\t - Step 223: loss: 1.424 acc: 0.453\n",
      "\t - Step 224: loss: 1.385 acc: 0.445\n",
      "\t - Step 225: loss: 1.338 acc: 0.649\n",
      "- Avg.loss: 1.373  | Avg.acc: 0.479\n",
      "- Avg. val_loss: 1.563  | Avg. val_acc: 0.429\n",
      "* Update optimal model\n",
      "Epoch:  7\n",
      "\t - Step 1: loss: 1.369 acc: 0.461\n",
      "\t - Step 2: loss: 1.313 acc: 0.453\n",
      "\t - Step 3: loss: 1.453 acc: 0.422\n",
      "\t - Step 4: loss: 1.376 acc: 0.516\n",
      "\t - Step 5: loss: 1.431 acc: 0.477\n",
      "\t - Step 6: loss: 1.274 acc: 0.523\n",
      "\t - Step 7: loss: 1.252 acc: 0.555\n",
      "\t - Step 8: loss: 1.531 acc: 0.383\n",
      "\t - Step 9: loss: 1.328 acc: 0.445\n",
      "\t - Step 10: loss: 1.256 acc: 0.562\n",
      "\t - Step 11: loss: 1.347 acc: 0.500\n",
      "\t - Step 12: loss: 1.298 acc: 0.508\n",
      "\t - Step 13: loss: 1.415 acc: 0.453\n",
      "\t - Step 14: loss: 1.362 acc: 0.531\n",
      "\t - Step 15: loss: 1.354 acc: 0.484\n",
      "\t - Step 16: loss: 1.279 acc: 0.531\n",
      "\t - Step 17: loss: 1.449 acc: 0.438\n",
      "\t - Step 18: loss: 1.353 acc: 0.461\n",
      "\t - Step 19: loss: 1.461 acc: 0.453\n",
      "\t - Step 20: loss: 1.156 acc: 0.594\n",
      "\t - Step 21: loss: 1.387 acc: 0.477\n",
      "\t - Step 22: loss: 1.275 acc: 0.508\n",
      "\t - Step 23: loss: 1.259 acc: 0.547\n",
      "\t - Step 24: loss: 1.482 acc: 0.477\n",
      "\t - Step 25: loss: 1.288 acc: 0.516\n",
      "\t - Step 26: loss: 1.500 acc: 0.430\n",
      "\t - Step 27: loss: 1.514 acc: 0.445\n",
      "\t - Step 28: loss: 1.260 acc: 0.539\n",
      "\t - Step 29: loss: 1.275 acc: 0.461\n",
      "\t - Step 30: loss: 1.235 acc: 0.547\n",
      "\t - Step 31: loss: 1.396 acc: 0.469\n",
      "\t - Step 32: loss: 1.279 acc: 0.453\n",
      "\t - Step 33: loss: 1.525 acc: 0.438\n",
      "\t - Step 34: loss: 1.352 acc: 0.461\n",
      "\t - Step 35: loss: 1.290 acc: 0.539\n",
      "\t - Step 36: loss: 1.321 acc: 0.469\n",
      "\t - Step 37: loss: 1.397 acc: 0.414\n",
      "\t - Step 38: loss: 1.417 acc: 0.461\n",
      "\t - Step 39: loss: 1.338 acc: 0.438\n",
      "\t - Step 40: loss: 1.353 acc: 0.445\n",
      "\t - Step 41: loss: 1.289 acc: 0.523\n",
      "\t - Step 42: loss: 1.435 acc: 0.461\n",
      "\t - Step 43: loss: 1.295 acc: 0.539\n",
      "\t - Step 44: loss: 1.300 acc: 0.562\n",
      "\t - Step 45: loss: 1.319 acc: 0.508\n",
      "\t - Step 46: loss: 1.276 acc: 0.578\n",
      "\t - Step 47: loss: 1.243 acc: 0.531\n",
      "\t - Step 48: loss: 1.352 acc: 0.508\n",
      "\t - Step 49: loss: 1.288 acc: 0.516\n",
      "\t - Step 50: loss: 1.518 acc: 0.453\n",
      "\t - Step 51: loss: 1.327 acc: 0.523\n",
      "\t - Step 52: loss: 1.353 acc: 0.461\n",
      "\t - Step 53: loss: 1.478 acc: 0.430\n",
      "\t - Step 54: loss: 1.340 acc: 0.547\n",
      "\t - Step 55: loss: 1.456 acc: 0.453\n",
      "\t - Step 56: loss: 1.304 acc: 0.469\n",
      "\t - Step 57: loss: 1.373 acc: 0.484\n",
      "\t - Step 58: loss: 1.277 acc: 0.586\n",
      "\t - Step 59: loss: 1.286 acc: 0.492\n",
      "\t - Step 60: loss: 1.358 acc: 0.461\n",
      "\t - Step 61: loss: 1.333 acc: 0.477\n",
      "\t - Step 62: loss: 1.345 acc: 0.453\n",
      "\t - Step 63: loss: 1.537 acc: 0.430\n",
      "\t - Step 64: loss: 1.257 acc: 0.539\n",
      "\t - Step 65: loss: 1.286 acc: 0.555\n",
      "\t - Step 66: loss: 1.272 acc: 0.570\n",
      "\t - Step 67: loss: 1.341 acc: 0.508\n",
      "\t - Step 68: loss: 1.335 acc: 0.523\n",
      "\t - Step 69: loss: 1.269 acc: 0.539\n",
      "\t - Step 70: loss: 1.302 acc: 0.500\n",
      "\t - Step 71: loss: 1.477 acc: 0.445\n",
      "\t - Step 72: loss: 1.301 acc: 0.578\n",
      "\t - Step 73: loss: 1.346 acc: 0.484\n",
      "\t - Step 74: loss: 1.295 acc: 0.516\n",
      "\t - Step 75: loss: 1.352 acc: 0.523\n",
      "\t - Step 76: loss: 1.345 acc: 0.477\n",
      "\t - Step 77: loss: 1.389 acc: 0.516\n",
      "\t - Step 78: loss: 1.367 acc: 0.484\n",
      "\t - Step 79: loss: 1.362 acc: 0.492\n",
      "\t - Step 80: loss: 1.394 acc: 0.500\n",
      "\t - Step 81: loss: 1.447 acc: 0.453\n",
      "\t - Step 82: loss: 1.374 acc: 0.453\n",
      "\t - Step 83: loss: 1.498 acc: 0.375\n",
      "\t - Step 84: loss: 1.370 acc: 0.445\n",
      "\t - Step 85: loss: 1.316 acc: 0.539\n",
      "\t - Step 86: loss: 1.433 acc: 0.508\n",
      "\t - Step 87: loss: 1.641 acc: 0.406\n",
      "\t - Step 88: loss: 1.375 acc: 0.484\n",
      "\t - Step 89: loss: 1.517 acc: 0.453\n",
      "\t - Step 90: loss: 1.404 acc: 0.430\n",
      "\t - Step 91: loss: 1.400 acc: 0.430\n",
      "\t - Step 92: loss: 1.396 acc: 0.398\n",
      "\t - Step 93: loss: 1.336 acc: 0.562\n",
      "\t - Step 94: loss: 1.361 acc: 0.539\n",
      "\t - Step 95: loss: 1.281 acc: 0.555\n",
      "\t - Step 96: loss: 1.314 acc: 0.500\n",
      "\t - Step 97: loss: 1.289 acc: 0.516\n",
      "\t - Step 98: loss: 1.375 acc: 0.453\n",
      "\t - Step 99: loss: 1.326 acc: 0.523\n",
      "\t - Step 100: loss: 1.514 acc: 0.391\n",
      "\t - Step 101: loss: 1.510 acc: 0.414\n",
      "\t - Step 102: loss: 1.299 acc: 0.430\n",
      "\t - Step 103: loss: 1.413 acc: 0.461\n",
      "\t - Step 104: loss: 1.386 acc: 0.461\n",
      "\t - Step 105: loss: 1.260 acc: 0.508\n",
      "\t - Step 106: loss: 1.365 acc: 0.469\n",
      "\t - Step 107: loss: 1.292 acc: 0.516\n",
      "\t - Step 108: loss: 1.265 acc: 0.547\n",
      "\t - Step 109: loss: 1.524 acc: 0.383\n",
      "\t - Step 110: loss: 1.297 acc: 0.516\n",
      "\t - Step 111: loss: 1.302 acc: 0.492\n",
      "\t - Step 112: loss: 1.231 acc: 0.523\n",
      "\t - Step 113: loss: 1.370 acc: 0.508\n",
      "\t - Step 114: loss: 1.422 acc: 0.461\n",
      "\t - Step 115: loss: 1.170 acc: 0.539\n",
      "\t - Step 116: loss: 1.406 acc: 0.484\n",
      "\t - Step 117: loss: 1.402 acc: 0.414\n",
      "\t - Step 118: loss: 1.431 acc: 0.430\n",
      "\t - Step 119: loss: 1.458 acc: 0.445\n",
      "\t - Step 120: loss: 1.300 acc: 0.492\n",
      "\t - Step 121: loss: 1.296 acc: 0.547\n",
      "\t - Step 122: loss: 1.236 acc: 0.523\n",
      "\t - Step 123: loss: 1.258 acc: 0.539\n",
      "\t - Step 124: loss: 1.395 acc: 0.430\n",
      "\t - Step 125: loss: 1.307 acc: 0.477\n",
      "\t - Step 126: loss: 1.471 acc: 0.414\n",
      "\t - Step 127: loss: 1.206 acc: 0.562\n",
      "\t - Step 128: loss: 1.436 acc: 0.430\n",
      "\t - Step 129: loss: 1.261 acc: 0.539\n",
      "\t - Step 130: loss: 1.438 acc: 0.422\n",
      "\t - Step 131: loss: 1.431 acc: 0.445\n",
      "\t - Step 132: loss: 1.306 acc: 0.500\n",
      "\t - Step 133: loss: 1.200 acc: 0.547\n",
      "\t - Step 134: loss: 1.318 acc: 0.531\n",
      "\t - Step 135: loss: 1.367 acc: 0.508\n",
      "\t - Step 136: loss: 1.252 acc: 0.523\n",
      "\t - Step 137: loss: 1.399 acc: 0.500\n",
      "\t - Step 138: loss: 1.411 acc: 0.492\n",
      "\t - Step 139: loss: 1.545 acc: 0.453\n",
      "\t - Step 140: loss: 1.345 acc: 0.477\n",
      "\t - Step 141: loss: 1.205 acc: 0.609\n",
      "\t - Step 142: loss: 1.343 acc: 0.492\n",
      "\t - Step 143: loss: 1.441 acc: 0.445\n",
      "\t - Step 144: loss: 1.369 acc: 0.461\n",
      "\t - Step 145: loss: 1.351 acc: 0.461\n",
      "\t - Step 146: loss: 1.562 acc: 0.461\n",
      "\t - Step 147: loss: 1.313 acc: 0.461\n",
      "\t - Step 148: loss: 1.434 acc: 0.438\n",
      "\t - Step 149: loss: 1.368 acc: 0.500\n",
      "\t - Step 150: loss: 1.303 acc: 0.508\n",
      "\t - Step 151: loss: 1.358 acc: 0.500\n",
      "\t - Step 152: loss: 1.415 acc: 0.406\n",
      "\t - Step 153: loss: 1.362 acc: 0.492\n",
      "\t - Step 154: loss: 1.475 acc: 0.445\n",
      "\t - Step 155: loss: 1.451 acc: 0.539\n",
      "\t - Step 156: loss: 1.372 acc: 0.492\n",
      "\t - Step 157: loss: 1.413 acc: 0.469\n",
      "\t - Step 158: loss: 1.206 acc: 0.539\n",
      "\t - Step 159: loss: 1.422 acc: 0.484\n",
      "\t - Step 160: loss: 1.521 acc: 0.406\n",
      "\t - Step 161: loss: 1.334 acc: 0.484\n",
      "\t - Step 162: loss: 1.338 acc: 0.508\n",
      "\t - Step 163: loss: 1.335 acc: 0.461\n",
      "\t - Step 164: loss: 1.229 acc: 0.523\n",
      "\t - Step 165: loss: 1.356 acc: 0.438\n",
      "\t - Step 166: loss: 1.425 acc: 0.469\n",
      "\t - Step 167: loss: 1.245 acc: 0.547\n",
      "\t - Step 168: loss: 1.209 acc: 0.531\n",
      "\t - Step 169: loss: 1.257 acc: 0.547\n",
      "\t - Step 170: loss: 1.355 acc: 0.484\n",
      "\t - Step 171: loss: 1.328 acc: 0.484\n",
      "\t - Step 172: loss: 1.285 acc: 0.500\n",
      "\t - Step 173: loss: 1.319 acc: 0.492\n",
      "\t - Step 174: loss: 1.366 acc: 0.516\n",
      "\t - Step 175: loss: 1.419 acc: 0.461\n",
      "\t - Step 176: loss: 1.236 acc: 0.547\n",
      "\t - Step 177: loss: 1.420 acc: 0.484\n",
      "\t - Step 178: loss: 1.421 acc: 0.477\n",
      "\t - Step 179: loss: 1.417 acc: 0.492\n",
      "\t - Step 180: loss: 1.510 acc: 0.391\n",
      "\t - Step 181: loss: 1.302 acc: 0.477\n",
      "\t - Step 182: loss: 1.322 acc: 0.477\n",
      "\t - Step 183: loss: 1.308 acc: 0.531\n",
      "\t - Step 184: loss: 1.375 acc: 0.508\n",
      "\t - Step 185: loss: 1.417 acc: 0.516\n",
      "\t - Step 186: loss: 1.467 acc: 0.461\n",
      "\t - Step 187: loss: 1.274 acc: 0.500\n",
      "\t - Step 188: loss: 1.342 acc: 0.523\n",
      "\t - Step 189: loss: 1.235 acc: 0.500\n",
      "\t - Step 190: loss: 1.308 acc: 0.430\n",
      "\t - Step 191: loss: 1.249 acc: 0.508\n",
      "\t - Step 192: loss: 1.371 acc: 0.461\n",
      "\t - Step 193: loss: 1.336 acc: 0.469\n",
      "\t - Step 194: loss: 1.424 acc: 0.422\n",
      "\t - Step 195: loss: 1.452 acc: 0.414\n",
      "\t - Step 196: loss: 1.422 acc: 0.438\n",
      "\t - Step 197: loss: 1.382 acc: 0.477\n",
      "\t - Step 198: loss: 1.341 acc: 0.508\n",
      "\t - Step 199: loss: 1.331 acc: 0.500\n",
      "\t - Step 200: loss: 1.385 acc: 0.453\n",
      "\t - Step 201: loss: 1.378 acc: 0.438\n",
      "\t - Step 202: loss: 1.385 acc: 0.500\n",
      "\t - Step 203: loss: 1.342 acc: 0.500\n",
      "\t - Step 204: loss: 1.388 acc: 0.492\n",
      "\t - Step 205: loss: 1.235 acc: 0.516\n",
      "\t - Step 206: loss: 1.444 acc: 0.477\n",
      "\t - Step 207: loss: 1.458 acc: 0.438\n",
      "\t - Step 208: loss: 1.385 acc: 0.484\n",
      "\t - Step 209: loss: 1.442 acc: 0.422\n",
      "\t - Step 210: loss: 1.371 acc: 0.484\n",
      "\t - Step 211: loss: 1.328 acc: 0.508\n",
      "\t - Step 212: loss: 1.334 acc: 0.500\n",
      "\t - Step 213: loss: 1.463 acc: 0.477\n",
      "\t - Step 214: loss: 1.453 acc: 0.406\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t - Step 215: loss: 1.348 acc: 0.523\n",
      "\t - Step 216: loss: 1.405 acc: 0.461\n",
      "\t - Step 217: loss: 1.356 acc: 0.461\n",
      "\t - Step 218: loss: 1.287 acc: 0.547\n",
      "\t - Step 219: loss: 1.418 acc: 0.500\n",
      "\t - Step 220: loss: 1.368 acc: 0.492\n",
      "\t - Step 221: loss: 1.294 acc: 0.453\n",
      "\t - Step 222: loss: 1.495 acc: 0.469\n",
      "\t - Step 223: loss: 1.451 acc: 0.461\n",
      "\t - Step 224: loss: 1.380 acc: 0.492\n",
      "\t - Step 225: loss: 1.447 acc: 0.459\n",
      "- Avg.loss: 1.360  | Avg.acc: 0.485\n",
      "- Avg. val_loss: 1.642  | Avg. val_acc: 0.389\n",
      "Epoch:  8\n",
      "\t - Step 1: loss: 1.308 acc: 0.453\n",
      "\t - Step 2: loss: 1.584 acc: 0.398\n",
      "\t - Step 3: loss: 1.231 acc: 0.555\n",
      "\t - Step 4: loss: 1.416 acc: 0.438\n",
      "\t - Step 5: loss: 1.275 acc: 0.461\n",
      "\t - Step 6: loss: 1.269 acc: 0.523\n",
      "\t - Step 7: loss: 1.261 acc: 0.500\n",
      "\t - Step 8: loss: 1.271 acc: 0.547\n",
      "\t - Step 9: loss: 1.340 acc: 0.547\n",
      "\t - Step 10: loss: 1.391 acc: 0.445\n",
      "\t - Step 11: loss: 1.252 acc: 0.562\n",
      "\t - Step 12: loss: 1.335 acc: 0.508\n",
      "\t - Step 13: loss: 1.439 acc: 0.406\n",
      "\t - Step 14: loss: 1.294 acc: 0.492\n",
      "\t - Step 15: loss: 1.286 acc: 0.516\n",
      "\t - Step 16: loss: 1.333 acc: 0.508\n",
      "\t - Step 17: loss: 1.309 acc: 0.516\n",
      "\t - Step 18: loss: 1.471 acc: 0.484\n",
      "\t - Step 19: loss: 1.246 acc: 0.516\n",
      "\t - Step 20: loss: 1.329 acc: 0.477\n",
      "\t - Step 21: loss: 1.391 acc: 0.492\n",
      "\t - Step 22: loss: 1.438 acc: 0.430\n",
      "\t - Step 23: loss: 1.224 acc: 0.578\n",
      "\t - Step 24: loss: 1.293 acc: 0.461\n",
      "\t - Step 25: loss: 1.407 acc: 0.445\n",
      "\t - Step 26: loss: 1.506 acc: 0.406\n",
      "\t - Step 27: loss: 1.331 acc: 0.461\n",
      "\t - Step 28: loss: 1.372 acc: 0.461\n",
      "\t - Step 29: loss: 1.339 acc: 0.453\n",
      "\t - Step 30: loss: 1.252 acc: 0.500\n",
      "\t - Step 31: loss: 1.347 acc: 0.422\n",
      "\t - Step 32: loss: 1.248 acc: 0.531\n",
      "\t - Step 33: loss: 1.401 acc: 0.492\n",
      "\t - Step 34: loss: 1.295 acc: 0.523\n",
      "\t - Step 35: loss: 1.275 acc: 0.492\n",
      "\t - Step 36: loss: 1.321 acc: 0.516\n",
      "\t - Step 37: loss: 1.353 acc: 0.453\n",
      "\t - Step 38: loss: 1.225 acc: 0.500\n",
      "\t - Step 39: loss: 1.364 acc: 0.500\n",
      "\t - Step 40: loss: 1.223 acc: 0.562\n",
      "\t - Step 41: loss: 1.369 acc: 0.477\n",
      "\t - Step 42: loss: 1.196 acc: 0.578\n",
      "\t - Step 43: loss: 1.506 acc: 0.430\n",
      "\t - Step 44: loss: 1.450 acc: 0.516\n",
      "\t - Step 45: loss: 1.538 acc: 0.414\n",
      "\t - Step 46: loss: 1.367 acc: 0.484\n",
      "\t - Step 47: loss: 1.180 acc: 0.562\n",
      "\t - Step 48: loss: 1.488 acc: 0.430\n",
      "\t - Step 49: loss: 1.385 acc: 0.477\n",
      "\t - Step 50: loss: 1.288 acc: 0.523\n",
      "\t - Step 51: loss: 1.417 acc: 0.445\n",
      "\t - Step 52: loss: 1.324 acc: 0.539\n",
      "\t - Step 53: loss: 1.303 acc: 0.508\n",
      "\t - Step 54: loss: 1.319 acc: 0.477\n",
      "\t - Step 55: loss: 1.209 acc: 0.570\n",
      "\t - Step 56: loss: 1.430 acc: 0.484\n",
      "\t - Step 57: loss: 1.413 acc: 0.461\n",
      "\t - Step 58: loss: 1.280 acc: 0.570\n",
      "\t - Step 59: loss: 1.253 acc: 0.531\n",
      "\t - Step 60: loss: 1.338 acc: 0.438\n",
      "\t - Step 61: loss: 1.266 acc: 0.539\n",
      "\t - Step 62: loss: 1.318 acc: 0.523\n",
      "\t - Step 63: loss: 1.434 acc: 0.430\n",
      "\t - Step 64: loss: 1.389 acc: 0.453\n",
      "\t - Step 65: loss: 1.352 acc: 0.461\n",
      "\t - Step 66: loss: 1.288 acc: 0.484\n",
      "\t - Step 67: loss: 1.403 acc: 0.492\n",
      "\t - Step 68: loss: 1.244 acc: 0.492\n",
      "\t - Step 69: loss: 1.288 acc: 0.492\n",
      "\t - Step 70: loss: 1.344 acc: 0.414\n",
      "\t - Step 71: loss: 1.339 acc: 0.508\n",
      "\t - Step 72: loss: 1.380 acc: 0.477\n",
      "\t - Step 73: loss: 1.276 acc: 0.516\n",
      "\t - Step 74: loss: 1.326 acc: 0.484\n",
      "\t - Step 75: loss: 1.395 acc: 0.445\n",
      "\t - Step 76: loss: 1.335 acc: 0.484\n",
      "\t - Step 77: loss: 1.439 acc: 0.492\n",
      "\t - Step 78: loss: 1.247 acc: 0.531\n",
      "\t - Step 79: loss: 1.233 acc: 0.531\n",
      "\t - Step 80: loss: 1.386 acc: 0.477\n",
      "\t - Step 81: loss: 1.244 acc: 0.500\n",
      "\t - Step 82: loss: 1.403 acc: 0.484\n",
      "\t - Step 83: loss: 1.288 acc: 0.516\n",
      "\t - Step 84: loss: 1.312 acc: 0.500\n",
      "\t - Step 85: loss: 1.448 acc: 0.492\n",
      "\t - Step 86: loss: 1.263 acc: 0.523\n",
      "\t - Step 87: loss: 1.344 acc: 0.445\n",
      "\t - Step 88: loss: 1.341 acc: 0.484\n",
      "\t - Step 89: loss: 1.168 acc: 0.539\n",
      "\t - Step 90: loss: 1.422 acc: 0.453\n",
      "\t - Step 91: loss: 1.383 acc: 0.484\n",
      "\t - Step 92: loss: 1.311 acc: 0.469\n",
      "\t - Step 93: loss: 1.323 acc: 0.492\n",
      "\t - Step 94: loss: 1.267 acc: 0.508\n",
      "\t - Step 95: loss: 1.312 acc: 0.445\n",
      "\t - Step 96: loss: 1.220 acc: 0.594\n",
      "\t - Step 97: loss: 1.404 acc: 0.445\n",
      "\t - Step 98: loss: 1.392 acc: 0.453\n",
      "\t - Step 99: loss: 1.602 acc: 0.359\n",
      "\t - Step 100: loss: 1.374 acc: 0.508\n",
      "\t - Step 101: loss: 1.315 acc: 0.477\n",
      "\t - Step 102: loss: 1.288 acc: 0.484\n",
      "\t - Step 103: loss: 1.217 acc: 0.602\n",
      "\t - Step 104: loss: 1.286 acc: 0.547\n",
      "\t - Step 105: loss: 1.250 acc: 0.555\n",
      "\t - Step 106: loss: 1.326 acc: 0.469\n",
      "\t - Step 107: loss: 1.348 acc: 0.516\n",
      "\t - Step 108: loss: 1.399 acc: 0.500\n",
      "\t - Step 109: loss: 1.277 acc: 0.531\n",
      "\t - Step 110: loss: 1.304 acc: 0.508\n",
      "\t - Step 111: loss: 1.316 acc: 0.570\n",
      "\t - Step 112: loss: 1.326 acc: 0.500\n",
      "\t - Step 113: loss: 1.411 acc: 0.453\n",
      "\t - Step 114: loss: 1.258 acc: 0.531\n",
      "\t - Step 115: loss: 1.449 acc: 0.445\n",
      "\t - Step 116: loss: 1.395 acc: 0.516\n",
      "\t - Step 117: loss: 1.234 acc: 0.578\n",
      "\t - Step 118: loss: 1.372 acc: 0.469\n",
      "\t - Step 119: loss: 1.362 acc: 0.492\n",
      "\t - Step 120: loss: 1.454 acc: 0.438\n",
      "\t - Step 121: loss: 1.504 acc: 0.430\n",
      "\t - Step 122: loss: 1.336 acc: 0.500\n",
      "\t - Step 123: loss: 1.552 acc: 0.414\n",
      "\t - Step 124: loss: 1.401 acc: 0.453\n",
      "\t - Step 125: loss: 1.252 acc: 0.516\n",
      "\t - Step 126: loss: 1.260 acc: 0.531\n",
      "\t - Step 127: loss: 1.502 acc: 0.391\n",
      "\t - Step 128: loss: 1.298 acc: 0.547\n",
      "\t - Step 129: loss: 1.344 acc: 0.430\n",
      "\t - Step 130: loss: 1.311 acc: 0.500\n",
      "\t - Step 131: loss: 1.496 acc: 0.461\n",
      "\t - Step 132: loss: 1.485 acc: 0.422\n",
      "\t - Step 133: loss: 1.291 acc: 0.523\n",
      "\t - Step 134: loss: 1.358 acc: 0.508\n",
      "\t - Step 135: loss: 1.362 acc: 0.477\n",
      "\t - Step 136: loss: 1.329 acc: 0.516\n",
      "\t - Step 137: loss: 1.353 acc: 0.469\n",
      "\t - Step 138: loss: 1.312 acc: 0.531\n",
      "\t - Step 139: loss: 1.405 acc: 0.469\n",
      "\t - Step 140: loss: 1.299 acc: 0.555\n",
      "\t - Step 141: loss: 1.380 acc: 0.516\n",
      "\t - Step 142: loss: 1.281 acc: 0.508\n",
      "\t - Step 143: loss: 1.327 acc: 0.453\n",
      "\t - Step 144: loss: 1.432 acc: 0.430\n",
      "\t - Step 145: loss: 1.364 acc: 0.516\n",
      "\t - Step 146: loss: 1.240 acc: 0.570\n",
      "\t - Step 147: loss: 1.330 acc: 0.438\n",
      "\t - Step 148: loss: 1.200 acc: 0.578\n",
      "\t - Step 149: loss: 1.321 acc: 0.500\n",
      "\t - Step 150: loss: 1.326 acc: 0.500\n",
      "\t - Step 151: loss: 1.233 acc: 0.562\n",
      "\t - Step 152: loss: 1.201 acc: 0.539\n",
      "\t - Step 153: loss: 1.298 acc: 0.523\n",
      "\t - Step 154: loss: 1.367 acc: 0.492\n",
      "\t - Step 155: loss: 1.238 acc: 0.570\n",
      "\t - Step 156: loss: 1.315 acc: 0.477\n",
      "\t - Step 157: loss: 1.426 acc: 0.508\n",
      "\t - Step 158: loss: 1.316 acc: 0.477\n",
      "\t - Step 159: loss: 1.212 acc: 0.516\n",
      "\t - Step 160: loss: 1.345 acc: 0.516\n",
      "\t - Step 161: loss: 1.290 acc: 0.531\n",
      "\t - Step 162: loss: 1.148 acc: 0.570\n",
      "\t - Step 163: loss: 1.474 acc: 0.414\n",
      "\t - Step 164: loss: 1.337 acc: 0.461\n",
      "\t - Step 165: loss: 1.362 acc: 0.492\n",
      "\t - Step 166: loss: 1.329 acc: 0.508\n",
      "\t - Step 167: loss: 1.361 acc: 0.469\n",
      "\t - Step 168: loss: 1.445 acc: 0.430\n",
      "\t - Step 169: loss: 1.491 acc: 0.414\n",
      "\t - Step 170: loss: 1.398 acc: 0.430\n",
      "\t - Step 171: loss: 1.358 acc: 0.469\n",
      "\t - Step 172: loss: 1.346 acc: 0.453\n",
      "\t - Step 173: loss: 1.377 acc: 0.469\n",
      "\t - Step 174: loss: 1.401 acc: 0.516\n",
      "\t - Step 175: loss: 1.327 acc: 0.516\n",
      "\t - Step 176: loss: 1.391 acc: 0.453\n",
      "\t - Step 177: loss: 1.367 acc: 0.508\n",
      "\t - Step 178: loss: 1.287 acc: 0.578\n",
      "\t - Step 179: loss: 1.331 acc: 0.547\n",
      "\t - Step 180: loss: 1.331 acc: 0.500\n",
      "\t - Step 181: loss: 1.365 acc: 0.516\n",
      "\t - Step 182: loss: 1.362 acc: 0.547\n",
      "\t - Step 183: loss: 1.265 acc: 0.523\n",
      "\t - Step 184: loss: 1.206 acc: 0.516\n",
      "\t - Step 185: loss: 1.318 acc: 0.523\n",
      "\t - Step 186: loss: 1.388 acc: 0.492\n",
      "\t - Step 187: loss: 1.434 acc: 0.492\n",
      "\t - Step 188: loss: 1.437 acc: 0.461\n",
      "\t - Step 189: loss: 1.428 acc: 0.453\n",
      "\t - Step 190: loss: 1.286 acc: 0.562\n",
      "\t - Step 191: loss: 1.422 acc: 0.422\n",
      "\t - Step 192: loss: 1.354 acc: 0.461\n",
      "\t - Step 193: loss: 1.257 acc: 0.531\n",
      "\t - Step 194: loss: 1.243 acc: 0.562\n",
      "\t - Step 195: loss: 1.459 acc: 0.406\n",
      "\t - Step 196: loss: 1.239 acc: 0.570\n",
      "\t - Step 197: loss: 1.324 acc: 0.516\n",
      "\t - Step 198: loss: 1.492 acc: 0.445\n",
      "\t - Step 199: loss: 1.329 acc: 0.453\n",
      "\t - Step 200: loss: 1.383 acc: 0.430\n",
      "\t - Step 201: loss: 1.340 acc: 0.531\n",
      "\t - Step 202: loss: 1.457 acc: 0.461\n",
      "\t - Step 203: loss: 1.216 acc: 0.500\n",
      "\t - Step 204: loss: 1.275 acc: 0.516\n",
      "\t - Step 205: loss: 1.170 acc: 0.617\n",
      "\t - Step 206: loss: 1.358 acc: 0.477\n",
      "\t - Step 207: loss: 1.331 acc: 0.461\n",
      "\t - Step 208: loss: 1.389 acc: 0.492\n",
      "\t - Step 209: loss: 1.450 acc: 0.445\n",
      "\t - Step 210: loss: 1.288 acc: 0.477\n",
      "\t - Step 211: loss: 1.323 acc: 0.539\n",
      "\t - Step 212: loss: 1.391 acc: 0.422\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t - Step 213: loss: 1.436 acc: 0.477\n",
      "\t - Step 214: loss: 1.464 acc: 0.469\n",
      "\t - Step 215: loss: 1.421 acc: 0.469\n",
      "\t - Step 216: loss: 1.371 acc: 0.484\n",
      "\t - Step 217: loss: 1.460 acc: 0.422\n",
      "\t - Step 218: loss: 1.336 acc: 0.484\n",
      "\t - Step 219: loss: 1.295 acc: 0.500\n",
      "\t - Step 220: loss: 1.334 acc: 0.492\n",
      "\t - Step 221: loss: 1.378 acc: 0.500\n",
      "\t - Step 222: loss: 1.394 acc: 0.477\n",
      "\t - Step 223: loss: 1.248 acc: 0.539\n",
      "\t - Step 224: loss: 1.298 acc: 0.461\n",
      "\t - Step 225: loss: 1.318 acc: 0.432\n",
      "- Avg.loss: 1.342  | Avg.acc: 0.492\n",
      "- Avg. val_loss: 1.529  | Avg. val_acc: 0.424\n",
      "Epoch:  9\n",
      "\t - Step 1: loss: 1.370 acc: 0.461\n",
      "\t - Step 2: loss: 1.363 acc: 0.484\n",
      "\t - Step 3: loss: 1.250 acc: 0.531\n",
      "\t - Step 4: loss: 1.386 acc: 0.500\n",
      "\t - Step 5: loss: 1.139 acc: 0.570\n",
      "\t - Step 6: loss: 1.304 acc: 0.508\n",
      "\t - Step 7: loss: 1.231 acc: 0.555\n",
      "\t - Step 8: loss: 1.445 acc: 0.414\n",
      "\t - Step 9: loss: 1.362 acc: 0.523\n",
      "\t - Step 10: loss: 1.153 acc: 0.586\n",
      "\t - Step 11: loss: 1.225 acc: 0.555\n",
      "\t - Step 12: loss: 1.342 acc: 0.539\n",
      "\t - Step 13: loss: 1.180 acc: 0.539\n",
      "\t - Step 14: loss: 1.257 acc: 0.562\n",
      "\t - Step 15: loss: 1.291 acc: 0.484\n",
      "\t - Step 16: loss: 1.263 acc: 0.484\n",
      "\t - Step 17: loss: 1.284 acc: 0.508\n",
      "\t - Step 18: loss: 1.291 acc: 0.508\n",
      "\t - Step 19: loss: 1.261 acc: 0.539\n",
      "\t - Step 20: loss: 1.374 acc: 0.516\n",
      "\t - Step 21: loss: 1.256 acc: 0.531\n",
      "\t - Step 22: loss: 1.447 acc: 0.523\n",
      "\t - Step 23: loss: 1.342 acc: 0.500\n",
      "\t - Step 24: loss: 1.380 acc: 0.492\n",
      "\t - Step 25: loss: 1.309 acc: 0.531\n",
      "\t - Step 26: loss: 1.280 acc: 0.508\n",
      "\t - Step 27: loss: 1.317 acc: 0.484\n",
      "\t - Step 28: loss: 1.246 acc: 0.531\n",
      "\t - Step 29: loss: 1.240 acc: 0.578\n",
      "\t - Step 30: loss: 1.341 acc: 0.523\n",
      "\t - Step 31: loss: 1.318 acc: 0.539\n",
      "\t - Step 32: loss: 1.313 acc: 0.461\n",
      "\t - Step 33: loss: 1.268 acc: 0.508\n",
      "\t - Step 34: loss: 1.475 acc: 0.422\n",
      "\t - Step 35: loss: 1.348 acc: 0.469\n",
      "\t - Step 36: loss: 1.332 acc: 0.539\n",
      "\t - Step 37: loss: 1.256 acc: 0.539\n",
      "\t - Step 38: loss: 1.302 acc: 0.555\n",
      "\t - Step 39: loss: 1.477 acc: 0.445\n",
      "\t - Step 40: loss: 1.293 acc: 0.508\n",
      "\t - Step 41: loss: 1.372 acc: 0.469\n",
      "\t - Step 42: loss: 1.232 acc: 0.531\n",
      "\t - Step 43: loss: 1.431 acc: 0.484\n",
      "\t - Step 44: loss: 1.442 acc: 0.430\n",
      "\t - Step 45: loss: 1.258 acc: 0.508\n",
      "\t - Step 46: loss: 1.279 acc: 0.539\n",
      "\t - Step 47: loss: 1.272 acc: 0.500\n",
      "\t - Step 48: loss: 1.299 acc: 0.508\n",
      "\t - Step 49: loss: 1.345 acc: 0.523\n",
      "\t - Step 50: loss: 1.361 acc: 0.500\n",
      "\t - Step 51: loss: 1.311 acc: 0.469\n",
      "\t - Step 52: loss: 1.129 acc: 0.547\n",
      "\t - Step 53: loss: 1.334 acc: 0.508\n",
      "\t - Step 54: loss: 1.241 acc: 0.570\n",
      "\t - Step 55: loss: 1.269 acc: 0.492\n",
      "\t - Step 56: loss: 1.261 acc: 0.516\n",
      "\t - Step 57: loss: 1.420 acc: 0.500\n",
      "\t - Step 58: loss: 1.370 acc: 0.453\n",
      "\t - Step 59: loss: 1.429 acc: 0.477\n",
      "\t - Step 60: loss: 1.281 acc: 0.555\n",
      "\t - Step 61: loss: 1.371 acc: 0.484\n",
      "\t - Step 62: loss: 1.415 acc: 0.484\n",
      "\t - Step 63: loss: 1.287 acc: 0.500\n",
      "\t - Step 64: loss: 1.324 acc: 0.516\n",
      "\t - Step 65: loss: 1.376 acc: 0.484\n",
      "\t - Step 66: loss: 1.199 acc: 0.516\n",
      "\t - Step 67: loss: 1.334 acc: 0.531\n",
      "\t - Step 68: loss: 1.183 acc: 0.570\n",
      "\t - Step 69: loss: 1.315 acc: 0.539\n",
      "\t - Step 70: loss: 1.349 acc: 0.484\n",
      "\t - Step 71: loss: 1.298 acc: 0.516\n",
      "\t - Step 72: loss: 1.376 acc: 0.484\n",
      "\t - Step 73: loss: 1.463 acc: 0.430\n",
      "\t - Step 74: loss: 1.491 acc: 0.430\n",
      "\t - Step 75: loss: 1.336 acc: 0.500\n",
      "\t - Step 76: loss: 1.187 acc: 0.602\n",
      "\t - Step 77: loss: 1.227 acc: 0.570\n",
      "\t - Step 78: loss: 1.312 acc: 0.547\n",
      "\t - Step 79: loss: 1.325 acc: 0.469\n",
      "\t - Step 80: loss: 1.259 acc: 0.539\n",
      "\t - Step 81: loss: 1.247 acc: 0.547\n",
      "\t - Step 82: loss: 1.437 acc: 0.477\n",
      "\t - Step 83: loss: 1.320 acc: 0.508\n",
      "\t - Step 84: loss: 1.381 acc: 0.445\n",
      "\t - Step 85: loss: 1.277 acc: 0.500\n",
      "\t - Step 86: loss: 1.291 acc: 0.484\n",
      "\t - Step 87: loss: 1.275 acc: 0.547\n",
      "\t - Step 88: loss: 1.342 acc: 0.484\n",
      "\t - Step 89: loss: 1.319 acc: 0.461\n",
      "\t - Step 90: loss: 1.457 acc: 0.461\n",
      "\t - Step 91: loss: 1.436 acc: 0.430\n",
      "\t - Step 92: loss: 1.370 acc: 0.469\n",
      "\t - Step 93: loss: 1.337 acc: 0.516\n",
      "\t - Step 94: loss: 1.269 acc: 0.484\n",
      "\t - Step 95: loss: 1.216 acc: 0.547\n",
      "\t - Step 96: loss: 1.299 acc: 0.523\n",
      "\t - Step 97: loss: 1.438 acc: 0.453\n",
      "\t - Step 98: loss: 1.418 acc: 0.469\n",
      "\t - Step 99: loss: 1.301 acc: 0.484\n",
      "\t - Step 100: loss: 1.264 acc: 0.570\n",
      "\t - Step 101: loss: 1.352 acc: 0.453\n",
      "\t - Step 102: loss: 1.260 acc: 0.516\n",
      "\t - Step 103: loss: 1.182 acc: 0.531\n",
      "\t - Step 104: loss: 1.324 acc: 0.516\n",
      "\t - Step 105: loss: 1.266 acc: 0.570\n",
      "\t - Step 106: loss: 1.196 acc: 0.570\n",
      "\t - Step 107: loss: 1.377 acc: 0.461\n",
      "\t - Step 108: loss: 1.336 acc: 0.469\n",
      "\t - Step 109: loss: 1.258 acc: 0.500\n",
      "\t - Step 110: loss: 1.267 acc: 0.508\n",
      "\t - Step 111: loss: 1.376 acc: 0.438\n",
      "\t - Step 112: loss: 1.487 acc: 0.477\n",
      "\t - Step 113: loss: 1.379 acc: 0.484\n",
      "\t - Step 114: loss: 1.431 acc: 0.438\n",
      "\t - Step 115: loss: 1.427 acc: 0.469\n",
      "\t - Step 116: loss: 1.480 acc: 0.477\n",
      "\t - Step 117: loss: 1.613 acc: 0.375\n",
      "\t - Step 118: loss: 1.295 acc: 0.539\n",
      "\t - Step 119: loss: 1.250 acc: 0.492\n",
      "\t - Step 120: loss: 1.335 acc: 0.477\n",
      "\t - Step 121: loss: 1.303 acc: 0.453\n",
      "\t - Step 122: loss: 1.379 acc: 0.469\n",
      "\t - Step 123: loss: 1.377 acc: 0.484\n",
      "\t - Step 124: loss: 1.320 acc: 0.547\n",
      "\t - Step 125: loss: 1.361 acc: 0.516\n",
      "\t - Step 126: loss: 1.472 acc: 0.453\n",
      "\t - Step 127: loss: 1.380 acc: 0.461\n",
      "\t - Step 128: loss: 1.310 acc: 0.492\n",
      "\t - Step 129: loss: 1.257 acc: 0.508\n",
      "\t - Step 130: loss: 1.347 acc: 0.500\n",
      "\t - Step 131: loss: 1.482 acc: 0.469\n",
      "\t - Step 132: loss: 1.436 acc: 0.453\n",
      "\t - Step 133: loss: 1.227 acc: 0.516\n",
      "\t - Step 134: loss: 1.333 acc: 0.516\n",
      "\t - Step 135: loss: 1.211 acc: 0.578\n",
      "\t - Step 136: loss: 1.422 acc: 0.445\n",
      "\t - Step 137: loss: 1.338 acc: 0.516\n",
      "\t - Step 138: loss: 1.271 acc: 0.461\n",
      "\t - Step 139: loss: 1.203 acc: 0.547\n",
      "\t - Step 140: loss: 1.231 acc: 0.555\n",
      "\t - Step 141: loss: 1.329 acc: 0.492\n",
      "\t - Step 142: loss: 1.357 acc: 0.508\n",
      "\t - Step 143: loss: 1.288 acc: 0.516\n",
      "\t - Step 144: loss: 1.252 acc: 0.555\n",
      "\t - Step 145: loss: 1.423 acc: 0.477\n",
      "\t - Step 146: loss: 1.281 acc: 0.492\n",
      "\t - Step 147: loss: 1.307 acc: 0.508\n",
      "\t - Step 148: loss: 1.318 acc: 0.539\n",
      "\t - Step 149: loss: 1.420 acc: 0.445\n",
      "\t - Step 150: loss: 1.397 acc: 0.453\n",
      "\t - Step 151: loss: 1.377 acc: 0.492\n",
      "\t - Step 152: loss: 1.292 acc: 0.492\n",
      "\t - Step 153: loss: 1.264 acc: 0.492\n",
      "\t - Step 154: loss: 1.275 acc: 0.578\n",
      "\t - Step 155: loss: 1.394 acc: 0.445\n",
      "\t - Step 156: loss: 1.392 acc: 0.500\n",
      "\t - Step 157: loss: 1.308 acc: 0.508\n",
      "\t - Step 158: loss: 1.317 acc: 0.477\n",
      "\t - Step 159: loss: 1.331 acc: 0.500\n",
      "\t - Step 160: loss: 1.345 acc: 0.531\n",
      "\t - Step 161: loss: 1.340 acc: 0.492\n",
      "\t - Step 162: loss: 1.168 acc: 0.555\n",
      "\t - Step 163: loss: 1.277 acc: 0.531\n",
      "\t - Step 164: loss: 1.270 acc: 0.531\n",
      "\t - Step 165: loss: 1.404 acc: 0.477\n",
      "\t - Step 166: loss: 1.356 acc: 0.492\n",
      "\t - Step 167: loss: 1.390 acc: 0.438\n",
      "\t - Step 168: loss: 1.331 acc: 0.477\n",
      "\t - Step 169: loss: 1.238 acc: 0.523\n",
      "\t - Step 170: loss: 1.398 acc: 0.516\n",
      "\t - Step 171: loss: 1.280 acc: 0.531\n",
      "\t - Step 172: loss: 1.265 acc: 0.523\n",
      "\t - Step 173: loss: 1.332 acc: 0.484\n",
      "\t - Step 174: loss: 1.378 acc: 0.438\n",
      "\t - Step 175: loss: 1.386 acc: 0.516\n",
      "\t - Step 176: loss: 1.442 acc: 0.484\n",
      "\t - Step 177: loss: 1.271 acc: 0.531\n",
      "\t - Step 178: loss: 1.364 acc: 0.445\n",
      "\t - Step 179: loss: 1.257 acc: 0.508\n",
      "\t - Step 180: loss: 1.359 acc: 0.516\n",
      "\t - Step 181: loss: 1.357 acc: 0.500\n",
      "\t - Step 182: loss: 1.350 acc: 0.500\n",
      "\t - Step 183: loss: 1.378 acc: 0.461\n",
      "\t - Step 184: loss: 1.324 acc: 0.555\n",
      "\t - Step 185: loss: 1.416 acc: 0.422\n",
      "\t - Step 186: loss: 1.243 acc: 0.531\n",
      "\t - Step 187: loss: 1.420 acc: 0.508\n",
      "\t - Step 188: loss: 1.388 acc: 0.508\n",
      "\t - Step 189: loss: 1.281 acc: 0.492\n",
      "\t - Step 190: loss: 1.232 acc: 0.547\n",
      "\t - Step 191: loss: 1.372 acc: 0.492\n",
      "\t - Step 192: loss: 1.313 acc: 0.469\n",
      "\t - Step 193: loss: 1.427 acc: 0.477\n",
      "\t - Step 194: loss: 1.256 acc: 0.531\n",
      "\t - Step 195: loss: 1.382 acc: 0.453\n",
      "\t - Step 196: loss: 1.246 acc: 0.523\n",
      "\t - Step 197: loss: 1.370 acc: 0.430\n",
      "\t - Step 198: loss: 1.420 acc: 0.461\n",
      "\t - Step 199: loss: 1.367 acc: 0.484\n",
      "\t - Step 200: loss: 1.469 acc: 0.414\n",
      "\t - Step 201: loss: 1.354 acc: 0.453\n",
      "\t - Step 202: loss: 1.281 acc: 0.570\n",
      "\t - Step 203: loss: 1.315 acc: 0.508\n",
      "\t - Step 204: loss: 1.437 acc: 0.477\n",
      "\t - Step 205: loss: 1.288 acc: 0.539\n",
      "\t - Step 206: loss: 1.306 acc: 0.492\n",
      "\t - Step 207: loss: 1.359 acc: 0.445\n",
      "\t - Step 208: loss: 1.334 acc: 0.539\n",
      "\t - Step 209: loss: 1.278 acc: 0.547\n",
      "\t - Step 210: loss: 1.324 acc: 0.477\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t - Step 211: loss: 1.453 acc: 0.461\n",
      "\t - Step 212: loss: 1.227 acc: 0.555\n",
      "\t - Step 213: loss: 1.191 acc: 0.539\n",
      "\t - Step 214: loss: 1.402 acc: 0.492\n",
      "\t - Step 215: loss: 1.314 acc: 0.500\n",
      "\t - Step 216: loss: 1.456 acc: 0.461\n",
      "\t - Step 217: loss: 1.430 acc: 0.438\n",
      "\t - Step 218: loss: 1.305 acc: 0.492\n",
      "\t - Step 219: loss: 1.500 acc: 0.422\n",
      "\t - Step 220: loss: 1.507 acc: 0.398\n",
      "\t - Step 221: loss: 1.366 acc: 0.492\n",
      "\t - Step 222: loss: 1.406 acc: 0.445\n",
      "\t - Step 223: loss: 1.437 acc: 0.438\n",
      "\t - Step 224: loss: 1.286 acc: 0.562\n",
      "\t - Step 225: loss: 1.385 acc: 0.514\n",
      "- Avg.loss: 1.331  | Avg.acc: 0.500\n",
      "- Avg. val_loss: 1.553  | Avg. val_acc: 0.420\n",
      "Epoch:  10\n",
      "\t - Step 1: loss: 1.325 acc: 0.508\n",
      "\t - Step 2: loss: 1.273 acc: 0.547\n",
      "\t - Step 3: loss: 1.239 acc: 0.555\n",
      "\t - Step 4: loss: 1.279 acc: 0.539\n",
      "\t - Step 5: loss: 1.214 acc: 0.562\n",
      "\t - Step 6: loss: 1.223 acc: 0.508\n",
      "\t - Step 7: loss: 1.540 acc: 0.453\n",
      "\t - Step 8: loss: 1.330 acc: 0.445\n",
      "\t - Step 9: loss: 1.358 acc: 0.445\n",
      "\t - Step 10: loss: 1.325 acc: 0.500\n",
      "\t - Step 11: loss: 1.337 acc: 0.492\n",
      "\t - Step 12: loss: 1.357 acc: 0.555\n",
      "\t - Step 13: loss: 1.281 acc: 0.539\n",
      "\t - Step 14: loss: 1.291 acc: 0.531\n",
      "\t - Step 15: loss: 1.254 acc: 0.516\n",
      "\t - Step 16: loss: 1.288 acc: 0.469\n",
      "\t - Step 17: loss: 1.399 acc: 0.516\n",
      "\t - Step 18: loss: 1.337 acc: 0.516\n",
      "\t - Step 19: loss: 1.206 acc: 0.531\n",
      "\t - Step 20: loss: 1.460 acc: 0.453\n",
      "\t - Step 21: loss: 1.194 acc: 0.555\n",
      "\t - Step 22: loss: 1.333 acc: 0.508\n",
      "\t - Step 23: loss: 1.204 acc: 0.500\n",
      "\t - Step 24: loss: 1.350 acc: 0.477\n",
      "\t - Step 25: loss: 1.213 acc: 0.508\n",
      "\t - Step 26: loss: 1.274 acc: 0.484\n",
      "\t - Step 27: loss: 1.369 acc: 0.508\n",
      "\t - Step 28: loss: 1.213 acc: 0.586\n",
      "\t - Step 29: loss: 1.165 acc: 0.562\n",
      "\t - Step 30: loss: 1.280 acc: 0.508\n",
      "\t - Step 31: loss: 1.395 acc: 0.453\n",
      "\t - Step 32: loss: 1.353 acc: 0.492\n",
      "\t - Step 33: loss: 1.325 acc: 0.531\n",
      "\t - Step 34: loss: 1.386 acc: 0.492\n",
      "\t - Step 35: loss: 1.384 acc: 0.469\n",
      "\t - Step 36: loss: 1.211 acc: 0.547\n",
      "\t - Step 37: loss: 1.238 acc: 0.578\n",
      "\t - Step 38: loss: 1.318 acc: 0.516\n",
      "\t - Step 39: loss: 1.392 acc: 0.492\n",
      "\t - Step 40: loss: 1.161 acc: 0.602\n",
      "\t - Step 41: loss: 1.290 acc: 0.562\n",
      "\t - Step 42: loss: 1.288 acc: 0.484\n",
      "\t - Step 43: loss: 1.200 acc: 0.570\n",
      "\t - Step 44: loss: 1.403 acc: 0.516\n",
      "\t - Step 45: loss: 1.292 acc: 0.547\n",
      "\t - Step 46: loss: 1.387 acc: 0.461\n",
      "\t - Step 47: loss: 1.319 acc: 0.523\n",
      "\t - Step 48: loss: 1.251 acc: 0.523\n",
      "\t - Step 49: loss: 1.279 acc: 0.516\n",
      "\t - Step 50: loss: 1.434 acc: 0.469\n",
      "\t - Step 51: loss: 1.316 acc: 0.492\n",
      "\t - Step 52: loss: 1.247 acc: 0.547\n",
      "\t - Step 53: loss: 1.391 acc: 0.492\n",
      "\t - Step 54: loss: 1.249 acc: 0.531\n",
      "\t - Step 55: loss: 1.451 acc: 0.453\n",
      "\t - Step 56: loss: 1.103 acc: 0.609\n",
      "\t - Step 57: loss: 1.209 acc: 0.562\n",
      "\t - Step 58: loss: 1.231 acc: 0.562\n",
      "\t - Step 59: loss: 1.235 acc: 0.555\n",
      "\t - Step 60: loss: 1.393 acc: 0.469\n",
      "\t - Step 61: loss: 1.385 acc: 0.523\n",
      "\t - Step 62: loss: 1.308 acc: 0.531\n",
      "\t - Step 63: loss: 1.365 acc: 0.453\n",
      "\t - Step 64: loss: 1.244 acc: 0.516\n",
      "\t - Step 65: loss: 1.245 acc: 0.531\n",
      "\t - Step 66: loss: 1.399 acc: 0.484\n",
      "\t - Step 67: loss: 1.338 acc: 0.484\n",
      "\t - Step 68: loss: 1.308 acc: 0.539\n",
      "\t - Step 69: loss: 1.322 acc: 0.508\n",
      "\t - Step 70: loss: 1.475 acc: 0.430\n",
      "\t - Step 71: loss: 1.393 acc: 0.438\n",
      "\t - Step 72: loss: 1.250 acc: 0.492\n",
      "\t - Step 73: loss: 1.257 acc: 0.531\n",
      "\t - Step 74: loss: 1.375 acc: 0.453\n",
      "\t - Step 75: loss: 1.294 acc: 0.523\n",
      "\t - Step 76: loss: 1.377 acc: 0.453\n",
      "\t - Step 77: loss: 1.454 acc: 0.445\n",
      "\t - Step 78: loss: 1.282 acc: 0.469\n",
      "\t - Step 79: loss: 1.324 acc: 0.438\n",
      "\t - Step 80: loss: 1.344 acc: 0.469\n",
      "\t - Step 81: loss: 1.310 acc: 0.500\n",
      "\t - Step 82: loss: 1.319 acc: 0.508\n",
      "\t - Step 83: loss: 1.394 acc: 0.484\n",
      "\t - Step 84: loss: 1.221 acc: 0.594\n",
      "\t - Step 85: loss: 1.397 acc: 0.500\n",
      "\t - Step 86: loss: 1.289 acc: 0.547\n",
      "\t - Step 87: loss: 1.313 acc: 0.523\n",
      "\t - Step 88: loss: 1.326 acc: 0.484\n",
      "\t - Step 89: loss: 1.283 acc: 0.555\n",
      "\t - Step 90: loss: 1.308 acc: 0.500\n",
      "\t - Step 91: loss: 1.346 acc: 0.461\n",
      "\t - Step 92: loss: 1.274 acc: 0.562\n",
      "\t - Step 93: loss: 1.454 acc: 0.438\n",
      "\t - Step 94: loss: 1.376 acc: 0.453\n",
      "\t - Step 95: loss: 1.280 acc: 0.516\n",
      "\t - Step 96: loss: 1.310 acc: 0.508\n",
      "\t - Step 97: loss: 1.211 acc: 0.539\n",
      "\t - Step 98: loss: 1.360 acc: 0.492\n",
      "\t - Step 99: loss: 1.266 acc: 0.500\n",
      "\t - Step 100: loss: 1.345 acc: 0.461\n",
      "\t - Step 101: loss: 1.421 acc: 0.461\n",
      "\t - Step 102: loss: 1.340 acc: 0.484\n",
      "\t - Step 103: loss: 1.332 acc: 0.500\n",
      "\t - Step 104: loss: 1.242 acc: 0.531\n",
      "\t - Step 105: loss: 1.402 acc: 0.477\n",
      "\t - Step 106: loss: 1.318 acc: 0.453\n",
      "\t - Step 107: loss: 1.218 acc: 0.594\n",
      "\t - Step 108: loss: 1.284 acc: 0.508\n",
      "\t - Step 109: loss: 1.305 acc: 0.523\n",
      "\t - Step 110: loss: 1.308 acc: 0.492\n",
      "\t - Step 111: loss: 1.399 acc: 0.430\n",
      "\t - Step 112: loss: 1.427 acc: 0.484\n",
      "\t - Step 113: loss: 1.326 acc: 0.492\n",
      "\t - Step 114: loss: 1.313 acc: 0.531\n",
      "\t - Step 115: loss: 1.438 acc: 0.445\n",
      "\t - Step 116: loss: 1.553 acc: 0.438\n",
      "\t - Step 117: loss: 1.245 acc: 0.508\n",
      "\t - Step 118: loss: 1.330 acc: 0.477\n",
      "\t - Step 119: loss: 1.280 acc: 0.500\n",
      "\t - Step 120: loss: 1.352 acc: 0.453\n",
      "\t - Step 121: loss: 1.253 acc: 0.523\n",
      "\t - Step 122: loss: 1.431 acc: 0.445\n",
      "\t - Step 123: loss: 1.278 acc: 0.516\n",
      "\t - Step 124: loss: 1.182 acc: 0.609\n",
      "\t - Step 125: loss: 1.259 acc: 0.547\n",
      "\t - Step 126: loss: 1.340 acc: 0.500\n",
      "\t - Step 127: loss: 1.379 acc: 0.453\n",
      "\t - Step 128: loss: 1.373 acc: 0.508\n",
      "\t - Step 129: loss: 1.253 acc: 0.508\n",
      "\t - Step 130: loss: 1.320 acc: 0.562\n",
      "\t - Step 131: loss: 1.254 acc: 0.570\n",
      "\t - Step 132: loss: 1.358 acc: 0.445\n",
      "\t - Step 133: loss: 1.307 acc: 0.477\n",
      "\t - Step 134: loss: 1.356 acc: 0.516\n",
      "\t - Step 135: loss: 1.533 acc: 0.422\n",
      "\t - Step 136: loss: 1.275 acc: 0.523\n",
      "\t - Step 137: loss: 1.321 acc: 0.500\n",
      "\t - Step 138: loss: 1.385 acc: 0.484\n",
      "\t - Step 139: loss: 1.203 acc: 0.555\n",
      "\t - Step 140: loss: 1.324 acc: 0.484\n",
      "\t - Step 141: loss: 1.390 acc: 0.492\n",
      "\t - Step 142: loss: 1.507 acc: 0.422\n",
      "\t - Step 143: loss: 1.455 acc: 0.445\n",
      "\t - Step 144: loss: 1.291 acc: 0.500\n",
      "\t - Step 145: loss: 1.282 acc: 0.516\n",
      "\t - Step 146: loss: 1.247 acc: 0.484\n",
      "\t - Step 147: loss: 1.436 acc: 0.469\n",
      "\t - Step 148: loss: 1.390 acc: 0.414\n",
      "\t - Step 149: loss: 1.365 acc: 0.508\n",
      "\t - Step 150: loss: 1.510 acc: 0.492\n",
      "\t - Step 151: loss: 1.358 acc: 0.516\n",
      "\t - Step 152: loss: 1.247 acc: 0.531\n",
      "\t - Step 153: loss: 1.439 acc: 0.500\n",
      "\t - Step 154: loss: 1.261 acc: 0.516\n",
      "\t - Step 155: loss: 1.407 acc: 0.414\n",
      "\t - Step 156: loss: 1.267 acc: 0.523\n",
      "\t - Step 157: loss: 1.439 acc: 0.453\n",
      "\t - Step 158: loss: 1.326 acc: 0.508\n",
      "\t - Step 159: loss: 1.172 acc: 0.555\n",
      "\t - Step 160: loss: 1.421 acc: 0.445\n",
      "\t - Step 161: loss: 1.239 acc: 0.523\n",
      "\t - Step 162: loss: 1.378 acc: 0.469\n",
      "\t - Step 163: loss: 1.420 acc: 0.492\n",
      "\t - Step 164: loss: 1.276 acc: 0.500\n",
      "\t - Step 165: loss: 1.404 acc: 0.508\n",
      "\t - Step 166: loss: 1.458 acc: 0.461\n",
      "\t - Step 167: loss: 1.464 acc: 0.453\n",
      "\t - Step 168: loss: 1.250 acc: 0.508\n",
      "\t - Step 169: loss: 1.403 acc: 0.453\n",
      "\t - Step 170: loss: 1.322 acc: 0.508\n",
      "\t - Step 171: loss: 1.305 acc: 0.539\n",
      "\t - Step 172: loss: 1.316 acc: 0.500\n",
      "\t - Step 173: loss: 1.456 acc: 0.430\n",
      "\t - Step 174: loss: 1.291 acc: 0.477\n",
      "\t - Step 175: loss: 1.247 acc: 0.500\n",
      "\t - Step 176: loss: 1.228 acc: 0.547\n",
      "\t - Step 177: loss: 1.593 acc: 0.375\n",
      "\t - Step 178: loss: 1.420 acc: 0.547\n",
      "\t - Step 179: loss: 1.446 acc: 0.453\n",
      "\t - Step 180: loss: 1.240 acc: 0.531\n",
      "\t - Step 181: loss: 1.186 acc: 0.570\n",
      "\t - Step 182: loss: 1.315 acc: 0.492\n",
      "\t - Step 183: loss: 1.439 acc: 0.484\n",
      "\t - Step 184: loss: 1.338 acc: 0.445\n",
      "\t - Step 185: loss: 1.297 acc: 0.492\n",
      "\t - Step 186: loss: 1.352 acc: 0.461\n",
      "\t - Step 187: loss: 1.417 acc: 0.508\n",
      "\t - Step 188: loss: 1.268 acc: 0.500\n",
      "\t - Step 189: loss: 1.260 acc: 0.531\n",
      "\t - Step 190: loss: 1.178 acc: 0.562\n",
      "\t - Step 191: loss: 1.314 acc: 0.516\n",
      "\t - Step 192: loss: 1.321 acc: 0.461\n",
      "\t - Step 193: loss: 1.242 acc: 0.531\n",
      "\t - Step 194: loss: 1.271 acc: 0.539\n",
      "\t - Step 195: loss: 1.269 acc: 0.547\n",
      "\t - Step 196: loss: 1.379 acc: 0.500\n",
      "\t - Step 197: loss: 1.402 acc: 0.453\n",
      "\t - Step 198: loss: 1.385 acc: 0.461\n",
      "\t - Step 199: loss: 1.426 acc: 0.453\n",
      "\t - Step 200: loss: 1.216 acc: 0.578\n",
      "\t - Step 201: loss: 1.278 acc: 0.602\n",
      "\t - Step 202: loss: 1.461 acc: 0.461\n",
      "\t - Step 203: loss: 1.446 acc: 0.500\n",
      "\t - Step 204: loss: 1.491 acc: 0.414\n",
      "\t - Step 205: loss: 1.262 acc: 0.523\n",
      "\t - Step 206: loss: 1.373 acc: 0.484\n",
      "\t - Step 207: loss: 1.220 acc: 0.508\n",
      "\t - Step 208: loss: 1.429 acc: 0.469\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t - Step 209: loss: 1.447 acc: 0.461\n",
      "\t - Step 210: loss: 1.418 acc: 0.422\n",
      "\t - Step 211: loss: 1.303 acc: 0.531\n",
      "\t - Step 212: loss: 1.221 acc: 0.555\n",
      "\t - Step 213: loss: 1.188 acc: 0.555\n",
      "\t - Step 214: loss: 1.350 acc: 0.492\n",
      "\t - Step 215: loss: 1.297 acc: 0.484\n",
      "\t - Step 216: loss: 1.345 acc: 0.508\n",
      "\t - Step 217: loss: 1.458 acc: 0.461\n",
      "\t - Step 218: loss: 1.343 acc: 0.477\n",
      "\t - Step 219: loss: 1.335 acc: 0.516\n",
      "\t - Step 220: loss: 1.436 acc: 0.469\n",
      "\t - Step 221: loss: 1.338 acc: 0.469\n",
      "\t - Step 222: loss: 1.455 acc: 0.391\n",
      "\t - Step 223: loss: 1.321 acc: 0.555\n",
      "\t - Step 224: loss: 1.233 acc: 0.523\n",
      "\t - Step 225: loss: 1.164 acc: 0.649\n",
      "- Avg.loss: 1.327  | Avg.acc: 0.501\n",
      "- Avg. val_loss: 1.545  | Avg. val_acc: 0.436\n",
      "* Update optimal model\n",
      "Epoch:  11\n",
      "\t - Step 1: loss: 1.203 acc: 0.531\n",
      "\t - Step 2: loss: 1.237 acc: 0.531\n",
      "\t - Step 3: loss: 1.266 acc: 0.516\n",
      "\t - Step 4: loss: 1.327 acc: 0.492\n",
      "\t - Step 5: loss: 1.326 acc: 0.508\n",
      "\t - Step 6: loss: 1.387 acc: 0.445\n",
      "\t - Step 7: loss: 1.423 acc: 0.500\n",
      "\t - Step 8: loss: 1.254 acc: 0.516\n",
      "\t - Step 9: loss: 1.290 acc: 0.578\n",
      "\t - Step 10: loss: 1.433 acc: 0.484\n",
      "\t - Step 11: loss: 1.288 acc: 0.539\n",
      "\t - Step 12: loss: 1.275 acc: 0.531\n",
      "\t - Step 13: loss: 1.230 acc: 0.578\n",
      "\t - Step 14: loss: 1.244 acc: 0.555\n",
      "\t - Step 15: loss: 1.128 acc: 0.617\n",
      "\t - Step 16: loss: 1.345 acc: 0.477\n",
      "\t - Step 17: loss: 1.273 acc: 0.500\n",
      "\t - Step 18: loss: 1.307 acc: 0.492\n",
      "\t - Step 19: loss: 1.301 acc: 0.516\n",
      "\t - Step 20: loss: 1.362 acc: 0.484\n",
      "\t - Step 21: loss: 1.143 acc: 0.609\n",
      "\t - Step 22: loss: 1.353 acc: 0.484\n",
      "\t - Step 23: loss: 1.233 acc: 0.555\n",
      "\t - Step 24: loss: 1.178 acc: 0.664\n",
      "\t - Step 25: loss: 1.334 acc: 0.500\n",
      "\t - Step 26: loss: 1.307 acc: 0.477\n",
      "\t - Step 27: loss: 1.245 acc: 0.555\n",
      "\t - Step 28: loss: 1.328 acc: 0.477\n",
      "\t - Step 29: loss: 1.129 acc: 0.570\n",
      "\t - Step 30: loss: 1.274 acc: 0.492\n",
      "\t - Step 31: loss: 1.254 acc: 0.484\n",
      "\t - Step 32: loss: 1.245 acc: 0.492\n",
      "\t - Step 33: loss: 1.292 acc: 0.555\n",
      "\t - Step 34: loss: 1.288 acc: 0.523\n",
      "\t - Step 35: loss: 1.253 acc: 0.523\n",
      "\t - Step 36: loss: 1.304 acc: 0.516\n",
      "\t - Step 37: loss: 1.334 acc: 0.500\n",
      "\t - Step 38: loss: 1.363 acc: 0.516\n",
      "\t - Step 39: loss: 1.286 acc: 0.516\n",
      "\t - Step 40: loss: 1.315 acc: 0.492\n",
      "\t - Step 41: loss: 1.436 acc: 0.469\n",
      "\t - Step 42: loss: 1.263 acc: 0.539\n",
      "\t - Step 43: loss: 1.307 acc: 0.516\n",
      "\t - Step 44: loss: 1.272 acc: 0.523\n",
      "\t - Step 45: loss: 1.262 acc: 0.523\n",
      "\t - Step 46: loss: 1.455 acc: 0.391\n",
      "\t - Step 47: loss: 1.208 acc: 0.586\n",
      "\t - Step 48: loss: 1.444 acc: 0.453\n",
      "\t - Step 49: loss: 1.259 acc: 0.555\n",
      "\t - Step 50: loss: 1.187 acc: 0.555\n",
      "\t - Step 51: loss: 1.246 acc: 0.516\n",
      "\t - Step 52: loss: 1.309 acc: 0.500\n",
      "\t - Step 53: loss: 1.334 acc: 0.422\n",
      "\t - Step 54: loss: 1.379 acc: 0.445\n",
      "\t - Step 55: loss: 1.383 acc: 0.484\n",
      "\t - Step 56: loss: 1.190 acc: 0.555\n",
      "\t - Step 57: loss: 1.481 acc: 0.414\n",
      "\t - Step 58: loss: 1.247 acc: 0.555\n",
      "\t - Step 59: loss: 1.377 acc: 0.500\n",
      "\t - Step 60: loss: 1.328 acc: 0.469\n",
      "\t - Step 61: loss: 1.366 acc: 0.492\n",
      "\t - Step 62: loss: 1.405 acc: 0.461\n",
      "\t - Step 63: loss: 1.405 acc: 0.484\n",
      "\t - Step 64: loss: 1.253 acc: 0.539\n",
      "\t - Step 65: loss: 1.279 acc: 0.539\n",
      "\t - Step 66: loss: 1.407 acc: 0.469\n",
      "\t - Step 67: loss: 1.065 acc: 0.648\n",
      "\t - Step 68: loss: 1.294 acc: 0.492\n",
      "\t - Step 69: loss: 1.368 acc: 0.508\n",
      "\t - Step 70: loss: 1.265 acc: 0.570\n",
      "\t - Step 71: loss: 1.303 acc: 0.508\n",
      "\t - Step 72: loss: 1.363 acc: 0.461\n",
      "\t - Step 73: loss: 1.397 acc: 0.422\n",
      "\t - Step 74: loss: 1.342 acc: 0.523\n",
      "\t - Step 75: loss: 1.334 acc: 0.453\n",
      "\t - Step 76: loss: 1.345 acc: 0.469\n",
      "\t - Step 77: loss: 1.311 acc: 0.547\n",
      "\t - Step 78: loss: 1.266 acc: 0.523\n",
      "\t - Step 79: loss: 1.351 acc: 0.492\n",
      "\t - Step 80: loss: 1.320 acc: 0.477\n",
      "\t - Step 81: loss: 1.241 acc: 0.547\n",
      "\t - Step 82: loss: 1.247 acc: 0.508\n",
      "\t - Step 83: loss: 1.226 acc: 0.586\n",
      "\t - Step 84: loss: 1.279 acc: 0.516\n",
      "\t - Step 85: loss: 1.398 acc: 0.500\n",
      "\t - Step 86: loss: 1.218 acc: 0.547\n",
      "\t - Step 87: loss: 1.218 acc: 0.516\n",
      "\t - Step 88: loss: 1.296 acc: 0.531\n",
      "\t - Step 89: loss: 1.266 acc: 0.492\n",
      "\t - Step 90: loss: 1.413 acc: 0.469\n",
      "\t - Step 91: loss: 1.181 acc: 0.594\n",
      "\t - Step 92: loss: 1.343 acc: 0.453\n",
      "\t - Step 93: loss: 1.417 acc: 0.453\n",
      "\t - Step 94: loss: 1.339 acc: 0.422\n",
      "\t - Step 95: loss: 1.277 acc: 0.523\n",
      "\t - Step 96: loss: 1.146 acc: 0.594\n",
      "\t - Step 97: loss: 1.350 acc: 0.484\n",
      "\t - Step 98: loss: 1.293 acc: 0.500\n",
      "\t - Step 99: loss: 1.229 acc: 0.555\n",
      "\t - Step 100: loss: 1.454 acc: 0.398\n",
      "\t - Step 101: loss: 1.270 acc: 0.516\n",
      "\t - Step 102: loss: 1.388 acc: 0.500\n",
      "\t - Step 103: loss: 1.392 acc: 0.492\n",
      "\t - Step 104: loss: 1.473 acc: 0.422\n",
      "\t - Step 105: loss: 1.370 acc: 0.547\n",
      "\t - Step 106: loss: 1.247 acc: 0.523\n",
      "\t - Step 107: loss: 1.212 acc: 0.570\n",
      "\t - Step 108: loss: 1.244 acc: 0.555\n",
      "\t - Step 109: loss: 1.277 acc: 0.500\n",
      "\t - Step 110: loss: 1.417 acc: 0.445\n",
      "\t - Step 111: loss: 1.352 acc: 0.438\n",
      "\t - Step 112: loss: 1.262 acc: 0.500\n",
      "\t - Step 113: loss: 1.435 acc: 0.484\n",
      "\t - Step 114: loss: 1.248 acc: 0.516\n",
      "\t - Step 115: loss: 1.258 acc: 0.555\n",
      "\t - Step 116: loss: 1.385 acc: 0.438\n",
      "\t - Step 117: loss: 1.298 acc: 0.477\n",
      "\t - Step 118: loss: 1.317 acc: 0.531\n",
      "\t - Step 119: loss: 1.324 acc: 0.484\n",
      "\t - Step 120: loss: 1.359 acc: 0.516\n",
      "\t - Step 121: loss: 1.331 acc: 0.484\n",
      "\t - Step 122: loss: 1.372 acc: 0.445\n",
      "\t - Step 123: loss: 1.473 acc: 0.422\n",
      "\t - Step 124: loss: 1.266 acc: 0.500\n",
      "\t - Step 125: loss: 1.222 acc: 0.523\n",
      "\t - Step 126: loss: 1.257 acc: 0.492\n",
      "\t - Step 127: loss: 1.229 acc: 0.531\n",
      "\t - Step 128: loss: 1.238 acc: 0.516\n",
      "\t - Step 129: loss: 1.197 acc: 0.523\n",
      "\t - Step 130: loss: 1.327 acc: 0.484\n",
      "\t - Step 131: loss: 1.357 acc: 0.453\n",
      "\t - Step 132: loss: 1.423 acc: 0.516\n",
      "\t - Step 133: loss: 1.259 acc: 0.516\n",
      "\t - Step 134: loss: 1.346 acc: 0.477\n",
      "\t - Step 135: loss: 1.313 acc: 0.461\n",
      "\t - Step 136: loss: 1.373 acc: 0.500\n",
      "\t - Step 137: loss: 1.234 acc: 0.523\n",
      "\t - Step 138: loss: 1.259 acc: 0.539\n",
      "\t - Step 139: loss: 1.344 acc: 0.492\n",
      "\t - Step 140: loss: 1.341 acc: 0.492\n",
      "\t - Step 141: loss: 1.260 acc: 0.539\n",
      "\t - Step 142: loss: 1.417 acc: 0.477\n",
      "\t - Step 143: loss: 1.495 acc: 0.438\n",
      "\t - Step 144: loss: 1.282 acc: 0.562\n",
      "\t - Step 145: loss: 1.422 acc: 0.453\n",
      "\t - Step 146: loss: 1.454 acc: 0.414\n",
      "\t - Step 147: loss: 1.355 acc: 0.461\n",
      "\t - Step 148: loss: 1.203 acc: 0.555\n",
      "\t - Step 149: loss: 1.192 acc: 0.555\n",
      "\t - Step 150: loss: 1.364 acc: 0.492\n",
      "\t - Step 151: loss: 1.244 acc: 0.555\n",
      "\t - Step 152: loss: 1.265 acc: 0.500\n",
      "\t - Step 153: loss: 1.400 acc: 0.539\n",
      "\t - Step 154: loss: 1.442 acc: 0.453\n",
      "\t - Step 155: loss: 1.211 acc: 0.570\n",
      "\t - Step 156: loss: 1.295 acc: 0.500\n",
      "\t - Step 157: loss: 1.330 acc: 0.523\n",
      "\t - Step 158: loss: 1.330 acc: 0.484\n",
      "\t - Step 159: loss: 1.281 acc: 0.539\n",
      "\t - Step 160: loss: 1.156 acc: 0.523\n",
      "\t - Step 161: loss: 1.322 acc: 0.477\n",
      "\t - Step 162: loss: 1.465 acc: 0.414\n",
      "\t - Step 163: loss: 1.199 acc: 0.555\n",
      "\t - Step 164: loss: 1.300 acc: 0.523\n",
      "\t - Step 165: loss: 1.455 acc: 0.461\n",
      "\t - Step 166: loss: 1.439 acc: 0.438\n",
      "\t - Step 167: loss: 1.287 acc: 0.500\n",
      "\t - Step 168: loss: 1.325 acc: 0.523\n",
      "\t - Step 169: loss: 1.334 acc: 0.430\n",
      "\t - Step 170: loss: 1.157 acc: 0.555\n",
      "\t - Step 171: loss: 1.314 acc: 0.477\n",
      "\t - Step 172: loss: 1.310 acc: 0.531\n",
      "\t - Step 173: loss: 1.246 acc: 0.508\n",
      "\t - Step 174: loss: 1.378 acc: 0.453\n",
      "\t - Step 175: loss: 1.390 acc: 0.500\n",
      "\t - Step 176: loss: 1.361 acc: 0.523\n",
      "\t - Step 177: loss: 1.173 acc: 0.562\n",
      "\t - Step 178: loss: 1.154 acc: 0.547\n",
      "\t - Step 179: loss: 1.286 acc: 0.469\n",
      "\t - Step 180: loss: 1.376 acc: 0.469\n",
      "\t - Step 181: loss: 1.384 acc: 0.492\n",
      "\t - Step 182: loss: 1.238 acc: 0.547\n",
      "\t - Step 183: loss: 1.335 acc: 0.484\n",
      "\t - Step 184: loss: 1.373 acc: 0.508\n",
      "\t - Step 185: loss: 1.291 acc: 0.516\n",
      "\t - Step 186: loss: 1.208 acc: 0.578\n",
      "\t - Step 187: loss: 1.155 acc: 0.633\n",
      "\t - Step 188: loss: 1.215 acc: 0.625\n",
      "\t - Step 189: loss: 1.269 acc: 0.484\n",
      "\t - Step 190: loss: 1.450 acc: 0.469\n",
      "\t - Step 191: loss: 1.173 acc: 0.523\n",
      "\t - Step 192: loss: 1.507 acc: 0.391\n",
      "\t - Step 193: loss: 1.485 acc: 0.484\n",
      "\t - Step 194: loss: 1.249 acc: 0.547\n",
      "\t - Step 195: loss: 1.318 acc: 0.523\n",
      "\t - Step 196: loss: 1.499 acc: 0.461\n",
      "\t - Step 197: loss: 1.254 acc: 0.539\n",
      "\t - Step 198: loss: 1.205 acc: 0.547\n",
      "\t - Step 199: loss: 1.351 acc: 0.508\n",
      "\t - Step 200: loss: 1.460 acc: 0.430\n",
      "\t - Step 201: loss: 1.361 acc: 0.461\n",
      "\t - Step 202: loss: 1.437 acc: 0.469\n",
      "\t - Step 203: loss: 1.229 acc: 0.555\n",
      "\t - Step 204: loss: 1.261 acc: 0.508\n",
      "\t - Step 205: loss: 1.216 acc: 0.539\n",
      "\t - Step 206: loss: 1.192 acc: 0.570\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t - Step 207: loss: 1.344 acc: 0.484\n",
      "\t - Step 208: loss: 1.322 acc: 0.492\n",
      "\t - Step 209: loss: 1.168 acc: 0.523\n",
      "\t - Step 210: loss: 1.316 acc: 0.484\n",
      "\t - Step 211: loss: 1.319 acc: 0.492\n",
      "\t - Step 212: loss: 1.273 acc: 0.531\n",
      "\t - Step 213: loss: 1.516 acc: 0.422\n",
      "\t - Step 214: loss: 1.175 acc: 0.594\n",
      "\t - Step 215: loss: 1.354 acc: 0.484\n",
      "\t - Step 216: loss: 1.455 acc: 0.414\n",
      "\t - Step 217: loss: 1.379 acc: 0.477\n",
      "\t - Step 218: loss: 1.301 acc: 0.539\n",
      "\t - Step 219: loss: 1.255 acc: 0.562\n",
      "\t - Step 220: loss: 1.309 acc: 0.523\n",
      "\t - Step 221: loss: 1.441 acc: 0.453\n",
      "\t - Step 222: loss: 1.460 acc: 0.453\n",
      "\t - Step 223: loss: 1.272 acc: 0.477\n",
      "\t - Step 224: loss: 1.358 acc: 0.484\n",
      "\t - Step 225: loss: 1.340 acc: 0.486\n",
      "- Avg.loss: 1.310  | Avg.acc: 0.506\n",
      "- Avg. val_loss: 1.789  | Avg. val_acc: 0.361\n",
      "Epoch:  12\n",
      "\t - Step 1: loss: 1.258 acc: 0.484\n",
      "\t - Step 2: loss: 1.206 acc: 0.594\n",
      "\t - Step 3: loss: 1.545 acc: 0.445\n",
      "\t - Step 4: loss: 1.380 acc: 0.484\n",
      "\t - Step 5: loss: 1.292 acc: 0.500\n",
      "\t - Step 6: loss: 1.279 acc: 0.578\n",
      "\t - Step 7: loss: 1.313 acc: 0.508\n",
      "\t - Step 8: loss: 1.449 acc: 0.469\n",
      "\t - Step 9: loss: 1.267 acc: 0.500\n",
      "\t - Step 10: loss: 1.532 acc: 0.414\n",
      "\t - Step 11: loss: 1.372 acc: 0.477\n",
      "\t - Step 12: loss: 1.182 acc: 0.609\n",
      "\t - Step 13: loss: 1.283 acc: 0.555\n",
      "\t - Step 14: loss: 1.397 acc: 0.453\n",
      "\t - Step 15: loss: 1.331 acc: 0.500\n",
      "\t - Step 16: loss: 1.240 acc: 0.484\n",
      "\t - Step 17: loss: 1.180 acc: 0.539\n",
      "\t - Step 18: loss: 1.271 acc: 0.523\n",
      "\t - Step 19: loss: 1.263 acc: 0.547\n",
      "\t - Step 20: loss: 1.215 acc: 0.516\n",
      "\t - Step 21: loss: 1.193 acc: 0.539\n",
      "\t - Step 22: loss: 1.325 acc: 0.484\n",
      "\t - Step 23: loss: 1.240 acc: 0.516\n",
      "\t - Step 24: loss: 1.339 acc: 0.531\n",
      "\t - Step 25: loss: 1.283 acc: 0.484\n",
      "\t - Step 26: loss: 1.274 acc: 0.508\n",
      "\t - Step 27: loss: 1.116 acc: 0.625\n",
      "\t - Step 28: loss: 1.278 acc: 0.523\n",
      "\t - Step 29: loss: 1.378 acc: 0.523\n",
      "\t - Step 30: loss: 1.443 acc: 0.406\n",
      "\t - Step 31: loss: 1.290 acc: 0.516\n",
      "\t - Step 32: loss: 1.174 acc: 0.547\n",
      "\t - Step 33: loss: 1.339 acc: 0.492\n",
      "\t - Step 34: loss: 1.378 acc: 0.461\n",
      "\t - Step 35: loss: 1.275 acc: 0.516\n",
      "\t - Step 36: loss: 1.279 acc: 0.477\n",
      "\t - Step 37: loss: 1.246 acc: 0.547\n",
      "\t - Step 38: loss: 1.262 acc: 0.492\n",
      "\t - Step 39: loss: 1.354 acc: 0.469\n",
      "\t - Step 40: loss: 1.332 acc: 0.547\n",
      "\t - Step 41: loss: 1.369 acc: 0.516\n",
      "\t - Step 42: loss: 1.429 acc: 0.445\n",
      "\t - Step 43: loss: 1.359 acc: 0.508\n",
      "\t - Step 44: loss: 1.242 acc: 0.523\n",
      "\t - Step 45: loss: 1.375 acc: 0.555\n",
      "\t - Step 46: loss: 1.326 acc: 0.570\n",
      "\t - Step 47: loss: 1.155 acc: 0.586\n",
      "\t - Step 48: loss: 1.313 acc: 0.469\n",
      "\t - Step 49: loss: 1.233 acc: 0.516\n",
      "\t - Step 50: loss: 1.249 acc: 0.500\n",
      "\t - Step 51: loss: 1.263 acc: 0.523\n",
      "\t - Step 52: loss: 1.158 acc: 0.562\n",
      "\t - Step 53: loss: 1.050 acc: 0.617\n",
      "\t - Step 54: loss: 1.219 acc: 0.594\n",
      "\t - Step 55: loss: 1.242 acc: 0.523\n",
      "\t - Step 56: loss: 1.212 acc: 0.531\n",
      "\t - Step 57: loss: 1.268 acc: 0.500\n",
      "\t - Step 58: loss: 1.346 acc: 0.469\n",
      "\t - Step 59: loss: 1.263 acc: 0.516\n",
      "\t - Step 60: loss: 1.445 acc: 0.469\n",
      "\t - Step 61: loss: 1.370 acc: 0.508\n",
      "\t - Step 62: loss: 1.234 acc: 0.547\n",
      "\t - Step 63: loss: 1.323 acc: 0.516\n",
      "\t - Step 64: loss: 1.231 acc: 0.477\n",
      "\t - Step 65: loss: 1.376 acc: 0.484\n",
      "\t - Step 66: loss: 1.465 acc: 0.438\n",
      "\t - Step 67: loss: 1.239 acc: 0.547\n",
      "\t - Step 68: loss: 1.246 acc: 0.539\n",
      "\t - Step 69: loss: 1.308 acc: 0.531\n",
      "\t - Step 70: loss: 1.283 acc: 0.516\n",
      "\t - Step 71: loss: 1.372 acc: 0.477\n",
      "\t - Step 72: loss: 1.372 acc: 0.539\n",
      "\t - Step 73: loss: 1.290 acc: 0.523\n",
      "\t - Step 74: loss: 1.405 acc: 0.469\n",
      "\t - Step 75: loss: 1.301 acc: 0.492\n",
      "\t - Step 76: loss: 1.260 acc: 0.500\n",
      "\t - Step 77: loss: 1.385 acc: 0.492\n",
      "\t - Step 78: loss: 1.192 acc: 0.547\n",
      "\t - Step 79: loss: 1.372 acc: 0.453\n",
      "\t - Step 80: loss: 1.330 acc: 0.477\n",
      "\t - Step 81: loss: 1.224 acc: 0.602\n",
      "\t - Step 82: loss: 1.289 acc: 0.531\n",
      "\t - Step 83: loss: 1.317 acc: 0.516\n",
      "\t - Step 84: loss: 1.267 acc: 0.531\n",
      "\t - Step 85: loss: 1.185 acc: 0.578\n",
      "\t - Step 86: loss: 1.288 acc: 0.492\n",
      "\t - Step 87: loss: 1.284 acc: 0.477\n",
      "\t - Step 88: loss: 1.217 acc: 0.562\n",
      "\t - Step 89: loss: 1.398 acc: 0.469\n",
      "\t - Step 90: loss: 1.335 acc: 0.508\n",
      "\t - Step 91: loss: 1.345 acc: 0.516\n",
      "\t - Step 92: loss: 1.325 acc: 0.500\n",
      "\t - Step 93: loss: 1.250 acc: 0.555\n",
      "\t - Step 94: loss: 1.382 acc: 0.414\n",
      "\t - Step 95: loss: 1.353 acc: 0.523\n",
      "\t - Step 96: loss: 1.223 acc: 0.531\n",
      "\t - Step 97: loss: 1.296 acc: 0.555\n",
      "\t - Step 98: loss: 1.392 acc: 0.406\n",
      "\t - Step 99: loss: 1.337 acc: 0.500\n",
      "\t - Step 100: loss: 1.367 acc: 0.422\n",
      "\t - Step 101: loss: 1.385 acc: 0.484\n",
      "\t - Step 102: loss: 1.247 acc: 0.531\n",
      "\t - Step 103: loss: 1.239 acc: 0.539\n",
      "\t - Step 104: loss: 1.379 acc: 0.492\n",
      "\t - Step 105: loss: 1.225 acc: 0.562\n",
      "\t - Step 106: loss: 1.275 acc: 0.539\n",
      "\t - Step 107: loss: 1.256 acc: 0.516\n",
      "\t - Step 108: loss: 1.227 acc: 0.516\n",
      "\t - Step 109: loss: 1.357 acc: 0.484\n",
      "\t - Step 110: loss: 1.321 acc: 0.516\n",
      "\t - Step 111: loss: 1.325 acc: 0.461\n",
      "\t - Step 112: loss: 1.304 acc: 0.523\n",
      "\t - Step 113: loss: 1.163 acc: 0.617\n",
      "\t - Step 114: loss: 1.193 acc: 0.586\n",
      "\t - Step 115: loss: 1.307 acc: 0.523\n",
      "\t - Step 116: loss: 1.325 acc: 0.492\n",
      "\t - Step 117: loss: 1.231 acc: 0.516\n",
      "\t - Step 118: loss: 1.349 acc: 0.531\n",
      "\t - Step 119: loss: 1.165 acc: 0.570\n",
      "\t - Step 120: loss: 1.138 acc: 0.578\n",
      "\t - Step 121: loss: 1.371 acc: 0.523\n",
      "\t - Step 122: loss: 1.207 acc: 0.570\n",
      "\t - Step 123: loss: 1.229 acc: 0.523\n",
      "\t - Step 124: loss: 1.392 acc: 0.477\n",
      "\t - Step 125: loss: 1.289 acc: 0.539\n",
      "\t - Step 126: loss: 1.390 acc: 0.461\n",
      "\t - Step 127: loss: 1.406 acc: 0.445\n",
      "\t - Step 128: loss: 1.197 acc: 0.570\n",
      "\t - Step 129: loss: 1.231 acc: 0.523\n",
      "\t - Step 130: loss: 1.271 acc: 0.516\n",
      "\t - Step 131: loss: 1.277 acc: 0.477\n",
      "\t - Step 132: loss: 1.382 acc: 0.484\n",
      "\t - Step 133: loss: 1.270 acc: 0.500\n",
      "\t - Step 134: loss: 1.343 acc: 0.500\n",
      "\t - Step 135: loss: 1.208 acc: 0.562\n",
      "\t - Step 136: loss: 1.294 acc: 0.461\n",
      "\t - Step 137: loss: 1.314 acc: 0.516\n",
      "\t - Step 138: loss: 1.199 acc: 0.539\n",
      "\t - Step 139: loss: 1.371 acc: 0.469\n",
      "\t - Step 140: loss: 1.191 acc: 0.531\n",
      "\t - Step 141: loss: 1.321 acc: 0.531\n",
      "\t - Step 142: loss: 1.354 acc: 0.453\n",
      "\t - Step 143: loss: 1.323 acc: 0.500\n",
      "\t - Step 144: loss: 1.355 acc: 0.445\n",
      "\t - Step 145: loss: 1.300 acc: 0.523\n",
      "\t - Step 146: loss: 1.268 acc: 0.516\n",
      "\t - Step 147: loss: 1.208 acc: 0.531\n",
      "\t - Step 148: loss: 1.326 acc: 0.523\n",
      "\t - Step 149: loss: 1.241 acc: 0.562\n",
      "\t - Step 150: loss: 1.236 acc: 0.516\n",
      "\t - Step 151: loss: 1.254 acc: 0.523\n",
      "\t - Step 152: loss: 1.349 acc: 0.492\n",
      "\t - Step 153: loss: 1.335 acc: 0.492\n",
      "\t - Step 154: loss: 1.423 acc: 0.445\n",
      "\t - Step 155: loss: 1.310 acc: 0.516\n",
      "\t - Step 156: loss: 1.298 acc: 0.531\n",
      "\t - Step 157: loss: 1.441 acc: 0.516\n",
      "\t - Step 158: loss: 1.279 acc: 0.523\n",
      "\t - Step 159: loss: 1.310 acc: 0.555\n",
      "\t - Step 160: loss: 1.329 acc: 0.461\n",
      "\t - Step 161: loss: 1.288 acc: 0.531\n",
      "\t - Step 162: loss: 1.336 acc: 0.508\n",
      "\t - Step 163: loss: 1.224 acc: 0.547\n",
      "\t - Step 164: loss: 1.408 acc: 0.453\n",
      "\t - Step 165: loss: 1.181 acc: 0.547\n",
      "\t - Step 166: loss: 1.514 acc: 0.414\n",
      "\t - Step 167: loss: 1.267 acc: 0.516\n",
      "\t - Step 168: loss: 1.272 acc: 0.547\n",
      "\t - Step 169: loss: 1.262 acc: 0.539\n",
      "\t - Step 170: loss: 1.458 acc: 0.430\n",
      "\t - Step 171: loss: 1.449 acc: 0.414\n",
      "\t - Step 172: loss: 1.427 acc: 0.484\n",
      "\t - Step 173: loss: 1.315 acc: 0.516\n",
      "\t - Step 174: loss: 1.312 acc: 0.484\n",
      "\t - Step 175: loss: 1.425 acc: 0.484\n",
      "\t - Step 176: loss: 1.424 acc: 0.500\n",
      "\t - Step 177: loss: 1.280 acc: 0.500\n",
      "\t - Step 178: loss: 1.349 acc: 0.484\n",
      "\t - Step 179: loss: 1.396 acc: 0.422\n",
      "\t - Step 180: loss: 1.415 acc: 0.523\n",
      "\t - Step 181: loss: 1.338 acc: 0.453\n",
      "\t - Step 182: loss: 1.352 acc: 0.508\n",
      "\t - Step 183: loss: 1.199 acc: 0.555\n",
      "\t - Step 184: loss: 1.406 acc: 0.430\n",
      "\t - Step 185: loss: 1.387 acc: 0.438\n",
      "\t - Step 186: loss: 1.272 acc: 0.500\n",
      "\t - Step 187: loss: 1.315 acc: 0.500\n",
      "\t - Step 188: loss: 1.327 acc: 0.484\n",
      "\t - Step 189: loss: 1.321 acc: 0.531\n",
      "\t - Step 190: loss: 1.302 acc: 0.570\n",
      "\t - Step 191: loss: 1.396 acc: 0.500\n",
      "\t - Step 192: loss: 1.223 acc: 0.570\n",
      "\t - Step 193: loss: 1.353 acc: 0.445\n",
      "\t - Step 194: loss: 1.395 acc: 0.516\n",
      "\t - Step 195: loss: 1.456 acc: 0.430\n",
      "\t - Step 196: loss: 1.234 acc: 0.555\n",
      "\t - Step 197: loss: 1.240 acc: 0.484\n",
      "\t - Step 198: loss: 1.365 acc: 0.539\n",
      "\t - Step 199: loss: 1.338 acc: 0.461\n",
      "\t - Step 200: loss: 1.370 acc: 0.484\n",
      "\t - Step 201: loss: 1.212 acc: 0.555\n",
      "\t - Step 202: loss: 1.397 acc: 0.484\n",
      "\t - Step 203: loss: 1.293 acc: 0.469\n",
      "\t - Step 204: loss: 1.396 acc: 0.477\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t - Step 205: loss: 1.334 acc: 0.469\n",
      "\t - Step 206: loss: 1.344 acc: 0.508\n",
      "\t - Step 207: loss: 1.437 acc: 0.430\n",
      "\t - Step 208: loss: 1.352 acc: 0.508\n",
      "\t - Step 209: loss: 1.322 acc: 0.516\n",
      "\t - Step 210: loss: 1.265 acc: 0.547\n",
      "\t - Step 211: loss: 1.264 acc: 0.531\n",
      "\t - Step 212: loss: 1.285 acc: 0.531\n",
      "\t - Step 213: loss: 1.273 acc: 0.477\n",
      "\t - Step 214: loss: 1.309 acc: 0.484\n",
      "\t - Step 215: loss: 1.343 acc: 0.531\n",
      "\t - Step 216: loss: 1.460 acc: 0.391\n",
      "\t - Step 217: loss: 1.264 acc: 0.555\n",
      "\t - Step 218: loss: 1.386 acc: 0.422\n",
      "\t - Step 219: loss: 1.101 acc: 0.617\n",
      "\t - Step 220: loss: 1.237 acc: 0.547\n",
      "\t - Step 221: loss: 1.286 acc: 0.500\n",
      "\t - Step 222: loss: 1.176 acc: 0.570\n",
      "\t - Step 223: loss: 1.378 acc: 0.492\n",
      "\t - Step 224: loss: 1.363 acc: 0.453\n",
      "\t - Step 225: loss: 1.507 acc: 0.432\n",
      "- Avg.loss: 1.307  | Avg.acc: 0.508\n",
      "- Avg. val_loss: 1.608  | Avg. val_acc: 0.401\n",
      "Epoch:  13\n",
      "\t - Step 1: loss: 1.210 acc: 0.562\n",
      "\t - Step 2: loss: 1.180 acc: 0.570\n",
      "\t - Step 3: loss: 1.389 acc: 0.438\n",
      "\t - Step 4: loss: 1.175 acc: 0.578\n",
      "\t - Step 5: loss: 1.402 acc: 0.508\n",
      "\t - Step 6: loss: 1.401 acc: 0.445\n",
      "\t - Step 7: loss: 1.289 acc: 0.508\n",
      "\t - Step 8: loss: 1.267 acc: 0.539\n",
      "\t - Step 9: loss: 1.158 acc: 0.547\n",
      "\t - Step 10: loss: 1.236 acc: 0.547\n",
      "\t - Step 11: loss: 1.335 acc: 0.508\n",
      "\t - Step 12: loss: 1.116 acc: 0.578\n",
      "\t - Step 13: loss: 1.258 acc: 0.516\n",
      "\t - Step 14: loss: 1.293 acc: 0.555\n",
      "\t - Step 15: loss: 1.326 acc: 0.539\n",
      "\t - Step 16: loss: 1.451 acc: 0.484\n",
      "\t - Step 17: loss: 1.269 acc: 0.531\n",
      "\t - Step 18: loss: 1.258 acc: 0.484\n",
      "\t - Step 19: loss: 1.129 acc: 0.602\n",
      "\t - Step 20: loss: 1.279 acc: 0.523\n",
      "\t - Step 21: loss: 1.218 acc: 0.547\n",
      "\t - Step 22: loss: 1.383 acc: 0.508\n",
      "\t - Step 23: loss: 1.303 acc: 0.523\n",
      "\t - Step 24: loss: 1.351 acc: 0.516\n",
      "\t - Step 25: loss: 1.339 acc: 0.516\n",
      "\t - Step 26: loss: 1.257 acc: 0.578\n",
      "\t - Step 27: loss: 1.148 acc: 0.609\n",
      "\t - Step 28: loss: 1.377 acc: 0.492\n",
      "\t - Step 29: loss: 1.434 acc: 0.414\n",
      "\t - Step 30: loss: 1.359 acc: 0.469\n",
      "\t - Step 31: loss: 1.204 acc: 0.547\n",
      "\t - Step 32: loss: 1.333 acc: 0.523\n",
      "\t - Step 33: loss: 1.365 acc: 0.492\n",
      "\t - Step 34: loss: 1.402 acc: 0.406\n",
      "\t - Step 35: loss: 1.343 acc: 0.484\n",
      "\t - Step 36: loss: 1.335 acc: 0.531\n",
      "\t - Step 37: loss: 1.274 acc: 0.484\n",
      "\t - Step 38: loss: 1.312 acc: 0.500\n",
      "\t - Step 39: loss: 1.166 acc: 0.562\n",
      "\t - Step 40: loss: 1.346 acc: 0.469\n",
      "\t - Step 41: loss: 1.361 acc: 0.461\n",
      "\t - Step 42: loss: 1.351 acc: 0.469\n",
      "\t - Step 43: loss: 1.198 acc: 0.617\n",
      "\t - Step 44: loss: 1.165 acc: 0.539\n",
      "\t - Step 45: loss: 1.212 acc: 0.555\n",
      "\t - Step 46: loss: 1.321 acc: 0.523\n",
      "\t - Step 47: loss: 1.150 acc: 0.617\n",
      "\t - Step 48: loss: 1.226 acc: 0.539\n",
      "\t - Step 49: loss: 1.188 acc: 0.539\n",
      "\t - Step 50: loss: 1.341 acc: 0.469\n",
      "\t - Step 51: loss: 1.195 acc: 0.578\n",
      "\t - Step 52: loss: 1.221 acc: 0.570\n",
      "\t - Step 53: loss: 1.286 acc: 0.516\n",
      "\t - Step 54: loss: 1.298 acc: 0.461\n",
      "\t - Step 55: loss: 1.378 acc: 0.422\n",
      "\t - Step 56: loss: 1.334 acc: 0.500\n",
      "\t - Step 57: loss: 1.292 acc: 0.539\n",
      "\t - Step 58: loss: 1.284 acc: 0.484\n",
      "\t - Step 59: loss: 1.216 acc: 0.531\n",
      "\t - Step 60: loss: 1.315 acc: 0.469\n",
      "\t - Step 61: loss: 1.232 acc: 0.508\n",
      "\t - Step 62: loss: 1.423 acc: 0.375\n",
      "\t - Step 63: loss: 1.212 acc: 0.555\n",
      "\t - Step 64: loss: 1.308 acc: 0.508\n",
      "\t - Step 65: loss: 1.309 acc: 0.492\n",
      "\t - Step 66: loss: 1.216 acc: 0.570\n",
      "\t - Step 67: loss: 1.308 acc: 0.500\n",
      "\t - Step 68: loss: 1.349 acc: 0.461\n",
      "\t - Step 69: loss: 1.223 acc: 0.539\n",
      "\t - Step 70: loss: 1.230 acc: 0.508\n",
      "\t - Step 71: loss: 1.234 acc: 0.539\n",
      "\t - Step 72: loss: 1.342 acc: 0.492\n",
      "\t - Step 73: loss: 1.103 acc: 0.562\n",
      "\t - Step 74: loss: 1.190 acc: 0.570\n",
      "\t - Step 75: loss: 1.284 acc: 0.508\n",
      "\t - Step 76: loss: 1.304 acc: 0.508\n",
      "\t - Step 77: loss: 1.249 acc: 0.555\n",
      "\t - Step 78: loss: 1.281 acc: 0.578\n",
      "\t - Step 79: loss: 1.324 acc: 0.555\n",
      "\t - Step 80: loss: 1.268 acc: 0.539\n",
      "\t - Step 81: loss: 1.283 acc: 0.531\n",
      "\t - Step 82: loss: 1.180 acc: 0.539\n",
      "\t - Step 83: loss: 1.358 acc: 0.469\n",
      "\t - Step 84: loss: 1.450 acc: 0.461\n",
      "\t - Step 85: loss: 1.363 acc: 0.508\n",
      "\t - Step 86: loss: 1.414 acc: 0.422\n",
      "\t - Step 87: loss: 1.122 acc: 0.586\n",
      "\t - Step 88: loss: 1.237 acc: 0.547\n",
      "\t - Step 89: loss: 1.184 acc: 0.547\n",
      "\t - Step 90: loss: 1.258 acc: 0.508\n",
      "\t - Step 91: loss: 1.444 acc: 0.484\n",
      "\t - Step 92: loss: 1.325 acc: 0.516\n",
      "\t - Step 93: loss: 1.334 acc: 0.516\n",
      "\t - Step 94: loss: 1.456 acc: 0.453\n",
      "\t - Step 95: loss: 1.299 acc: 0.523\n",
      "\t - Step 96: loss: 1.201 acc: 0.586\n",
      "\t - Step 97: loss: 1.178 acc: 0.547\n",
      "\t - Step 98: loss: 1.333 acc: 0.461\n",
      "\t - Step 99: loss: 1.309 acc: 0.523\n",
      "\t - Step 100: loss: 1.309 acc: 0.492\n",
      "\t - Step 101: loss: 1.384 acc: 0.492\n",
      "\t - Step 102: loss: 1.353 acc: 0.484\n",
      "\t - Step 103: loss: 1.347 acc: 0.500\n",
      "\t - Step 104: loss: 1.266 acc: 0.516\n",
      "\t - Step 105: loss: 1.245 acc: 0.539\n",
      "\t - Step 106: loss: 1.284 acc: 0.445\n",
      "\t - Step 107: loss: 1.210 acc: 0.578\n",
      "\t - Step 108: loss: 1.301 acc: 0.484\n",
      "\t - Step 109: loss: 1.428 acc: 0.438\n",
      "\t - Step 110: loss: 1.400 acc: 0.445\n",
      "\t - Step 111: loss: 1.309 acc: 0.469\n",
      "\t - Step 112: loss: 1.318 acc: 0.453\n",
      "\t - Step 113: loss: 1.331 acc: 0.469\n",
      "\t - Step 114: loss: 1.266 acc: 0.570\n",
      "\t - Step 115: loss: 1.460 acc: 0.445\n",
      "\t - Step 116: loss: 1.309 acc: 0.531\n",
      "\t - Step 117: loss: 1.237 acc: 0.555\n",
      "\t - Step 118: loss: 1.355 acc: 0.477\n",
      "\t - Step 119: loss: 1.353 acc: 0.547\n",
      "\t - Step 120: loss: 1.249 acc: 0.531\n",
      "\t - Step 121: loss: 1.230 acc: 0.531\n",
      "\t - Step 122: loss: 1.267 acc: 0.492\n",
      "\t - Step 123: loss: 1.388 acc: 0.523\n",
      "\t - Step 124: loss: 1.286 acc: 0.539\n",
      "\t - Step 125: loss: 1.249 acc: 0.562\n",
      "\t - Step 126: loss: 1.339 acc: 0.461\n",
      "\t - Step 127: loss: 1.377 acc: 0.430\n",
      "\t - Step 128: loss: 1.370 acc: 0.500\n",
      "\t - Step 129: loss: 1.380 acc: 0.508\n",
      "\t - Step 130: loss: 1.306 acc: 0.523\n",
      "\t - Step 131: loss: 1.383 acc: 0.477\n",
      "\t - Step 132: loss: 1.357 acc: 0.484\n",
      "\t - Step 133: loss: 1.494 acc: 0.422\n",
      "\t - Step 134: loss: 1.368 acc: 0.461\n",
      "\t - Step 135: loss: 1.274 acc: 0.547\n",
      "\t - Step 136: loss: 1.351 acc: 0.461\n",
      "\t - Step 137: loss: 1.415 acc: 0.422\n",
      "\t - Step 138: loss: 1.399 acc: 0.461\n",
      "\t - Step 139: loss: 1.191 acc: 0.562\n",
      "\t - Step 140: loss: 1.286 acc: 0.484\n",
      "\t - Step 141: loss: 1.282 acc: 0.484\n",
      "\t - Step 142: loss: 1.289 acc: 0.523\n",
      "\t - Step 143: loss: 1.259 acc: 0.500\n",
      "\t - Step 144: loss: 1.467 acc: 0.414\n",
      "\t - Step 145: loss: 1.337 acc: 0.469\n",
      "\t - Step 146: loss: 1.263 acc: 0.523\n",
      "\t - Step 147: loss: 1.243 acc: 0.516\n",
      "\t - Step 148: loss: 1.257 acc: 0.516\n",
      "\t - Step 149: loss: 1.170 acc: 0.617\n",
      "\t - Step 150: loss: 1.392 acc: 0.461\n",
      "\t - Step 151: loss: 1.336 acc: 0.531\n",
      "\t - Step 152: loss: 1.306 acc: 0.477\n",
      "\t - Step 153: loss: 1.325 acc: 0.492\n",
      "\t - Step 154: loss: 1.323 acc: 0.508\n",
      "\t - Step 155: loss: 1.272 acc: 0.562\n",
      "\t - Step 156: loss: 1.216 acc: 0.570\n",
      "\t - Step 157: loss: 1.370 acc: 0.500\n",
      "\t - Step 158: loss: 1.411 acc: 0.438\n",
      "\t - Step 159: loss: 1.182 acc: 0.570\n",
      "\t - Step 160: loss: 1.363 acc: 0.453\n",
      "\t - Step 161: loss: 1.166 acc: 0.570\n",
      "\t - Step 162: loss: 1.276 acc: 0.594\n",
      "\t - Step 163: loss: 1.339 acc: 0.484\n",
      "\t - Step 164: loss: 1.429 acc: 0.469\n",
      "\t - Step 165: loss: 1.366 acc: 0.469\n",
      "\t - Step 166: loss: 1.327 acc: 0.500\n",
      "\t - Step 167: loss: 1.267 acc: 0.531\n",
      "\t - Step 168: loss: 1.339 acc: 0.492\n",
      "\t - Step 169: loss: 1.111 acc: 0.633\n",
      "\t - Step 170: loss: 1.509 acc: 0.383\n",
      "\t - Step 171: loss: 1.385 acc: 0.461\n",
      "\t - Step 172: loss: 1.253 acc: 0.508\n",
      "\t - Step 173: loss: 1.280 acc: 0.477\n",
      "\t - Step 174: loss: 1.286 acc: 0.508\n",
      "\t - Step 175: loss: 1.304 acc: 0.484\n",
      "\t - Step 176: loss: 1.268 acc: 0.578\n",
      "\t - Step 177: loss: 1.125 acc: 0.586\n",
      "\t - Step 178: loss: 1.153 acc: 0.562\n",
      "\t - Step 179: loss: 1.213 acc: 0.555\n",
      "\t - Step 180: loss: 1.441 acc: 0.422\n",
      "\t - Step 181: loss: 1.335 acc: 0.438\n",
      "\t - Step 182: loss: 1.262 acc: 0.492\n",
      "\t - Step 183: loss: 1.270 acc: 0.578\n",
      "\t - Step 184: loss: 1.353 acc: 0.477\n",
      "\t - Step 185: loss: 1.458 acc: 0.445\n",
      "\t - Step 186: loss: 1.326 acc: 0.508\n",
      "\t - Step 187: loss: 1.484 acc: 0.422\n",
      "\t - Step 188: loss: 1.336 acc: 0.492\n",
      "\t - Step 189: loss: 1.321 acc: 0.484\n",
      "\t - Step 190: loss: 1.303 acc: 0.539\n",
      "\t - Step 191: loss: 1.282 acc: 0.461\n",
      "\t - Step 192: loss: 1.443 acc: 0.422\n",
      "\t - Step 193: loss: 1.346 acc: 0.469\n",
      "\t - Step 194: loss: 1.327 acc: 0.500\n",
      "\t - Step 195: loss: 1.449 acc: 0.453\n",
      "\t - Step 196: loss: 1.394 acc: 0.445\n",
      "\t - Step 197: loss: 1.338 acc: 0.500\n",
      "\t - Step 198: loss: 1.194 acc: 0.555\n",
      "\t - Step 199: loss: 1.354 acc: 0.445\n",
      "\t - Step 200: loss: 1.256 acc: 0.523\n",
      "\t - Step 201: loss: 1.259 acc: 0.500\n",
      "\t - Step 202: loss: 1.189 acc: 0.562\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t - Step 203: loss: 1.358 acc: 0.469\n",
      "\t - Step 204: loss: 1.292 acc: 0.516\n",
      "\t - Step 205: loss: 1.337 acc: 0.492\n",
      "\t - Step 206: loss: 1.319 acc: 0.453\n",
      "\t - Step 207: loss: 1.134 acc: 0.547\n",
      "\t - Step 208: loss: 1.149 acc: 0.633\n",
      "\t - Step 209: loss: 1.178 acc: 0.594\n",
      "\t - Step 210: loss: 1.194 acc: 0.586\n",
      "\t - Step 211: loss: 1.451 acc: 0.453\n",
      "\t - Step 212: loss: 1.347 acc: 0.484\n",
      "\t - Step 213: loss: 1.208 acc: 0.555\n",
      "\t - Step 214: loss: 1.235 acc: 0.492\n",
      "\t - Step 215: loss: 1.173 acc: 0.555\n",
      "\t - Step 216: loss: 1.329 acc: 0.469\n",
      "\t - Step 217: loss: 1.349 acc: 0.500\n",
      "\t - Step 218: loss: 1.253 acc: 0.484\n",
      "\t - Step 219: loss: 1.304 acc: 0.531\n",
      "\t - Step 220: loss: 1.433 acc: 0.461\n",
      "\t - Step 221: loss: 1.288 acc: 0.531\n",
      "\t - Step 222: loss: 1.121 acc: 0.586\n",
      "\t - Step 223: loss: 1.264 acc: 0.508\n",
      "\t - Step 224: loss: 1.348 acc: 0.469\n",
      "\t - Step 225: loss: 1.251 acc: 0.514\n",
      "- Avg.loss: 1.298  | Avg.acc: 0.509\n",
      "- Avg. val_loss: 1.727  | Avg. val_acc: 0.409\n",
      "Epoch:  14\n",
      "\t - Step 1: loss: 1.206 acc: 0.555\n",
      "\t - Step 2: loss: 1.234 acc: 0.531\n",
      "\t - Step 3: loss: 1.288 acc: 0.562\n",
      "\t - Step 4: loss: 1.252 acc: 0.562\n",
      "\t - Step 5: loss: 1.317 acc: 0.531\n",
      "\t - Step 6: loss: 1.243 acc: 0.562\n",
      "\t - Step 7: loss: 1.363 acc: 0.453\n",
      "\t - Step 8: loss: 1.216 acc: 0.531\n",
      "\t - Step 9: loss: 1.230 acc: 0.562\n",
      "\t - Step 10: loss: 1.298 acc: 0.484\n",
      "\t - Step 11: loss: 1.310 acc: 0.438\n",
      "\t - Step 12: loss: 1.184 acc: 0.555\n",
      "\t - Step 13: loss: 1.362 acc: 0.477\n",
      "\t - Step 14: loss: 1.327 acc: 0.492\n",
      "\t - Step 15: loss: 1.159 acc: 0.562\n",
      "\t - Step 16: loss: 1.296 acc: 0.555\n",
      "\t - Step 17: loss: 1.277 acc: 0.500\n",
      "\t - Step 18: loss: 1.203 acc: 0.531\n",
      "\t - Step 19: loss: 1.320 acc: 0.547\n",
      "\t - Step 20: loss: 1.161 acc: 0.547\n",
      "\t - Step 21: loss: 1.311 acc: 0.562\n",
      "\t - Step 22: loss: 1.202 acc: 0.609\n",
      "\t - Step 23: loss: 1.291 acc: 0.477\n",
      "\t - Step 24: loss: 1.229 acc: 0.539\n",
      "\t - Step 25: loss: 1.289 acc: 0.531\n",
      "\t - Step 26: loss: 1.377 acc: 0.492\n",
      "\t - Step 27: loss: 1.456 acc: 0.453\n",
      "\t - Step 28: loss: 1.346 acc: 0.531\n",
      "\t - Step 29: loss: 1.374 acc: 0.438\n",
      "\t - Step 30: loss: 1.401 acc: 0.461\n",
      "\t - Step 31: loss: 1.422 acc: 0.492\n",
      "\t - Step 32: loss: 1.220 acc: 0.523\n",
      "\t - Step 33: loss: 1.401 acc: 0.484\n",
      "\t - Step 34: loss: 1.378 acc: 0.445\n",
      "\t - Step 35: loss: 1.279 acc: 0.523\n",
      "\t - Step 36: loss: 1.203 acc: 0.570\n",
      "\t - Step 37: loss: 1.292 acc: 0.523\n",
      "\t - Step 38: loss: 1.267 acc: 0.516\n",
      "\t - Step 39: loss: 1.206 acc: 0.562\n",
      "\t - Step 40: loss: 1.345 acc: 0.438\n",
      "\t - Step 41: loss: 1.268 acc: 0.516\n",
      "\t - Step 42: loss: 1.264 acc: 0.516\n",
      "\t - Step 43: loss: 1.341 acc: 0.539\n",
      "\t - Step 44: loss: 1.367 acc: 0.523\n",
      "\t - Step 45: loss: 1.227 acc: 0.555\n",
      "\t - Step 46: loss: 1.337 acc: 0.469\n",
      "\t - Step 47: loss: 1.320 acc: 0.516\n",
      "\t - Step 48: loss: 1.257 acc: 0.562\n",
      "\t - Step 49: loss: 1.275 acc: 0.477\n",
      "\t - Step 50: loss: 1.207 acc: 0.531\n",
      "\t - Step 51: loss: 1.355 acc: 0.477\n",
      "\t - Step 52: loss: 1.187 acc: 0.523\n",
      "\t - Step 53: loss: 1.241 acc: 0.523\n",
      "\t - Step 54: loss: 1.194 acc: 0.570\n",
      "\t - Step 55: loss: 1.234 acc: 0.578\n",
      "\t - Step 56: loss: 1.313 acc: 0.430\n",
      "\t - Step 57: loss: 1.121 acc: 0.586\n",
      "\t - Step 58: loss: 1.370 acc: 0.492\n",
      "\t - Step 59: loss: 1.167 acc: 0.617\n",
      "\t - Step 60: loss: 1.296 acc: 0.508\n",
      "\t - Step 61: loss: 1.156 acc: 0.531\n",
      "\t - Step 62: loss: 1.315 acc: 0.555\n",
      "\t - Step 63: loss: 1.222 acc: 0.547\n",
      "\t - Step 64: loss: 1.414 acc: 0.430\n",
      "\t - Step 65: loss: 1.299 acc: 0.523\n",
      "\t - Step 66: loss: 1.164 acc: 0.547\n",
      "\t - Step 67: loss: 1.281 acc: 0.594\n",
      "\t - Step 68: loss: 1.403 acc: 0.484\n",
      "\t - Step 69: loss: 1.268 acc: 0.516\n",
      "\t - Step 70: loss: 1.238 acc: 0.523\n",
      "\t - Step 71: loss: 1.229 acc: 0.594\n",
      "\t - Step 72: loss: 1.228 acc: 0.516\n",
      "\t - Step 73: loss: 1.156 acc: 0.562\n",
      "\t - Step 74: loss: 1.223 acc: 0.602\n",
      "\t - Step 75: loss: 1.224 acc: 0.523\n",
      "\t - Step 76: loss: 1.303 acc: 0.500\n",
      "\t - Step 77: loss: 1.231 acc: 0.516\n",
      "\t - Step 78: loss: 1.459 acc: 0.453\n",
      "\t - Step 79: loss: 1.424 acc: 0.430\n",
      "\t - Step 80: loss: 1.405 acc: 0.484\n",
      "\t - Step 81: loss: 1.257 acc: 0.500\n",
      "\t - Step 82: loss: 1.133 acc: 0.578\n",
      "\t - Step 83: loss: 1.267 acc: 0.469\n",
      "\t - Step 84: loss: 1.315 acc: 0.477\n",
      "\t - Step 85: loss: 1.197 acc: 0.562\n",
      "\t - Step 86: loss: 1.271 acc: 0.531\n",
      "\t - Step 87: loss: 1.285 acc: 0.531\n",
      "\t - Step 88: loss: 1.253 acc: 0.500\n",
      "\t - Step 89: loss: 1.371 acc: 0.445\n",
      "\t - Step 90: loss: 1.353 acc: 0.477\n",
      "\t - Step 91: loss: 1.245 acc: 0.508\n",
      "\t - Step 92: loss: 1.269 acc: 0.500\n",
      "\t - Step 93: loss: 1.226 acc: 0.539\n",
      "\t - Step 94: loss: 1.349 acc: 0.516\n",
      "\t - Step 95: loss: 1.340 acc: 0.500\n",
      "\t - Step 96: loss: 1.203 acc: 0.555\n",
      "\t - Step 97: loss: 1.358 acc: 0.445\n",
      "\t - Step 98: loss: 1.287 acc: 0.508\n",
      "\t - Step 99: loss: 1.157 acc: 0.578\n",
      "\t - Step 100: loss: 1.321 acc: 0.516\n",
      "\t - Step 101: loss: 1.308 acc: 0.508\n",
      "\t - Step 102: loss: 1.378 acc: 0.453\n",
      "\t - Step 103: loss: 1.217 acc: 0.555\n",
      "\t - Step 104: loss: 1.281 acc: 0.461\n",
      "\t - Step 105: loss: 1.426 acc: 0.461\n",
      "\t - Step 106: loss: 1.303 acc: 0.531\n",
      "\t - Step 107: loss: 1.273 acc: 0.492\n",
      "\t - Step 108: loss: 1.324 acc: 0.523\n",
      "\t - Step 109: loss: 1.221 acc: 0.602\n",
      "\t - Step 110: loss: 1.291 acc: 0.562\n",
      "\t - Step 111: loss: 1.338 acc: 0.531\n",
      "\t - Step 112: loss: 1.267 acc: 0.516\n",
      "\t - Step 113: loss: 1.350 acc: 0.500\n",
      "\t - Step 114: loss: 1.329 acc: 0.508\n",
      "\t - Step 115: loss: 1.261 acc: 0.516\n",
      "\t - Step 116: loss: 1.221 acc: 0.500\n",
      "\t - Step 117: loss: 1.257 acc: 0.508\n",
      "\t - Step 118: loss: 1.320 acc: 0.531\n",
      "\t - Step 119: loss: 1.364 acc: 0.477\n",
      "\t - Step 120: loss: 1.324 acc: 0.578\n",
      "\t - Step 121: loss: 1.581 acc: 0.383\n",
      "\t - Step 122: loss: 1.187 acc: 0.555\n",
      "\t - Step 123: loss: 1.402 acc: 0.477\n",
      "\t - Step 124: loss: 1.279 acc: 0.461\n",
      "\t - Step 125: loss: 1.277 acc: 0.570\n",
      "\t - Step 126: loss: 1.209 acc: 0.516\n",
      "\t - Step 127: loss: 1.404 acc: 0.469\n",
      "\t - Step 128: loss: 1.255 acc: 0.516\n",
      "\t - Step 129: loss: 1.219 acc: 0.570\n",
      "\t - Step 130: loss: 1.205 acc: 0.570\n",
      "\t - Step 131: loss: 1.376 acc: 0.508\n",
      "\t - Step 132: loss: 1.260 acc: 0.500\n",
      "\t - Step 133: loss: 1.189 acc: 0.602\n",
      "\t - Step 134: loss: 1.343 acc: 0.500\n",
      "\t - Step 135: loss: 1.262 acc: 0.508\n",
      "\t - Step 136: loss: 1.249 acc: 0.570\n",
      "\t - Step 137: loss: 1.247 acc: 0.539\n",
      "\t - Step 138: loss: 1.296 acc: 0.508\n",
      "\t - Step 139: loss: 1.336 acc: 0.508\n",
      "\t - Step 140: loss: 1.315 acc: 0.484\n",
      "\t - Step 141: loss: 1.403 acc: 0.453\n",
      "\t - Step 142: loss: 1.385 acc: 0.484\n",
      "\t - Step 143: loss: 1.192 acc: 0.570\n",
      "\t - Step 144: loss: 1.307 acc: 0.508\n",
      "\t - Step 145: loss: 1.217 acc: 0.547\n",
      "\t - Step 146: loss: 1.163 acc: 0.586\n",
      "\t - Step 147: loss: 1.389 acc: 0.453\n",
      "\t - Step 148: loss: 1.351 acc: 0.445\n",
      "\t - Step 149: loss: 1.287 acc: 0.492\n",
      "\t - Step 150: loss: 1.343 acc: 0.531\n",
      "\t - Step 151: loss: 1.311 acc: 0.508\n",
      "\t - Step 152: loss: 1.431 acc: 0.438\n",
      "\t - Step 153: loss: 1.264 acc: 0.523\n",
      "\t - Step 154: loss: 1.295 acc: 0.500\n",
      "\t - Step 155: loss: 1.336 acc: 0.508\n",
      "\t - Step 156: loss: 1.189 acc: 0.562\n",
      "\t - Step 157: loss: 1.349 acc: 0.500\n",
      "\t - Step 158: loss: 1.260 acc: 0.570\n",
      "\t - Step 159: loss: 1.262 acc: 0.602\n",
      "\t - Step 160: loss: 1.299 acc: 0.500\n",
      "\t - Step 161: loss: 1.272 acc: 0.453\n",
      "\t - Step 162: loss: 1.186 acc: 0.617\n",
      "\t - Step 163: loss: 1.238 acc: 0.516\n",
      "\t - Step 164: loss: 1.406 acc: 0.469\n",
      "\t - Step 165: loss: 1.175 acc: 0.516\n",
      "\t - Step 166: loss: 1.251 acc: 0.570\n",
      "\t - Step 167: loss: 1.314 acc: 0.547\n",
      "\t - Step 168: loss: 1.287 acc: 0.555\n",
      "\t - Step 169: loss: 1.274 acc: 0.531\n",
      "\t - Step 170: loss: 1.220 acc: 0.539\n",
      "\t - Step 171: loss: 1.274 acc: 0.547\n",
      "\t - Step 172: loss: 1.296 acc: 0.539\n",
      "\t - Step 173: loss: 1.410 acc: 0.484\n",
      "\t - Step 174: loss: 1.392 acc: 0.461\n",
      "\t - Step 175: loss: 1.320 acc: 0.500\n",
      "\t - Step 176: loss: 1.318 acc: 0.477\n",
      "\t - Step 177: loss: 1.393 acc: 0.477\n",
      "\t - Step 178: loss: 1.380 acc: 0.484\n",
      "\t - Step 179: loss: 1.304 acc: 0.461\n",
      "\t - Step 180: loss: 1.329 acc: 0.492\n",
      "\t - Step 181: loss: 1.308 acc: 0.508\n",
      "\t - Step 182: loss: 1.193 acc: 0.570\n",
      "\t - Step 183: loss: 1.242 acc: 0.531\n",
      "\t - Step 184: loss: 1.360 acc: 0.477\n",
      "\t - Step 185: loss: 1.348 acc: 0.492\n",
      "\t - Step 186: loss: 1.226 acc: 0.539\n",
      "\t - Step 187: loss: 1.433 acc: 0.523\n",
      "\t - Step 188: loss: 1.664 acc: 0.375\n",
      "\t - Step 189: loss: 1.368 acc: 0.461\n",
      "\t - Step 190: loss: 1.425 acc: 0.500\n",
      "\t - Step 191: loss: 1.256 acc: 0.547\n",
      "\t - Step 192: loss: 1.418 acc: 0.445\n",
      "\t - Step 193: loss: 1.254 acc: 0.516\n",
      "\t - Step 194: loss: 1.439 acc: 0.461\n",
      "\t - Step 195: loss: 1.290 acc: 0.492\n",
      "\t - Step 196: loss: 1.240 acc: 0.539\n",
      "\t - Step 197: loss: 1.337 acc: 0.492\n",
      "\t - Step 198: loss: 1.288 acc: 0.586\n",
      "\t - Step 199: loss: 1.258 acc: 0.539\n",
      "\t - Step 200: loss: 1.378 acc: 0.453\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t - Step 201: loss: 1.276 acc: 0.508\n",
      "\t - Step 202: loss: 1.283 acc: 0.492\n",
      "\t - Step 203: loss: 1.398 acc: 0.438\n",
      "\t - Step 204: loss: 1.261 acc: 0.484\n",
      "\t - Step 205: loss: 1.413 acc: 0.477\n",
      "\t - Step 206: loss: 1.192 acc: 0.500\n",
      "\t - Step 207: loss: 1.216 acc: 0.523\n",
      "\t - Step 208: loss: 1.260 acc: 0.547\n",
      "\t - Step 209: loss: 1.277 acc: 0.523\n",
      "\t - Step 210: loss: 1.396 acc: 0.484\n",
      "\t - Step 211: loss: 1.311 acc: 0.477\n",
      "\t - Step 212: loss: 1.212 acc: 0.547\n",
      "\t - Step 213: loss: 1.407 acc: 0.484\n",
      "\t - Step 214: loss: 1.232 acc: 0.531\n",
      "\t - Step 215: loss: 1.255 acc: 0.531\n",
      "\t - Step 216: loss: 1.230 acc: 0.531\n",
      "\t - Step 217: loss: 1.422 acc: 0.453\n",
      "\t - Step 218: loss: 1.311 acc: 0.555\n",
      "\t - Step 219: loss: 1.375 acc: 0.492\n",
      "\t - Step 220: loss: 1.328 acc: 0.500\n",
      "\t - Step 221: loss: 1.369 acc: 0.500\n",
      "\t - Step 222: loss: 1.294 acc: 0.500\n",
      "\t - Step 223: loss: 1.517 acc: 0.414\n",
      "\t - Step 224: loss: 1.420 acc: 0.430\n",
      "\t - Step 225: loss: 1.231 acc: 0.514\n",
      "- Avg.loss: 1.296  | Avg.acc: 0.513\n",
      "- Avg. val_loss: 1.517  | Avg. val_acc: 0.441\n",
      "* Update optimal model\n",
      "Epoch:  15\n",
      "\t - Step 1: loss: 1.174 acc: 0.531\n",
      "\t - Step 2: loss: 1.239 acc: 0.547\n",
      "\t - Step 3: loss: 1.230 acc: 0.508\n",
      "\t - Step 4: loss: 1.194 acc: 0.531\n",
      "\t - Step 5: loss: 1.309 acc: 0.445\n",
      "\t - Step 6: loss: 1.310 acc: 0.516\n",
      "\t - Step 7: loss: 1.229 acc: 0.508\n",
      "\t - Step 8: loss: 1.296 acc: 0.508\n",
      "\t - Step 9: loss: 1.209 acc: 0.531\n",
      "\t - Step 10: loss: 1.193 acc: 0.539\n",
      "\t - Step 11: loss: 1.304 acc: 0.547\n",
      "\t - Step 12: loss: 1.305 acc: 0.461\n",
      "\t - Step 13: loss: 1.206 acc: 0.539\n",
      "\t - Step 14: loss: 1.432 acc: 0.461\n",
      "\t - Step 15: loss: 1.480 acc: 0.438\n",
      "\t - Step 16: loss: 1.345 acc: 0.484\n",
      "\t - Step 17: loss: 1.189 acc: 0.578\n",
      "\t - Step 18: loss: 1.130 acc: 0.594\n",
      "\t - Step 19: loss: 1.183 acc: 0.578\n",
      "\t - Step 20: loss: 1.201 acc: 0.586\n",
      "\t - Step 21: loss: 1.237 acc: 0.547\n",
      "\t - Step 22: loss: 1.349 acc: 0.508\n",
      "\t - Step 23: loss: 1.204 acc: 0.586\n",
      "\t - Step 24: loss: 1.222 acc: 0.547\n",
      "\t - Step 25: loss: 1.307 acc: 0.508\n",
      "\t - Step 26: loss: 1.319 acc: 0.492\n",
      "\t - Step 27: loss: 1.310 acc: 0.547\n",
      "\t - Step 28: loss: 1.262 acc: 0.500\n",
      "\t - Step 29: loss: 1.151 acc: 0.539\n",
      "\t - Step 30: loss: 1.264 acc: 0.500\n",
      "\t - Step 31: loss: 1.188 acc: 0.516\n",
      "\t - Step 32: loss: 1.242 acc: 0.570\n",
      "\t - Step 33: loss: 1.215 acc: 0.594\n",
      "\t - Step 34: loss: 1.374 acc: 0.438\n",
      "\t - Step 35: loss: 1.251 acc: 0.539\n",
      "\t - Step 36: loss: 1.346 acc: 0.539\n",
      "\t - Step 37: loss: 1.359 acc: 0.469\n",
      "\t - Step 38: loss: 1.397 acc: 0.516\n",
      "\t - Step 39: loss: 1.251 acc: 0.516\n",
      "\t - Step 40: loss: 1.198 acc: 0.508\n",
      "\t - Step 41: loss: 1.214 acc: 0.531\n",
      "\t - Step 42: loss: 1.323 acc: 0.539\n",
      "\t - Step 43: loss: 1.220 acc: 0.594\n",
      "\t - Step 44: loss: 1.431 acc: 0.500\n",
      "\t - Step 45: loss: 1.355 acc: 0.430\n",
      "\t - Step 46: loss: 1.446 acc: 0.461\n",
      "\t - Step 47: loss: 1.270 acc: 0.516\n",
      "\t - Step 48: loss: 1.268 acc: 0.570\n",
      "\t - Step 49: loss: 1.321 acc: 0.516\n",
      "\t - Step 50: loss: 1.325 acc: 0.453\n",
      "\t - Step 51: loss: 1.284 acc: 0.523\n",
      "\t - Step 52: loss: 1.178 acc: 0.508\n",
      "\t - Step 53: loss: 1.142 acc: 0.594\n",
      "\t - Step 54: loss: 1.290 acc: 0.539\n",
      "\t - Step 55: loss: 1.039 acc: 0.641\n",
      "\t - Step 56: loss: 1.316 acc: 0.547\n",
      "\t - Step 57: loss: 1.406 acc: 0.453\n",
      "\t - Step 58: loss: 1.187 acc: 0.531\n",
      "\t - Step 59: loss: 1.338 acc: 0.523\n",
      "\t - Step 60: loss: 1.235 acc: 0.555\n",
      "\t - Step 61: loss: 1.323 acc: 0.477\n",
      "\t - Step 62: loss: 1.325 acc: 0.484\n",
      "\t - Step 63: loss: 1.430 acc: 0.469\n",
      "\t - Step 64: loss: 1.279 acc: 0.492\n",
      "\t - Step 65: loss: 1.333 acc: 0.539\n",
      "\t - Step 66: loss: 1.420 acc: 0.445\n",
      "\t - Step 67: loss: 1.219 acc: 0.523\n",
      "\t - Step 68: loss: 1.357 acc: 0.461\n",
      "\t - Step 69: loss: 1.203 acc: 0.516\n",
      "\t - Step 70: loss: 1.242 acc: 0.617\n",
      "\t - Step 71: loss: 1.193 acc: 0.562\n",
      "\t - Step 72: loss: 1.392 acc: 0.477\n",
      "\t - Step 73: loss: 1.389 acc: 0.461\n",
      "\t - Step 74: loss: 1.315 acc: 0.500\n",
      "\t - Step 75: loss: 1.225 acc: 0.555\n",
      "\t - Step 76: loss: 1.211 acc: 0.531\n",
      "\t - Step 77: loss: 1.229 acc: 0.555\n",
      "\t - Step 78: loss: 1.287 acc: 0.508\n",
      "\t - Step 79: loss: 1.334 acc: 0.516\n",
      "\t - Step 80: loss: 1.325 acc: 0.477\n",
      "\t - Step 81: loss: 1.323 acc: 0.477\n",
      "\t - Step 82: loss: 1.260 acc: 0.484\n",
      "\t - Step 83: loss: 1.266 acc: 0.555\n",
      "\t - Step 84: loss: 1.268 acc: 0.539\n",
      "\t - Step 85: loss: 1.396 acc: 0.422\n",
      "\t - Step 86: loss: 1.245 acc: 0.492\n",
      "\t - Step 87: loss: 1.194 acc: 0.562\n",
      "\t - Step 88: loss: 1.467 acc: 0.477\n",
      "\t - Step 89: loss: 1.183 acc: 0.570\n",
      "\t - Step 90: loss: 1.200 acc: 0.555\n",
      "\t - Step 91: loss: 1.287 acc: 0.453\n",
      "\t - Step 92: loss: 1.298 acc: 0.477\n",
      "\t - Step 93: loss: 1.208 acc: 0.539\n",
      "\t - Step 94: loss: 1.233 acc: 0.586\n",
      "\t - Step 95: loss: 1.342 acc: 0.477\n",
      "\t - Step 96: loss: 1.232 acc: 0.531\n",
      "\t - Step 97: loss: 1.285 acc: 0.539\n",
      "\t - Step 98: loss: 1.238 acc: 0.539\n",
      "\t - Step 99: loss: 1.285 acc: 0.539\n",
      "\t - Step 100: loss: 1.239 acc: 0.492\n",
      "\t - Step 101: loss: 1.310 acc: 0.523\n",
      "\t - Step 102: loss: 1.139 acc: 0.617\n",
      "\t - Step 103: loss: 1.306 acc: 0.492\n",
      "\t - Step 104: loss: 1.251 acc: 0.562\n",
      "\t - Step 105: loss: 1.297 acc: 0.500\n",
      "\t - Step 106: loss: 1.217 acc: 0.547\n",
      "\t - Step 107: loss: 1.189 acc: 0.570\n",
      "\t - Step 108: loss: 1.320 acc: 0.500\n",
      "\t - Step 109: loss: 1.337 acc: 0.508\n",
      "\t - Step 110: loss: 1.392 acc: 0.453\n",
      "\t - Step 111: loss: 1.304 acc: 0.547\n",
      "\t - Step 112: loss: 1.240 acc: 0.578\n",
      "\t - Step 113: loss: 1.217 acc: 0.594\n",
      "\t - Step 114: loss: 1.238 acc: 0.508\n",
      "\t - Step 115: loss: 1.240 acc: 0.555\n",
      "\t - Step 116: loss: 1.226 acc: 0.547\n",
      "\t - Step 117: loss: 1.242 acc: 0.484\n",
      "\t - Step 118: loss: 1.337 acc: 0.547\n",
      "\t - Step 119: loss: 1.420 acc: 0.492\n",
      "\t - Step 120: loss: 1.334 acc: 0.547\n",
      "\t - Step 121: loss: 1.177 acc: 0.570\n",
      "\t - Step 122: loss: 1.323 acc: 0.508\n",
      "\t - Step 123: loss: 1.319 acc: 0.531\n",
      "\t - Step 124: loss: 1.268 acc: 0.523\n",
      "\t - Step 125: loss: 1.195 acc: 0.578\n",
      "\t - Step 126: loss: 1.346 acc: 0.461\n",
      "\t - Step 127: loss: 1.302 acc: 0.469\n",
      "\t - Step 128: loss: 1.419 acc: 0.422\n",
      "\t - Step 129: loss: 1.299 acc: 0.484\n",
      "\t - Step 130: loss: 1.418 acc: 0.461\n",
      "\t - Step 131: loss: 1.299 acc: 0.484\n",
      "\t - Step 132: loss: 1.222 acc: 0.562\n",
      "\t - Step 133: loss: 1.432 acc: 0.453\n",
      "\t - Step 134: loss: 1.280 acc: 0.508\n",
      "\t - Step 135: loss: 1.167 acc: 0.562\n",
      "\t - Step 136: loss: 1.299 acc: 0.453\n",
      "\t - Step 137: loss: 1.174 acc: 0.555\n",
      "\t - Step 138: loss: 1.272 acc: 0.555\n",
      "\t - Step 139: loss: 1.445 acc: 0.430\n",
      "\t - Step 140: loss: 1.150 acc: 0.562\n",
      "\t - Step 141: loss: 1.229 acc: 0.523\n",
      "\t - Step 142: loss: 1.308 acc: 0.484\n",
      "\t - Step 143: loss: 1.292 acc: 0.508\n",
      "\t - Step 144: loss: 1.286 acc: 0.484\n",
      "\t - Step 145: loss: 1.221 acc: 0.578\n",
      "\t - Step 146: loss: 1.141 acc: 0.625\n",
      "\t - Step 147: loss: 1.342 acc: 0.453\n",
      "\t - Step 148: loss: 1.188 acc: 0.508\n",
      "\t - Step 149: loss: 1.205 acc: 0.492\n",
      "\t - Step 150: loss: 1.200 acc: 0.562\n",
      "\t - Step 151: loss: 1.128 acc: 0.547\n",
      "\t - Step 152: loss: 1.303 acc: 0.523\n",
      "\t - Step 153: loss: 1.258 acc: 0.562\n",
      "\t - Step 154: loss: 1.183 acc: 0.555\n",
      "\t - Step 155: loss: 1.251 acc: 0.492\n",
      "\t - Step 156: loss: 1.262 acc: 0.523\n",
      "\t - Step 157: loss: 1.382 acc: 0.500\n",
      "\t - Step 158: loss: 1.141 acc: 0.570\n",
      "\t - Step 159: loss: 1.288 acc: 0.500\n",
      "\t - Step 160: loss: 1.308 acc: 0.531\n",
      "\t - Step 161: loss: 1.131 acc: 0.656\n",
      "\t - Step 162: loss: 1.259 acc: 0.547\n",
      "\t - Step 163: loss: 1.306 acc: 0.500\n",
      "\t - Step 164: loss: 1.241 acc: 0.492\n",
      "\t - Step 165: loss: 1.499 acc: 0.445\n",
      "\t - Step 166: loss: 1.361 acc: 0.477\n",
      "\t - Step 167: loss: 1.379 acc: 0.477\n",
      "\t - Step 168: loss: 1.483 acc: 0.445\n",
      "\t - Step 169: loss: 1.238 acc: 0.492\n",
      "\t - Step 170: loss: 1.357 acc: 0.383\n",
      "\t - Step 171: loss: 1.259 acc: 0.516\n",
      "\t - Step 172: loss: 1.250 acc: 0.523\n",
      "\t - Step 173: loss: 1.338 acc: 0.484\n",
      "\t - Step 174: loss: 1.235 acc: 0.562\n",
      "\t - Step 175: loss: 1.285 acc: 0.531\n",
      "\t - Step 176: loss: 1.366 acc: 0.492\n",
      "\t - Step 177: loss: 1.338 acc: 0.477\n",
      "\t - Step 178: loss: 1.326 acc: 0.484\n",
      "\t - Step 179: loss: 1.281 acc: 0.492\n",
      "\t - Step 180: loss: 1.225 acc: 0.570\n",
      "\t - Step 181: loss: 1.416 acc: 0.523\n",
      "\t - Step 182: loss: 1.397 acc: 0.461\n",
      "\t - Step 183: loss: 1.321 acc: 0.477\n",
      "\t - Step 184: loss: 1.377 acc: 0.438\n",
      "\t - Step 185: loss: 1.323 acc: 0.516\n",
      "\t - Step 186: loss: 1.303 acc: 0.523\n",
      "\t - Step 187: loss: 1.209 acc: 0.555\n",
      "\t - Step 188: loss: 1.193 acc: 0.531\n",
      "\t - Step 189: loss: 1.276 acc: 0.531\n",
      "\t - Step 190: loss: 1.372 acc: 0.461\n",
      "\t - Step 191: loss: 1.316 acc: 0.469\n",
      "\t - Step 192: loss: 1.280 acc: 0.547\n",
      "\t - Step 193: loss: 1.229 acc: 0.562\n",
      "\t - Step 194: loss: 1.289 acc: 0.555\n",
      "\t - Step 195: loss: 1.251 acc: 0.547\n",
      "\t - Step 196: loss: 1.335 acc: 0.508\n",
      "\t - Step 197: loss: 1.256 acc: 0.516\n",
      "\t - Step 198: loss: 1.261 acc: 0.562\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t - Step 199: loss: 1.215 acc: 0.531\n",
      "\t - Step 200: loss: 1.276 acc: 0.516\n",
      "\t - Step 201: loss: 1.251 acc: 0.570\n",
      "\t - Step 202: loss: 1.245 acc: 0.531\n",
      "\t - Step 203: loss: 1.237 acc: 0.562\n",
      "\t - Step 204: loss: 1.322 acc: 0.477\n",
      "\t - Step 205: loss: 1.338 acc: 0.484\n",
      "\t - Step 206: loss: 1.203 acc: 0.547\n",
      "\t - Step 207: loss: 1.270 acc: 0.508\n",
      "\t - Step 208: loss: 1.487 acc: 0.414\n",
      "\t - Step 209: loss: 1.366 acc: 0.492\n",
      "\t - Step 210: loss: 1.441 acc: 0.367\n",
      "\t - Step 211: loss: 1.188 acc: 0.531\n",
      "\t - Step 212: loss: 1.257 acc: 0.555\n",
      "\t - Step 213: loss: 1.416 acc: 0.508\n",
      "\t - Step 214: loss: 1.259 acc: 0.523\n",
      "\t - Step 215: loss: 1.255 acc: 0.531\n",
      "\t - Step 216: loss: 1.373 acc: 0.570\n",
      "\t - Step 217: loss: 1.384 acc: 0.492\n",
      "\t - Step 218: loss: 1.283 acc: 0.477\n",
      "\t - Step 219: loss: 1.348 acc: 0.492\n",
      "\t - Step 220: loss: 1.337 acc: 0.516\n",
      "\t - Step 221: loss: 1.363 acc: 0.461\n",
      "\t - Step 222: loss: 1.370 acc: 0.453\n",
      "\t - Step 223: loss: 1.230 acc: 0.492\n",
      "\t - Step 224: loss: 1.348 acc: 0.445\n",
      "\t - Step 225: loss: 1.549 acc: 0.486\n",
      "- Avg.loss: 1.285  | Avg.acc: 0.516\n",
      "- Avg. val_loss: 1.690  | Avg. val_acc: 0.398\n",
      "Epoch:  16\n",
      "\t - Step 1: loss: 1.261 acc: 0.500\n",
      "\t - Step 2: loss: 1.299 acc: 0.539\n",
      "\t - Step 3: loss: 1.208 acc: 0.578\n",
      "\t - Step 4: loss: 1.193 acc: 0.562\n",
      "\t - Step 5: loss: 1.232 acc: 0.547\n",
      "\t - Step 6: loss: 1.259 acc: 0.547\n",
      "\t - Step 7: loss: 1.315 acc: 0.539\n",
      "\t - Step 8: loss: 1.402 acc: 0.453\n",
      "\t - Step 9: loss: 1.260 acc: 0.531\n",
      "\t - Step 10: loss: 1.202 acc: 0.570\n",
      "\t - Step 11: loss: 1.230 acc: 0.562\n",
      "\t - Step 12: loss: 1.214 acc: 0.508\n",
      "\t - Step 13: loss: 1.205 acc: 0.531\n",
      "\t - Step 14: loss: 1.348 acc: 0.445\n",
      "\t - Step 15: loss: 1.158 acc: 0.578\n",
      "\t - Step 16: loss: 1.253 acc: 0.547\n",
      "\t - Step 17: loss: 1.411 acc: 0.461\n",
      "\t - Step 18: loss: 1.216 acc: 0.570\n",
      "\t - Step 19: loss: 1.230 acc: 0.477\n",
      "\t - Step 20: loss: 1.277 acc: 0.531\n",
      "\t - Step 21: loss: 1.269 acc: 0.555\n",
      "\t - Step 22: loss: 1.249 acc: 0.523\n",
      "\t - Step 23: loss: 1.346 acc: 0.469\n",
      "\t - Step 24: loss: 1.219 acc: 0.516\n",
      "\t - Step 25: loss: 1.132 acc: 0.648\n",
      "\t - Step 26: loss: 1.202 acc: 0.500\n",
      "\t - Step 27: loss: 1.323 acc: 0.484\n",
      "\t - Step 28: loss: 1.411 acc: 0.406\n",
      "\t - Step 29: loss: 1.412 acc: 0.445\n",
      "\t - Step 30: loss: 1.366 acc: 0.484\n",
      "\t - Step 31: loss: 1.314 acc: 0.477\n",
      "\t - Step 32: loss: 1.213 acc: 0.602\n",
      "\t - Step 33: loss: 1.331 acc: 0.469\n",
      "\t - Step 34: loss: 1.371 acc: 0.484\n",
      "\t - Step 35: loss: 1.199 acc: 0.570\n",
      "\t - Step 36: loss: 1.314 acc: 0.453\n",
      "\t - Step 37: loss: 1.280 acc: 0.547\n",
      "\t - Step 38: loss: 1.329 acc: 0.484\n",
      "\t - Step 39: loss: 1.368 acc: 0.477\n",
      "\t - Step 40: loss: 1.291 acc: 0.539\n",
      "\t - Step 41: loss: 1.218 acc: 0.500\n",
      "\t - Step 42: loss: 1.275 acc: 0.523\n",
      "\t - Step 43: loss: 1.137 acc: 0.625\n",
      "\t - Step 44: loss: 1.198 acc: 0.570\n",
      "\t - Step 45: loss: 1.230 acc: 0.562\n",
      "\t - Step 46: loss: 1.260 acc: 0.484\n",
      "\t - Step 47: loss: 1.346 acc: 0.461\n",
      "\t - Step 48: loss: 1.312 acc: 0.547\n",
      "\t - Step 49: loss: 1.193 acc: 0.516\n",
      "\t - Step 50: loss: 1.194 acc: 0.562\n",
      "\t - Step 51: loss: 1.189 acc: 0.547\n",
      "\t - Step 52: loss: 1.205 acc: 0.602\n",
      "\t - Step 53: loss: 1.303 acc: 0.539\n",
      "\t - Step 54: loss: 1.202 acc: 0.516\n",
      "\t - Step 55: loss: 1.200 acc: 0.516\n",
      "\t - Step 56: loss: 1.210 acc: 0.570\n",
      "\t - Step 57: loss: 1.274 acc: 0.547\n",
      "\t - Step 58: loss: 1.270 acc: 0.555\n",
      "\t - Step 59: loss: 1.296 acc: 0.531\n",
      "\t - Step 60: loss: 1.122 acc: 0.555\n",
      "\t - Step 61: loss: 1.182 acc: 0.547\n",
      "\t - Step 62: loss: 1.245 acc: 0.555\n",
      "\t - Step 63: loss: 1.134 acc: 0.578\n",
      "\t - Step 64: loss: 1.137 acc: 0.523\n",
      "\t - Step 65: loss: 1.135 acc: 0.570\n",
      "\t - Step 66: loss: 1.296 acc: 0.500\n",
      "\t - Step 67: loss: 1.149 acc: 0.516\n",
      "\t - Step 68: loss: 1.318 acc: 0.492\n",
      "\t - Step 69: loss: 1.238 acc: 0.445\n",
      "\t - Step 70: loss: 1.339 acc: 0.508\n",
      "\t - Step 71: loss: 1.251 acc: 0.469\n",
      "\t - Step 72: loss: 1.098 acc: 0.508\n",
      "\t - Step 73: loss: 1.139 acc: 0.539\n",
      "\t - Step 74: loss: 1.422 acc: 0.500\n",
      "\t - Step 75: loss: 1.236 acc: 0.516\n",
      "\t - Step 76: loss: 1.319 acc: 0.508\n",
      "\t - Step 77: loss: 1.234 acc: 0.531\n",
      "\t - Step 78: loss: 1.066 acc: 0.617\n",
      "\t - Step 79: loss: 1.204 acc: 0.531\n",
      "\t - Step 80: loss: 1.296 acc: 0.484\n",
      "\t - Step 81: loss: 1.342 acc: 0.469\n",
      "\t - Step 82: loss: 1.228 acc: 0.523\n",
      "\t - Step 83: loss: 1.472 acc: 0.438\n",
      "\t - Step 84: loss: 1.173 acc: 0.531\n",
      "\t - Step 85: loss: 1.265 acc: 0.508\n",
      "\t - Step 86: loss: 1.362 acc: 0.477\n",
      "\t - Step 87: loss: 1.197 acc: 0.555\n",
      "\t - Step 88: loss: 1.217 acc: 0.555\n",
      "\t - Step 89: loss: 1.260 acc: 0.500\n",
      "\t - Step 90: loss: 1.337 acc: 0.469\n",
      "\t - Step 91: loss: 1.319 acc: 0.523\n",
      "\t - Step 92: loss: 1.267 acc: 0.477\n",
      "\t - Step 93: loss: 1.396 acc: 0.484\n",
      "\t - Step 94: loss: 1.238 acc: 0.484\n",
      "\t - Step 95: loss: 1.218 acc: 0.516\n",
      "\t - Step 96: loss: 1.335 acc: 0.531\n",
      "\t - Step 97: loss: 1.340 acc: 0.453\n",
      "\t - Step 98: loss: 1.477 acc: 0.453\n",
      "\t - Step 99: loss: 1.355 acc: 0.438\n",
      "\t - Step 100: loss: 1.205 acc: 0.617\n",
      "\t - Step 101: loss: 1.375 acc: 0.508\n",
      "\t - Step 102: loss: 1.276 acc: 0.570\n",
      "\t - Step 103: loss: 1.180 acc: 0.602\n",
      "\t - Step 104: loss: 1.396 acc: 0.461\n",
      "\t - Step 105: loss: 1.261 acc: 0.531\n",
      "\t - Step 106: loss: 1.149 acc: 0.609\n",
      "\t - Step 107: loss: 1.334 acc: 0.492\n",
      "\t - Step 108: loss: 1.234 acc: 0.492\n",
      "\t - Step 109: loss: 1.189 acc: 0.562\n",
      "\t - Step 110: loss: 1.427 acc: 0.469\n",
      "\t - Step 111: loss: 1.303 acc: 0.555\n",
      "\t - Step 112: loss: 1.283 acc: 0.461\n",
      "\t - Step 113: loss: 1.253 acc: 0.531\n",
      "\t - Step 114: loss: 1.280 acc: 0.523\n",
      "\t - Step 115: loss: 1.426 acc: 0.414\n",
      "\t - Step 116: loss: 1.344 acc: 0.516\n",
      "\t - Step 117: loss: 1.202 acc: 0.547\n",
      "\t - Step 118: loss: 1.384 acc: 0.492\n",
      "\t - Step 119: loss: 1.390 acc: 0.492\n",
      "\t - Step 120: loss: 1.308 acc: 0.461\n",
      "\t - Step 121: loss: 1.186 acc: 0.602\n",
      "\t - Step 122: loss: 1.342 acc: 0.484\n",
      "\t - Step 123: loss: 1.286 acc: 0.469\n",
      "\t - Step 124: loss: 1.238 acc: 0.523\n",
      "\t - Step 125: loss: 1.338 acc: 0.453\n",
      "\t - Step 126: loss: 1.280 acc: 0.508\n",
      "\t - Step 127: loss: 1.297 acc: 0.500\n",
      "\t - Step 128: loss: 1.276 acc: 0.516\n",
      "\t - Step 129: loss: 1.155 acc: 0.578\n",
      "\t - Step 130: loss: 1.217 acc: 0.531\n",
      "\t - Step 131: loss: 1.252 acc: 0.508\n",
      "\t - Step 132: loss: 1.293 acc: 0.531\n",
      "\t - Step 133: loss: 1.238 acc: 0.539\n",
      "\t - Step 134: loss: 1.202 acc: 0.547\n",
      "\t - Step 135: loss: 1.411 acc: 0.406\n",
      "\t - Step 136: loss: 1.256 acc: 0.516\n",
      "\t - Step 137: loss: 1.337 acc: 0.578\n",
      "\t - Step 138: loss: 1.207 acc: 0.562\n",
      "\t - Step 139: loss: 1.302 acc: 0.531\n",
      "\t - Step 140: loss: 1.353 acc: 0.555\n",
      "\t - Step 141: loss: 1.251 acc: 0.555\n",
      "\t - Step 142: loss: 1.256 acc: 0.523\n",
      "\t - Step 143: loss: 1.298 acc: 0.547\n",
      "\t - Step 144: loss: 1.312 acc: 0.492\n",
      "\t - Step 145: loss: 1.305 acc: 0.539\n",
      "\t - Step 146: loss: 1.301 acc: 0.492\n",
      "\t - Step 147: loss: 1.241 acc: 0.500\n",
      "\t - Step 148: loss: 1.432 acc: 0.445\n",
      "\t - Step 149: loss: 1.280 acc: 0.508\n",
      "\t - Step 150: loss: 1.192 acc: 0.570\n",
      "\t - Step 151: loss: 1.268 acc: 0.547\n",
      "\t - Step 152: loss: 1.271 acc: 0.445\n",
      "\t - Step 153: loss: 1.268 acc: 0.539\n",
      "\t - Step 154: loss: 1.337 acc: 0.539\n",
      "\t - Step 155: loss: 1.104 acc: 0.594\n",
      "\t - Step 156: loss: 1.286 acc: 0.539\n",
      "\t - Step 157: loss: 1.432 acc: 0.461\n",
      "\t - Step 158: loss: 1.346 acc: 0.516\n",
      "\t - Step 159: loss: 1.243 acc: 0.555\n",
      "\t - Step 160: loss: 1.395 acc: 0.492\n",
      "\t - Step 161: loss: 1.303 acc: 0.516\n",
      "\t - Step 162: loss: 1.316 acc: 0.516\n",
      "\t - Step 163: loss: 1.390 acc: 0.484\n",
      "\t - Step 164: loss: 1.438 acc: 0.453\n",
      "\t - Step 165: loss: 1.391 acc: 0.461\n",
      "\t - Step 166: loss: 1.327 acc: 0.492\n",
      "\t - Step 167: loss: 1.277 acc: 0.516\n",
      "\t - Step 168: loss: 1.408 acc: 0.438\n",
      "\t - Step 169: loss: 1.264 acc: 0.539\n",
      "\t - Step 170: loss: 1.285 acc: 0.508\n",
      "\t - Step 171: loss: 1.189 acc: 0.586\n",
      "\t - Step 172: loss: 1.408 acc: 0.477\n",
      "\t - Step 173: loss: 1.326 acc: 0.516\n",
      "\t - Step 174: loss: 1.377 acc: 0.469\n",
      "\t - Step 175: loss: 1.291 acc: 0.508\n",
      "\t - Step 176: loss: 1.285 acc: 0.523\n",
      "\t - Step 177: loss: 1.318 acc: 0.500\n",
      "\t - Step 178: loss: 1.253 acc: 0.516\n",
      "\t - Step 179: loss: 1.269 acc: 0.453\n",
      "\t - Step 180: loss: 1.266 acc: 0.531\n",
      "\t - Step 181: loss: 1.249 acc: 0.555\n",
      "\t - Step 182: loss: 1.226 acc: 0.539\n",
      "\t - Step 183: loss: 1.268 acc: 0.523\n",
      "\t - Step 184: loss: 1.375 acc: 0.492\n",
      "\t - Step 185: loss: 1.217 acc: 0.570\n",
      "\t - Step 186: loss: 1.411 acc: 0.438\n",
      "\t - Step 187: loss: 1.258 acc: 0.562\n",
      "\t - Step 188: loss: 1.180 acc: 0.570\n",
      "\t - Step 189: loss: 1.430 acc: 0.461\n",
      "\t - Step 190: loss: 1.224 acc: 0.523\n",
      "\t - Step 191: loss: 1.322 acc: 0.484\n",
      "\t - Step 192: loss: 1.448 acc: 0.453\n",
      "\t - Step 193: loss: 1.264 acc: 0.547\n",
      "\t - Step 194: loss: 1.430 acc: 0.500\n",
      "\t - Step 195: loss: 1.314 acc: 0.531\n",
      "\t - Step 196: loss: 1.197 acc: 0.555\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t - Step 197: loss: 1.276 acc: 0.539\n",
      "\t - Step 198: loss: 1.264 acc: 0.547\n",
      "\t - Step 199: loss: 1.213 acc: 0.570\n",
      "\t - Step 200: loss: 1.221 acc: 0.547\n",
      "\t - Step 201: loss: 1.219 acc: 0.562\n",
      "\t - Step 202: loss: 1.375 acc: 0.516\n",
      "\t - Step 203: loss: 1.336 acc: 0.516\n",
      "\t - Step 204: loss: 1.342 acc: 0.492\n",
      "\t - Step 205: loss: 1.289 acc: 0.516\n",
      "\t - Step 206: loss: 1.364 acc: 0.469\n",
      "\t - Step 207: loss: 1.214 acc: 0.562\n",
      "\t - Step 208: loss: 1.342 acc: 0.492\n",
      "\t - Step 209: loss: 1.308 acc: 0.477\n",
      "\t - Step 210: loss: 1.306 acc: 0.484\n",
      "\t - Step 211: loss: 1.389 acc: 0.500\n",
      "\t - Step 212: loss: 1.368 acc: 0.508\n",
      "\t - Step 213: loss: 1.535 acc: 0.438\n",
      "\t - Step 214: loss: 1.352 acc: 0.531\n",
      "\t - Step 215: loss: 1.217 acc: 0.570\n",
      "\t - Step 216: loss: 1.279 acc: 0.523\n",
      "\t - Step 217: loss: 1.320 acc: 0.508\n",
      "\t - Step 218: loss: 1.381 acc: 0.500\n",
      "\t - Step 219: loss: 1.308 acc: 0.469\n",
      "\t - Step 220: loss: 1.239 acc: 0.523\n",
      "\t - Step 221: loss: 1.285 acc: 0.508\n",
      "\t - Step 222: loss: 1.415 acc: 0.469\n",
      "\t - Step 223: loss: 1.324 acc: 0.453\n",
      "\t - Step 224: loss: 1.110 acc: 0.562\n",
      "\t - Step 225: loss: 1.183 acc: 0.568\n",
      "- Avg.loss: 1.282  | Avg.acc: 0.517\n",
      "- Avg. val_loss: 1.644  | Avg. val_acc: 0.383\n",
      "Epoch:  17\n",
      "\t - Step 1: loss: 1.297 acc: 0.516\n",
      "\t - Step 2: loss: 1.158 acc: 0.602\n",
      "\t - Step 3: loss: 1.297 acc: 0.523\n",
      "\t - Step 4: loss: 1.189 acc: 0.578\n",
      "\t - Step 5: loss: 1.244 acc: 0.570\n",
      "\t - Step 6: loss: 1.302 acc: 0.516\n",
      "\t - Step 7: loss: 1.268 acc: 0.516\n",
      "\t - Step 8: loss: 1.212 acc: 0.555\n",
      "\t - Step 9: loss: 1.332 acc: 0.469\n",
      "\t - Step 10: loss: 1.175 acc: 0.531\n",
      "\t - Step 11: loss: 1.244 acc: 0.508\n",
      "\t - Step 12: loss: 1.218 acc: 0.539\n",
      "\t - Step 13: loss: 1.264 acc: 0.562\n",
      "\t - Step 14: loss: 1.118 acc: 0.656\n",
      "\t - Step 15: loss: 1.306 acc: 0.469\n",
      "\t - Step 16: loss: 1.290 acc: 0.547\n",
      "\t - Step 17: loss: 1.317 acc: 0.492\n",
      "\t - Step 18: loss: 1.171 acc: 0.562\n",
      "\t - Step 19: loss: 1.354 acc: 0.539\n",
      "\t - Step 20: loss: 1.197 acc: 0.578\n",
      "\t - Step 21: loss: 1.401 acc: 0.477\n",
      "\t - Step 22: loss: 1.155 acc: 0.586\n",
      "\t - Step 23: loss: 1.299 acc: 0.523\n",
      "\t - Step 24: loss: 1.244 acc: 0.516\n",
      "\t - Step 25: loss: 1.173 acc: 0.531\n",
      "\t - Step 26: loss: 1.293 acc: 0.516\n",
      "\t - Step 27: loss: 1.071 acc: 0.586\n",
      "\t - Step 28: loss: 1.251 acc: 0.523\n",
      "\t - Step 29: loss: 1.056 acc: 0.633\n",
      "\t - Step 30: loss: 1.270 acc: 0.492\n",
      "\t - Step 31: loss: 1.294 acc: 0.492\n",
      "\t - Step 32: loss: 1.292 acc: 0.516\n",
      "\t - Step 33: loss: 1.249 acc: 0.500\n",
      "\t - Step 34: loss: 1.236 acc: 0.562\n",
      "\t - Step 35: loss: 1.398 acc: 0.484\n",
      "\t - Step 36: loss: 1.192 acc: 0.547\n",
      "\t - Step 37: loss: 1.373 acc: 0.500\n",
      "\t - Step 38: loss: 1.188 acc: 0.547\n",
      "\t - Step 39: loss: 1.347 acc: 0.492\n",
      "\t - Step 40: loss: 1.128 acc: 0.570\n",
      "\t - Step 41: loss: 1.263 acc: 0.516\n",
      "\t - Step 42: loss: 1.207 acc: 0.523\n",
      "\t - Step 43: loss: 1.343 acc: 0.523\n",
      "\t - Step 44: loss: 1.081 acc: 0.617\n",
      "\t - Step 45: loss: 1.250 acc: 0.484\n",
      "\t - Step 46: loss: 1.131 acc: 0.609\n",
      "\t - Step 47: loss: 1.193 acc: 0.555\n",
      "\t - Step 48: loss: 1.204 acc: 0.516\n",
      "\t - Step 49: loss: 1.191 acc: 0.586\n",
      "\t - Step 50: loss: 1.271 acc: 0.516\n",
      "\t - Step 51: loss: 1.285 acc: 0.547\n",
      "\t - Step 52: loss: 1.254 acc: 0.484\n",
      "\t - Step 53: loss: 1.186 acc: 0.547\n",
      "\t - Step 54: loss: 1.358 acc: 0.477\n",
      "\t - Step 55: loss: 1.150 acc: 0.539\n",
      "\t - Step 56: loss: 1.212 acc: 0.555\n",
      "\t - Step 57: loss: 1.282 acc: 0.508\n",
      "\t - Step 58: loss: 1.345 acc: 0.500\n",
      "\t - Step 59: loss: 1.291 acc: 0.500\n",
      "\t - Step 60: loss: 1.295 acc: 0.516\n",
      "\t - Step 61: loss: 1.216 acc: 0.531\n",
      "\t - Step 62: loss: 1.210 acc: 0.508\n",
      "\t - Step 63: loss: 1.290 acc: 0.508\n",
      "\t - Step 64: loss: 1.170 acc: 0.547\n",
      "\t - Step 65: loss: 1.318 acc: 0.477\n",
      "\t - Step 66: loss: 1.308 acc: 0.484\n",
      "\t - Step 67: loss: 1.312 acc: 0.516\n",
      "\t - Step 68: loss: 1.340 acc: 0.500\n",
      "\t - Step 69: loss: 1.141 acc: 0.570\n",
      "\t - Step 70: loss: 1.430 acc: 0.461\n",
      "\t - Step 71: loss: 1.219 acc: 0.508\n",
      "\t - Step 72: loss: 1.329 acc: 0.500\n",
      "\t - Step 73: loss: 1.249 acc: 0.555\n",
      "\t - Step 74: loss: 1.321 acc: 0.555\n",
      "\t - Step 75: loss: 1.302 acc: 0.500\n",
      "\t - Step 76: loss: 1.397 acc: 0.445\n",
      "\t - Step 77: loss: 1.117 acc: 0.594\n",
      "\t - Step 78: loss: 1.116 acc: 0.586\n",
      "\t - Step 79: loss: 1.409 acc: 0.469\n",
      "\t - Step 80: loss: 1.428 acc: 0.500\n",
      "\t - Step 81: loss: 1.305 acc: 0.508\n",
      "\t - Step 82: loss: 1.257 acc: 0.531\n",
      "\t - Step 83: loss: 1.357 acc: 0.477\n",
      "\t - Step 84: loss: 1.272 acc: 0.484\n",
      "\t - Step 85: loss: 1.312 acc: 0.492\n",
      "\t - Step 86: loss: 1.325 acc: 0.492\n",
      "\t - Step 87: loss: 1.290 acc: 0.523\n",
      "\t - Step 88: loss: 1.398 acc: 0.438\n",
      "\t - Step 89: loss: 1.327 acc: 0.461\n",
      "\t - Step 90: loss: 1.202 acc: 0.562\n",
      "\t - Step 91: loss: 1.180 acc: 0.617\n",
      "\t - Step 92: loss: 1.367 acc: 0.500\n",
      "\t - Step 93: loss: 1.346 acc: 0.469\n",
      "\t - Step 94: loss: 1.299 acc: 0.500\n",
      "\t - Step 95: loss: 1.267 acc: 0.539\n",
      "\t - Step 96: loss: 1.224 acc: 0.578\n",
      "\t - Step 97: loss: 1.326 acc: 0.508\n",
      "\t - Step 98: loss: 1.304 acc: 0.469\n",
      "\t - Step 99: loss: 1.283 acc: 0.523\n",
      "\t - Step 100: loss: 1.295 acc: 0.492\n",
      "\t - Step 101: loss: 1.339 acc: 0.508\n",
      "\t - Step 102: loss: 1.145 acc: 0.539\n",
      "\t - Step 103: loss: 1.369 acc: 0.484\n",
      "\t - Step 104: loss: 1.209 acc: 0.539\n",
      "\t - Step 105: loss: 1.419 acc: 0.453\n",
      "\t - Step 106: loss: 1.241 acc: 0.508\n",
      "\t - Step 107: loss: 1.480 acc: 0.430\n",
      "\t - Step 108: loss: 1.377 acc: 0.477\n",
      "\t - Step 109: loss: 1.258 acc: 0.523\n",
      "\t - Step 110: loss: 1.281 acc: 0.484\n",
      "\t - Step 111: loss: 1.399 acc: 0.508\n",
      "\t - Step 112: loss: 1.237 acc: 0.531\n",
      "\t - Step 113: loss: 1.395 acc: 0.391\n",
      "\t - Step 114: loss: 1.308 acc: 0.516\n",
      "\t - Step 115: loss: 1.233 acc: 0.523\n",
      "\t - Step 116: loss: 1.287 acc: 0.523\n",
      "\t - Step 117: loss: 1.166 acc: 0.578\n",
      "\t - Step 118: loss: 1.226 acc: 0.555\n",
      "\t - Step 119: loss: 1.209 acc: 0.555\n",
      "\t - Step 120: loss: 1.273 acc: 0.523\n",
      "\t - Step 121: loss: 1.212 acc: 0.547\n",
      "\t - Step 122: loss: 1.294 acc: 0.477\n",
      "\t - Step 123: loss: 1.302 acc: 0.500\n",
      "\t - Step 124: loss: 1.385 acc: 0.469\n",
      "\t - Step 125: loss: 1.413 acc: 0.453\n",
      "\t - Step 126: loss: 1.116 acc: 0.609\n",
      "\t - Step 127: loss: 1.252 acc: 0.562\n",
      "\t - Step 128: loss: 1.104 acc: 0.602\n",
      "\t - Step 129: loss: 1.392 acc: 0.492\n",
      "\t - Step 130: loss: 1.286 acc: 0.508\n",
      "\t - Step 131: loss: 1.321 acc: 0.555\n",
      "\t - Step 132: loss: 1.300 acc: 0.508\n",
      "\t - Step 133: loss: 1.196 acc: 0.594\n",
      "\t - Step 134: loss: 1.275 acc: 0.508\n",
      "\t - Step 135: loss: 1.239 acc: 0.562\n",
      "\t - Step 136: loss: 1.365 acc: 0.438\n",
      "\t - Step 137: loss: 1.219 acc: 0.562\n",
      "\t - Step 138: loss: 1.279 acc: 0.477\n",
      "\t - Step 139: loss: 1.087 acc: 0.586\n",
      "\t - Step 140: loss: 1.199 acc: 0.578\n",
      "\t - Step 141: loss: 1.227 acc: 0.539\n",
      "\t - Step 142: loss: 1.255 acc: 0.539\n",
      "\t - Step 143: loss: 1.463 acc: 0.484\n",
      "\t - Step 144: loss: 1.367 acc: 0.469\n",
      "\t - Step 145: loss: 1.205 acc: 0.516\n",
      "\t - Step 146: loss: 1.401 acc: 0.484\n",
      "\t - Step 147: loss: 1.388 acc: 0.508\n",
      "\t - Step 148: loss: 1.222 acc: 0.555\n",
      "\t - Step 149: loss: 1.129 acc: 0.609\n",
      "\t - Step 150: loss: 1.176 acc: 0.578\n",
      "\t - Step 151: loss: 1.256 acc: 0.547\n",
      "\t - Step 152: loss: 1.279 acc: 0.500\n",
      "\t - Step 153: loss: 1.363 acc: 0.484\n",
      "\t - Step 154: loss: 1.347 acc: 0.555\n",
      "\t - Step 155: loss: 1.294 acc: 0.453\n",
      "\t - Step 156: loss: 1.418 acc: 0.562\n",
      "\t - Step 157: loss: 1.386 acc: 0.438\n",
      "\t - Step 158: loss: 1.157 acc: 0.578\n",
      "\t - Step 159: loss: 1.339 acc: 0.492\n",
      "\t - Step 160: loss: 1.360 acc: 0.438\n",
      "\t - Step 161: loss: 1.264 acc: 0.578\n",
      "\t - Step 162: loss: 1.315 acc: 0.516\n",
      "\t - Step 163: loss: 1.185 acc: 0.539\n",
      "\t - Step 164: loss: 1.273 acc: 0.523\n",
      "\t - Step 165: loss: 1.209 acc: 0.547\n",
      "\t - Step 166: loss: 1.416 acc: 0.453\n",
      "\t - Step 167: loss: 1.334 acc: 0.484\n",
      "\t - Step 168: loss: 1.258 acc: 0.547\n",
      "\t - Step 169: loss: 1.151 acc: 0.578\n",
      "\t - Step 170: loss: 1.134 acc: 0.570\n",
      "\t - Step 171: loss: 1.312 acc: 0.492\n",
      "\t - Step 172: loss: 1.336 acc: 0.461\n",
      "\t - Step 173: loss: 1.210 acc: 0.562\n",
      "\t - Step 174: loss: 1.283 acc: 0.500\n",
      "\t - Step 175: loss: 1.223 acc: 0.539\n",
      "\t - Step 176: loss: 1.304 acc: 0.547\n",
      "\t - Step 177: loss: 1.388 acc: 0.484\n",
      "\t - Step 178: loss: 1.263 acc: 0.539\n",
      "\t - Step 179: loss: 1.164 acc: 0.594\n",
      "\t - Step 180: loss: 1.364 acc: 0.438\n",
      "\t - Step 181: loss: 1.337 acc: 0.469\n",
      "\t - Step 182: loss: 1.323 acc: 0.516\n",
      "\t - Step 183: loss: 1.246 acc: 0.508\n",
      "\t - Step 184: loss: 1.168 acc: 0.578\n",
      "\t - Step 185: loss: 1.235 acc: 0.531\n",
      "\t - Step 186: loss: 1.279 acc: 0.539\n",
      "\t - Step 187: loss: 1.360 acc: 0.484\n",
      "\t - Step 188: loss: 1.255 acc: 0.562\n",
      "\t - Step 189: loss: 1.222 acc: 0.555\n",
      "\t - Step 190: loss: 1.482 acc: 0.445\n",
      "\t - Step 191: loss: 1.268 acc: 0.547\n",
      "\t - Step 192: loss: 1.284 acc: 0.547\n",
      "\t - Step 193: loss: 1.294 acc: 0.500\n",
      "\t - Step 194: loss: 1.283 acc: 0.461\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t - Step 195: loss: 1.363 acc: 0.469\n",
      "\t - Step 196: loss: 1.218 acc: 0.609\n",
      "\t - Step 197: loss: 1.343 acc: 0.508\n",
      "\t - Step 198: loss: 1.342 acc: 0.500\n",
      "\t - Step 199: loss: 1.240 acc: 0.523\n",
      "\t - Step 200: loss: 1.327 acc: 0.477\n",
      "\t - Step 201: loss: 1.228 acc: 0.477\n",
      "\t - Step 202: loss: 1.304 acc: 0.500\n",
      "\t - Step 203: loss: 1.428 acc: 0.398\n",
      "\t - Step 204: loss: 1.250 acc: 0.555\n",
      "\t - Step 205: loss: 1.272 acc: 0.523\n",
      "\t - Step 206: loss: 1.400 acc: 0.453\n",
      "\t - Step 207: loss: 1.242 acc: 0.523\n",
      "\t - Step 208: loss: 1.291 acc: 0.547\n",
      "\t - Step 209: loss: 1.405 acc: 0.516\n",
      "\t - Step 210: loss: 1.279 acc: 0.508\n",
      "\t - Step 211: loss: 1.174 acc: 0.570\n",
      "\t - Step 212: loss: 1.192 acc: 0.562\n",
      "\t - Step 213: loss: 1.212 acc: 0.547\n",
      "\t - Step 214: loss: 1.434 acc: 0.422\n",
      "\t - Step 215: loss: 1.119 acc: 0.609\n",
      "\t - Step 216: loss: 1.262 acc: 0.531\n",
      "\t - Step 217: loss: 1.459 acc: 0.414\n",
      "\t - Step 218: loss: 1.325 acc: 0.539\n",
      "\t - Step 219: loss: 1.386 acc: 0.484\n",
      "\t - Step 220: loss: 1.222 acc: 0.578\n",
      "\t - Step 221: loss: 1.360 acc: 0.492\n",
      "\t - Step 222: loss: 1.242 acc: 0.539\n",
      "\t - Step 223: loss: 1.327 acc: 0.445\n",
      "\t - Step 224: loss: 1.339 acc: 0.477\n",
      "\t - Step 225: loss: 1.366 acc: 0.459\n",
      "- Avg.loss: 1.276  | Avg.acc: 0.520\n",
      "- Avg. val_loss: 1.583  | Avg. val_acc: 0.412\n",
      "Epoch:  18\n",
      "\t - Step 1: loss: 1.198 acc: 0.578\n",
      "\t - Step 2: loss: 1.293 acc: 0.492\n",
      "\t - Step 3: loss: 1.137 acc: 0.617\n",
      "\t - Step 4: loss: 1.177 acc: 0.531\n",
      "\t - Step 5: loss: 1.397 acc: 0.484\n",
      "\t - Step 6: loss: 1.321 acc: 0.500\n",
      "\t - Step 7: loss: 1.198 acc: 0.539\n",
      "\t - Step 8: loss: 1.171 acc: 0.594\n",
      "\t - Step 9: loss: 1.276 acc: 0.523\n",
      "\t - Step 10: loss: 1.208 acc: 0.562\n",
      "\t - Step 11: loss: 1.203 acc: 0.578\n",
      "\t - Step 12: loss: 1.392 acc: 0.492\n",
      "\t - Step 13: loss: 1.382 acc: 0.492\n",
      "\t - Step 14: loss: 1.380 acc: 0.453\n",
      "\t - Step 15: loss: 1.228 acc: 0.523\n",
      "\t - Step 16: loss: 1.325 acc: 0.523\n",
      "\t - Step 17: loss: 1.236 acc: 0.516\n",
      "\t - Step 18: loss: 1.349 acc: 0.469\n",
      "\t - Step 19: loss: 1.175 acc: 0.555\n",
      "\t - Step 20: loss: 1.385 acc: 0.508\n",
      "\t - Step 21: loss: 1.077 acc: 0.594\n",
      "\t - Step 22: loss: 1.216 acc: 0.609\n",
      "\t - Step 23: loss: 1.316 acc: 0.500\n",
      "\t - Step 24: loss: 1.208 acc: 0.523\n",
      "\t - Step 25: loss: 1.206 acc: 0.523\n",
      "\t - Step 26: loss: 1.362 acc: 0.445\n",
      "\t - Step 27: loss: 1.228 acc: 0.555\n",
      "\t - Step 28: loss: 1.305 acc: 0.477\n",
      "\t - Step 29: loss: 1.322 acc: 0.492\n",
      "\t - Step 30: loss: 1.168 acc: 0.555\n",
      "\t - Step 31: loss: 1.188 acc: 0.547\n",
      "\t - Step 32: loss: 1.350 acc: 0.484\n",
      "\t - Step 33: loss: 1.211 acc: 0.578\n",
      "\t - Step 34: loss: 1.224 acc: 0.531\n",
      "\t - Step 35: loss: 1.180 acc: 0.602\n",
      "\t - Step 36: loss: 1.266 acc: 0.547\n",
      "\t - Step 37: loss: 1.258 acc: 0.500\n",
      "\t - Step 38: loss: 1.292 acc: 0.523\n",
      "\t - Step 39: loss: 1.296 acc: 0.523\n",
      "\t - Step 40: loss: 1.332 acc: 0.461\n",
      "\t - Step 41: loss: 1.108 acc: 0.578\n",
      "\t - Step 42: loss: 1.213 acc: 0.547\n",
      "\t - Step 43: loss: 1.275 acc: 0.539\n",
      "\t - Step 44: loss: 1.321 acc: 0.492\n",
      "\t - Step 45: loss: 1.310 acc: 0.461\n",
      "\t - Step 46: loss: 1.359 acc: 0.477\n",
      "\t - Step 47: loss: 1.274 acc: 0.500\n",
      "\t - Step 48: loss: 1.474 acc: 0.430\n",
      "\t - Step 49: loss: 1.166 acc: 0.594\n",
      "\t - Step 50: loss: 1.281 acc: 0.531\n",
      "\t - Step 51: loss: 1.419 acc: 0.445\n",
      "\t - Step 52: loss: 1.194 acc: 0.492\n",
      "\t - Step 53: loss: 1.237 acc: 0.547\n",
      "\t - Step 54: loss: 1.195 acc: 0.555\n",
      "\t - Step 55: loss: 1.234 acc: 0.586\n",
      "\t - Step 56: loss: 1.246 acc: 0.547\n",
      "\t - Step 57: loss: 1.246 acc: 0.516\n",
      "\t - Step 58: loss: 1.314 acc: 0.516\n",
      "\t - Step 59: loss: 1.160 acc: 0.586\n",
      "\t - Step 60: loss: 1.299 acc: 0.562\n",
      "\t - Step 61: loss: 1.208 acc: 0.594\n",
      "\t - Step 62: loss: 1.265 acc: 0.562\n",
      "\t - Step 63: loss: 1.130 acc: 0.586\n",
      "\t - Step 64: loss: 1.310 acc: 0.516\n",
      "\t - Step 65: loss: 1.370 acc: 0.445\n",
      "\t - Step 66: loss: 1.204 acc: 0.570\n",
      "\t - Step 67: loss: 1.302 acc: 0.492\n",
      "\t - Step 68: loss: 1.175 acc: 0.555\n",
      "\t - Step 69: loss: 1.389 acc: 0.508\n",
      "\t - Step 70: loss: 1.135 acc: 0.562\n",
      "\t - Step 71: loss: 1.259 acc: 0.555\n",
      "\t - Step 72: loss: 1.222 acc: 0.570\n",
      "\t - Step 73: loss: 1.212 acc: 0.547\n",
      "\t - Step 74: loss: 1.148 acc: 0.555\n",
      "\t - Step 75: loss: 1.285 acc: 0.492\n",
      "\t - Step 76: loss: 1.351 acc: 0.484\n",
      "\t - Step 77: loss: 1.291 acc: 0.508\n",
      "\t - Step 78: loss: 1.266 acc: 0.539\n",
      "\t - Step 79: loss: 1.188 acc: 0.531\n",
      "\t - Step 80: loss: 1.160 acc: 0.594\n",
      "\t - Step 81: loss: 1.227 acc: 0.523\n",
      "\t - Step 82: loss: 1.205 acc: 0.516\n",
      "\t - Step 83: loss: 1.296 acc: 0.547\n",
      "\t - Step 84: loss: 1.235 acc: 0.570\n",
      "\t - Step 85: loss: 1.202 acc: 0.562\n",
      "\t - Step 86: loss: 1.141 acc: 0.562\n",
      "\t - Step 87: loss: 1.233 acc: 0.492\n",
      "\t - Step 88: loss: 1.253 acc: 0.516\n",
      "\t - Step 89: loss: 1.265 acc: 0.469\n",
      "\t - Step 90: loss: 1.261 acc: 0.555\n",
      "\t - Step 91: loss: 1.241 acc: 0.539\n",
      "\t - Step 92: loss: 1.259 acc: 0.500\n",
      "\t - Step 93: loss: 1.343 acc: 0.445\n",
      "\t - Step 94: loss: 1.335 acc: 0.516\n",
      "\t - Step 95: loss: 1.190 acc: 0.531\n",
      "\t - Step 96: loss: 1.164 acc: 0.578\n",
      "\t - Step 97: loss: 1.276 acc: 0.500\n",
      "\t - Step 98: loss: 1.202 acc: 0.578\n",
      "\t - Step 99: loss: 1.242 acc: 0.523\n",
      "\t - Step 100: loss: 1.167 acc: 0.555\n",
      "\t - Step 101: loss: 1.343 acc: 0.453\n",
      "\t - Step 102: loss: 1.266 acc: 0.555\n",
      "\t - Step 103: loss: 1.322 acc: 0.453\n",
      "\t - Step 104: loss: 1.263 acc: 0.484\n",
      "\t - Step 105: loss: 1.241 acc: 0.508\n",
      "\t - Step 106: loss: 1.219 acc: 0.539\n",
      "\t - Step 107: loss: 1.294 acc: 0.492\n",
      "\t - Step 108: loss: 1.252 acc: 0.531\n",
      "\t - Step 109: loss: 1.388 acc: 0.438\n",
      "\t - Step 110: loss: 1.325 acc: 0.500\n",
      "\t - Step 111: loss: 1.306 acc: 0.562\n",
      "\t - Step 112: loss: 1.364 acc: 0.539\n",
      "\t - Step 113: loss: 1.225 acc: 0.523\n",
      "\t - Step 114: loss: 1.268 acc: 0.516\n",
      "\t - Step 115: loss: 1.325 acc: 0.492\n",
      "\t - Step 116: loss: 1.347 acc: 0.539\n",
      "\t - Step 117: loss: 1.236 acc: 0.500\n",
      "\t - Step 118: loss: 1.281 acc: 0.508\n",
      "\t - Step 119: loss: 1.315 acc: 0.484\n",
      "\t - Step 120: loss: 1.208 acc: 0.578\n",
      "\t - Step 121: loss: 1.262 acc: 0.562\n",
      "\t - Step 122: loss: 1.323 acc: 0.477\n",
      "\t - Step 123: loss: 1.343 acc: 0.492\n",
      "\t - Step 124: loss: 1.213 acc: 0.562\n",
      "\t - Step 125: loss: 1.278 acc: 0.570\n",
      "\t - Step 126: loss: 1.328 acc: 0.492\n",
      "\t - Step 127: loss: 1.406 acc: 0.492\n",
      "\t - Step 128: loss: 1.179 acc: 0.539\n",
      "\t - Step 129: loss: 1.231 acc: 0.562\n",
      "\t - Step 130: loss: 1.375 acc: 0.484\n",
      "\t - Step 131: loss: 1.327 acc: 0.477\n",
      "\t - Step 132: loss: 1.353 acc: 0.516\n",
      "\t - Step 133: loss: 1.241 acc: 0.477\n",
      "\t - Step 134: loss: 1.215 acc: 0.562\n",
      "\t - Step 135: loss: 1.173 acc: 0.609\n",
      "\t - Step 136: loss: 1.184 acc: 0.578\n",
      "\t - Step 137: loss: 1.268 acc: 0.469\n",
      "\t - Step 138: loss: 1.401 acc: 0.438\n",
      "\t - Step 139: loss: 1.222 acc: 0.500\n",
      "\t - Step 140: loss: 1.248 acc: 0.547\n",
      "\t - Step 141: loss: 1.308 acc: 0.523\n",
      "\t - Step 142: loss: 1.178 acc: 0.555\n",
      "\t - Step 143: loss: 1.191 acc: 0.578\n",
      "\t - Step 144: loss: 1.192 acc: 0.578\n",
      "\t - Step 145: loss: 1.353 acc: 0.492\n",
      "\t - Step 146: loss: 1.107 acc: 0.617\n",
      "\t - Step 147: loss: 1.300 acc: 0.539\n",
      "\t - Step 148: loss: 1.191 acc: 0.562\n",
      "\t - Step 149: loss: 1.211 acc: 0.594\n",
      "\t - Step 150: loss: 1.379 acc: 0.453\n",
      "\t - Step 151: loss: 1.284 acc: 0.539\n",
      "\t - Step 152: loss: 1.189 acc: 0.570\n",
      "\t - Step 153: loss: 1.163 acc: 0.516\n",
      "\t - Step 154: loss: 1.408 acc: 0.508\n",
      "\t - Step 155: loss: 1.120 acc: 0.586\n",
      "\t - Step 156: loss: 1.214 acc: 0.516\n",
      "\t - Step 157: loss: 1.218 acc: 0.539\n",
      "\t - Step 158: loss: 1.160 acc: 0.570\n",
      "\t - Step 159: loss: 1.454 acc: 0.484\n",
      "\t - Step 160: loss: 1.241 acc: 0.562\n",
      "\t - Step 161: loss: 1.324 acc: 0.492\n",
      "\t - Step 162: loss: 1.191 acc: 0.539\n",
      "\t - Step 163: loss: 1.293 acc: 0.516\n",
      "\t - Step 164: loss: 1.337 acc: 0.500\n",
      "\t - Step 165: loss: 1.262 acc: 0.555\n",
      "\t - Step 166: loss: 1.355 acc: 0.461\n",
      "\t - Step 167: loss: 1.233 acc: 0.531\n",
      "\t - Step 168: loss: 1.117 acc: 0.578\n",
      "\t - Step 169: loss: 1.356 acc: 0.430\n",
      "\t - Step 170: loss: 1.362 acc: 0.453\n",
      "\t - Step 171: loss: 1.292 acc: 0.586\n",
      "\t - Step 172: loss: 1.188 acc: 0.539\n",
      "\t - Step 173: loss: 1.446 acc: 0.453\n",
      "\t - Step 174: loss: 1.289 acc: 0.500\n",
      "\t - Step 175: loss: 1.307 acc: 0.523\n",
      "\t - Step 176: loss: 1.163 acc: 0.562\n",
      "\t - Step 177: loss: 1.304 acc: 0.531\n",
      "\t - Step 178: loss: 1.395 acc: 0.492\n",
      "\t - Step 179: loss: 1.267 acc: 0.539\n",
      "\t - Step 180: loss: 1.158 acc: 0.609\n",
      "\t - Step 181: loss: 1.449 acc: 0.445\n",
      "\t - Step 182: loss: 1.324 acc: 0.539\n",
      "\t - Step 183: loss: 1.250 acc: 0.531\n",
      "\t - Step 184: loss: 1.276 acc: 0.523\n",
      "\t - Step 185: loss: 1.227 acc: 0.539\n",
      "\t - Step 186: loss: 1.251 acc: 0.539\n",
      "\t - Step 187: loss: 1.536 acc: 0.422\n",
      "\t - Step 188: loss: 1.324 acc: 0.492\n",
      "\t - Step 189: loss: 1.552 acc: 0.391\n",
      "\t - Step 190: loss: 1.339 acc: 0.492\n",
      "\t - Step 191: loss: 1.260 acc: 0.531\n",
      "\t - Step 192: loss: 1.230 acc: 0.586\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t - Step 193: loss: 1.284 acc: 0.492\n",
      "\t - Step 194: loss: 1.212 acc: 0.594\n",
      "\t - Step 195: loss: 1.541 acc: 0.391\n",
      "\t - Step 196: loss: 1.196 acc: 0.578\n",
      "\t - Step 197: loss: 1.408 acc: 0.469\n",
      "\t - Step 198: loss: 1.339 acc: 0.469\n",
      "\t - Step 199: loss: 1.368 acc: 0.516\n",
      "\t - Step 200: loss: 1.306 acc: 0.508\n",
      "\t - Step 201: loss: 1.194 acc: 0.523\n",
      "\t - Step 202: loss: 1.324 acc: 0.461\n",
      "\t - Step 203: loss: 1.157 acc: 0.562\n",
      "\t - Step 204: loss: 1.311 acc: 0.523\n",
      "\t - Step 205: loss: 1.225 acc: 0.578\n",
      "\t - Step 206: loss: 1.331 acc: 0.531\n",
      "\t - Step 207: loss: 1.182 acc: 0.523\n",
      "\t - Step 208: loss: 1.281 acc: 0.500\n",
      "\t - Step 209: loss: 1.337 acc: 0.469\n",
      "\t - Step 210: loss: 1.332 acc: 0.516\n",
      "\t - Step 211: loss: 1.345 acc: 0.469\n",
      "\t - Step 212: loss: 1.572 acc: 0.398\n",
      "\t - Step 213: loss: 1.378 acc: 0.430\n",
      "\t - Step 214: loss: 1.374 acc: 0.453\n",
      "\t - Step 215: loss: 1.179 acc: 0.508\n",
      "\t - Step 216: loss: 1.182 acc: 0.562\n",
      "\t - Step 217: loss: 1.292 acc: 0.547\n",
      "\t - Step 218: loss: 1.298 acc: 0.492\n",
      "\t - Step 219: loss: 1.287 acc: 0.461\n",
      "\t - Step 220: loss: 1.406 acc: 0.484\n",
      "\t - Step 221: loss: 1.389 acc: 0.500\n",
      "\t - Step 222: loss: 1.239 acc: 0.484\n",
      "\t - Step 223: loss: 1.472 acc: 0.477\n",
      "\t - Step 224: loss: 1.356 acc: 0.453\n",
      "\t - Step 225: loss: 1.424 acc: 0.541\n",
      "- Avg.loss: 1.275  | Avg.acc: 0.521\n",
      "- Avg. val_loss: 1.590  | Avg. val_acc: 0.420\n",
      "Epoch:  19\n",
      "\t - Step 1: loss: 1.267 acc: 0.547\n",
      "\t - Step 2: loss: 1.207 acc: 0.500\n",
      "\t - Step 3: loss: 1.303 acc: 0.523\n",
      "\t - Step 4: loss: 1.184 acc: 0.523\n",
      "\t - Step 5: loss: 1.306 acc: 0.484\n",
      "\t - Step 6: loss: 1.149 acc: 0.578\n",
      "\t - Step 7: loss: 1.149 acc: 0.586\n",
      "\t - Step 8: loss: 1.134 acc: 0.602\n",
      "\t - Step 9: loss: 1.429 acc: 0.492\n",
      "\t - Step 10: loss: 1.392 acc: 0.484\n",
      "\t - Step 11: loss: 1.271 acc: 0.539\n",
      "\t - Step 12: loss: 1.274 acc: 0.508\n",
      "\t - Step 13: loss: 1.275 acc: 0.539\n",
      "\t - Step 14: loss: 1.212 acc: 0.531\n",
      "\t - Step 15: loss: 1.244 acc: 0.547\n",
      "\t - Step 16: loss: 1.155 acc: 0.562\n",
      "\t - Step 17: loss: 1.285 acc: 0.484\n",
      "\t - Step 18: loss: 1.214 acc: 0.555\n",
      "\t - Step 19: loss: 1.322 acc: 0.500\n",
      "\t - Step 20: loss: 1.302 acc: 0.453\n",
      "\t - Step 21: loss: 1.166 acc: 0.570\n",
      "\t - Step 22: loss: 1.484 acc: 0.422\n",
      "\t - Step 23: loss: 1.206 acc: 0.570\n",
      "\t - Step 24: loss: 1.286 acc: 0.477\n",
      "\t - Step 25: loss: 1.275 acc: 0.484\n",
      "\t - Step 26: loss: 1.273 acc: 0.516\n",
      "\t - Step 27: loss: 1.352 acc: 0.531\n",
      "\t - Step 28: loss: 1.289 acc: 0.484\n",
      "\t - Step 29: loss: 1.400 acc: 0.445\n",
      "\t - Step 30: loss: 1.322 acc: 0.500\n",
      "\t - Step 31: loss: 1.308 acc: 0.477\n",
      "\t - Step 32: loss: 1.233 acc: 0.484\n",
      "\t - Step 33: loss: 1.263 acc: 0.516\n",
      "\t - Step 34: loss: 1.318 acc: 0.469\n",
      "\t - Step 35: loss: 1.322 acc: 0.461\n",
      "\t - Step 36: loss: 1.216 acc: 0.516\n",
      "\t - Step 37: loss: 1.204 acc: 0.555\n",
      "\t - Step 38: loss: 1.223 acc: 0.562\n",
      "\t - Step 39: loss: 1.213 acc: 0.586\n",
      "\t - Step 40: loss: 1.232 acc: 0.516\n",
      "\t - Step 41: loss: 1.248 acc: 0.586\n",
      "\t - Step 42: loss: 1.336 acc: 0.500\n",
      "\t - Step 43: loss: 1.306 acc: 0.492\n",
      "\t - Step 44: loss: 1.366 acc: 0.484\n",
      "\t - Step 45: loss: 1.255 acc: 0.508\n",
      "\t - Step 46: loss: 1.291 acc: 0.500\n",
      "\t - Step 47: loss: 1.326 acc: 0.492\n",
      "\t - Step 48: loss: 1.167 acc: 0.594\n",
      "\t - Step 49: loss: 1.215 acc: 0.531\n",
      "\t - Step 50: loss: 1.201 acc: 0.562\n",
      "\t - Step 51: loss: 1.086 acc: 0.578\n",
      "\t - Step 52: loss: 1.291 acc: 0.531\n",
      "\t - Step 53: loss: 1.242 acc: 0.461\n",
      "\t - Step 54: loss: 1.281 acc: 0.539\n",
      "\t - Step 55: loss: 1.275 acc: 0.562\n",
      "\t - Step 56: loss: 1.167 acc: 0.562\n",
      "\t - Step 57: loss: 1.219 acc: 0.586\n",
      "\t - Step 58: loss: 1.249 acc: 0.539\n",
      "\t - Step 59: loss: 1.271 acc: 0.500\n",
      "\t - Step 60: loss: 1.225 acc: 0.570\n",
      "\t - Step 61: loss: 1.302 acc: 0.492\n",
      "\t - Step 62: loss: 1.278 acc: 0.578\n",
      "\t - Step 63: loss: 1.268 acc: 0.539\n",
      "\t - Step 64: loss: 1.117 acc: 0.602\n",
      "\t - Step 65: loss: 1.209 acc: 0.547\n",
      "\t - Step 66: loss: 1.155 acc: 0.602\n",
      "\t - Step 67: loss: 1.274 acc: 0.539\n",
      "\t - Step 68: loss: 1.280 acc: 0.531\n",
      "\t - Step 69: loss: 1.291 acc: 0.539\n",
      "\t - Step 70: loss: 1.274 acc: 0.508\n",
      "\t - Step 71: loss: 1.264 acc: 0.516\n",
      "\t - Step 72: loss: 1.318 acc: 0.492\n",
      "\t - Step 73: loss: 1.110 acc: 0.633\n",
      "\t - Step 74: loss: 1.179 acc: 0.547\n",
      "\t - Step 75: loss: 1.162 acc: 0.586\n",
      "\t - Step 76: loss: 1.254 acc: 0.508\n",
      "\t - Step 77: loss: 1.291 acc: 0.523\n",
      "\t - Step 78: loss: 1.200 acc: 0.555\n",
      "\t - Step 79: loss: 1.354 acc: 0.461\n",
      "\t - Step 80: loss: 1.374 acc: 0.500\n",
      "\t - Step 81: loss: 1.249 acc: 0.555\n",
      "\t - Step 82: loss: 1.337 acc: 0.453\n",
      "\t - Step 83: loss: 1.166 acc: 0.555\n",
      "\t - Step 84: loss: 1.206 acc: 0.477\n",
      "\t - Step 85: loss: 1.379 acc: 0.445\n",
      "\t - Step 86: loss: 1.186 acc: 0.586\n",
      "\t - Step 87: loss: 1.262 acc: 0.562\n",
      "\t - Step 88: loss: 1.258 acc: 0.531\n",
      "\t - Step 89: loss: 1.304 acc: 0.531\n",
      "\t - Step 90: loss: 1.195 acc: 0.602\n",
      "\t - Step 91: loss: 1.247 acc: 0.516\n",
      "\t - Step 92: loss: 1.268 acc: 0.547\n",
      "\t - Step 93: loss: 1.334 acc: 0.453\n",
      "\t - Step 94: loss: 1.115 acc: 0.594\n",
      "\t - Step 95: loss: 1.390 acc: 0.477\n",
      "\t - Step 96: loss: 1.166 acc: 0.586\n",
      "\t - Step 97: loss: 1.141 acc: 0.641\n",
      "\t - Step 98: loss: 1.175 acc: 0.516\n",
      "\t - Step 99: loss: 1.339 acc: 0.492\n",
      "\t - Step 100: loss: 1.322 acc: 0.500\n",
      "\t - Step 101: loss: 1.231 acc: 0.492\n",
      "\t - Step 102: loss: 1.222 acc: 0.492\n",
      "\t - Step 103: loss: 1.348 acc: 0.500\n",
      "\t - Step 104: loss: 1.260 acc: 0.516\n",
      "\t - Step 105: loss: 1.313 acc: 0.492\n",
      "\t - Step 106: loss: 1.303 acc: 0.469\n",
      "\t - Step 107: loss: 1.231 acc: 0.516\n",
      "\t - Step 108: loss: 1.326 acc: 0.500\n",
      "\t - Step 109: loss: 1.083 acc: 0.625\n",
      "\t - Step 110: loss: 1.289 acc: 0.508\n",
      "\t - Step 111: loss: 1.156 acc: 0.570\n",
      "\t - Step 112: loss: 1.362 acc: 0.500\n",
      "\t - Step 113: loss: 1.411 acc: 0.430\n",
      "\t - Step 114: loss: 1.285 acc: 0.516\n",
      "\t - Step 115: loss: 1.233 acc: 0.516\n",
      "\t - Step 116: loss: 1.207 acc: 0.617\n",
      "\t - Step 117: loss: 1.234 acc: 0.547\n",
      "\t - Step 118: loss: 1.368 acc: 0.477\n",
      "\t - Step 119: loss: 1.296 acc: 0.516\n",
      "\t - Step 120: loss: 1.306 acc: 0.547\n",
      "\t - Step 121: loss: 1.261 acc: 0.594\n",
      "\t - Step 122: loss: 1.135 acc: 0.625\n",
      "\t - Step 123: loss: 1.256 acc: 0.547\n",
      "\t - Step 124: loss: 1.177 acc: 0.578\n",
      "\t - Step 125: loss: 1.302 acc: 0.500\n",
      "\t - Step 126: loss: 1.206 acc: 0.570\n",
      "\t - Step 127: loss: 1.393 acc: 0.453\n",
      "\t - Step 128: loss: 1.268 acc: 0.523\n",
      "\t - Step 129: loss: 1.156 acc: 0.562\n",
      "\t - Step 130: loss: 1.340 acc: 0.508\n",
      "\t - Step 131: loss: 1.192 acc: 0.586\n",
      "\t - Step 132: loss: 1.302 acc: 0.531\n",
      "\t - Step 133: loss: 1.347 acc: 0.531\n",
      "\t - Step 134: loss: 1.331 acc: 0.445\n",
      "\t - Step 135: loss: 1.223 acc: 0.508\n",
      "\t - Step 136: loss: 1.183 acc: 0.531\n",
      "\t - Step 137: loss: 1.302 acc: 0.531\n",
      "\t - Step 138: loss: 1.343 acc: 0.500\n",
      "\t - Step 139: loss: 1.192 acc: 0.594\n",
      "\t - Step 140: loss: 1.154 acc: 0.508\n",
      "\t - Step 141: loss: 1.262 acc: 0.531\n",
      "\t - Step 142: loss: 1.258 acc: 0.539\n",
      "\t - Step 143: loss: 1.369 acc: 0.492\n",
      "\t - Step 144: loss: 1.289 acc: 0.531\n",
      "\t - Step 145: loss: 1.583 acc: 0.383\n",
      "\t - Step 146: loss: 1.271 acc: 0.461\n",
      "\t - Step 147: loss: 1.279 acc: 0.508\n",
      "\t - Step 148: loss: 1.357 acc: 0.477\n",
      "\t - Step 149: loss: 1.216 acc: 0.562\n",
      "\t - Step 150: loss: 1.276 acc: 0.500\n",
      "\t - Step 151: loss: 1.209 acc: 0.531\n",
      "\t - Step 152: loss: 1.308 acc: 0.500\n",
      "\t - Step 153: loss: 1.229 acc: 0.523\n",
      "\t - Step 154: loss: 1.239 acc: 0.562\n",
      "\t - Step 155: loss: 1.167 acc: 0.602\n",
      "\t - Step 156: loss: 1.264 acc: 0.500\n",
      "\t - Step 157: loss: 1.374 acc: 0.461\n",
      "\t - Step 158: loss: 1.169 acc: 0.547\n",
      "\t - Step 159: loss: 1.236 acc: 0.562\n",
      "\t - Step 160: loss: 1.338 acc: 0.539\n",
      "\t - Step 161: loss: 1.461 acc: 0.438\n",
      "\t - Step 162: loss: 1.238 acc: 0.562\n",
      "\t - Step 163: loss: 1.315 acc: 0.461\n",
      "\t - Step 164: loss: 1.271 acc: 0.500\n",
      "\t - Step 165: loss: 1.266 acc: 0.578\n",
      "\t - Step 166: loss: 1.386 acc: 0.461\n",
      "\t - Step 167: loss: 1.210 acc: 0.523\n",
      "\t - Step 168: loss: 1.285 acc: 0.484\n",
      "\t - Step 169: loss: 1.204 acc: 0.562\n",
      "\t - Step 170: loss: 1.337 acc: 0.469\n",
      "\t - Step 171: loss: 1.342 acc: 0.484\n",
      "\t - Step 172: loss: 1.098 acc: 0.633\n",
      "\t - Step 173: loss: 1.380 acc: 0.508\n",
      "\t - Step 174: loss: 1.169 acc: 0.531\n",
      "\t - Step 175: loss: 1.197 acc: 0.570\n",
      "\t - Step 176: loss: 1.396 acc: 0.414\n",
      "\t - Step 177: loss: 1.322 acc: 0.500\n",
      "\t - Step 178: loss: 1.286 acc: 0.523\n",
      "\t - Step 179: loss: 1.307 acc: 0.461\n",
      "\t - Step 180: loss: 1.289 acc: 0.516\n",
      "\t - Step 181: loss: 1.298 acc: 0.500\n",
      "\t - Step 182: loss: 1.293 acc: 0.539\n",
      "\t - Step 183: loss: 1.279 acc: 0.531\n",
      "\t - Step 184: loss: 1.266 acc: 0.586\n",
      "\t - Step 185: loss: 1.215 acc: 0.539\n",
      "\t - Step 186: loss: 1.332 acc: 0.539\n",
      "\t - Step 187: loss: 1.318 acc: 0.461\n",
      "\t - Step 188: loss: 1.291 acc: 0.547\n",
      "\t - Step 189: loss: 1.243 acc: 0.523\n",
      "\t - Step 190: loss: 1.274 acc: 0.531\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t - Step 191: loss: 1.378 acc: 0.469\n",
      "\t - Step 192: loss: 1.139 acc: 0.594\n",
      "\t - Step 193: loss: 1.240 acc: 0.547\n",
      "\t - Step 194: loss: 1.388 acc: 0.445\n",
      "\t - Step 195: loss: 1.343 acc: 0.516\n",
      "\t - Step 196: loss: 1.354 acc: 0.484\n",
      "\t - Step 197: loss: 1.359 acc: 0.500\n",
      "\t - Step 198: loss: 1.347 acc: 0.508\n",
      "\t - Step 199: loss: 1.280 acc: 0.484\n",
      "\t - Step 200: loss: 1.302 acc: 0.531\n",
      "\t - Step 201: loss: 1.230 acc: 0.508\n",
      "\t - Step 202: loss: 1.357 acc: 0.516\n",
      "\t - Step 203: loss: 1.164 acc: 0.555\n",
      "\t - Step 204: loss: 1.243 acc: 0.516\n",
      "\t - Step 205: loss: 1.269 acc: 0.469\n",
      "\t - Step 206: loss: 1.238 acc: 0.531\n",
      "\t - Step 207: loss: 1.348 acc: 0.508\n",
      "\t - Step 208: loss: 1.320 acc: 0.531\n",
      "\t - Step 209: loss: 1.356 acc: 0.484\n",
      "\t - Step 210: loss: 1.280 acc: 0.477\n",
      "\t - Step 211: loss: 1.284 acc: 0.523\n",
      "\t - Step 212: loss: 1.217 acc: 0.523\n",
      "\t - Step 213: loss: 1.273 acc: 0.477\n",
      "\t - Step 214: loss: 1.351 acc: 0.492\n",
      "\t - Step 215: loss: 1.442 acc: 0.383\n",
      "\t - Step 216: loss: 1.223 acc: 0.562\n",
      "\t - Step 217: loss: 1.365 acc: 0.484\n",
      "\t - Step 218: loss: 1.281 acc: 0.562\n",
      "\t - Step 219: loss: 1.200 acc: 0.547\n",
      "\t - Step 220: loss: 1.193 acc: 0.547\n",
      "\t - Step 221: loss: 1.393 acc: 0.414\n",
      "\t - Step 222: loss: 1.362 acc: 0.508\n",
      "\t - Step 223: loss: 1.390 acc: 0.492\n",
      "\t - Step 224: loss: 1.151 acc: 0.602\n",
      "\t - Step 225: loss: 1.390 acc: 0.568\n",
      "- Avg.loss: 1.271  | Avg.acc: 0.522\n",
      "- Avg. val_loss: 1.566  | Avg. val_acc: 0.414\n",
      "Epoch:  20\n",
      "\t - Step 1: loss: 1.199 acc: 0.570\n",
      "\t - Step 2: loss: 1.133 acc: 0.570\n",
      "\t - Step 3: loss: 1.180 acc: 0.617\n",
      "\t - Step 4: loss: 1.203 acc: 0.539\n",
      "\t - Step 5: loss: 1.281 acc: 0.500\n",
      "\t - Step 6: loss: 1.223 acc: 0.531\n",
      "\t - Step 7: loss: 1.147 acc: 0.586\n",
      "\t - Step 8: loss: 1.334 acc: 0.508\n",
      "\t - Step 9: loss: 1.263 acc: 0.516\n",
      "\t - Step 10: loss: 1.245 acc: 0.508\n",
      "\t - Step 11: loss: 1.197 acc: 0.516\n",
      "\t - Step 12: loss: 1.200 acc: 0.547\n",
      "\t - Step 13: loss: 1.238 acc: 0.562\n",
      "\t - Step 14: loss: 1.209 acc: 0.555\n",
      "\t - Step 15: loss: 1.220 acc: 0.516\n",
      "\t - Step 16: loss: 1.334 acc: 0.547\n",
      "\t - Step 17: loss: 1.267 acc: 0.555\n",
      "\t - Step 18: loss: 1.269 acc: 0.508\n",
      "\t - Step 19: loss: 1.133 acc: 0.555\n",
      "\t - Step 20: loss: 1.244 acc: 0.531\n",
      "\t - Step 21: loss: 1.259 acc: 0.523\n",
      "\t - Step 22: loss: 1.286 acc: 0.477\n",
      "\t - Step 23: loss: 1.361 acc: 0.492\n",
      "\t - Step 24: loss: 1.331 acc: 0.484\n",
      "\t - Step 25: loss: 1.260 acc: 0.492\n",
      "\t - Step 26: loss: 1.199 acc: 0.531\n",
      "\t - Step 27: loss: 1.326 acc: 0.461\n",
      "\t - Step 28: loss: 1.099 acc: 0.570\n",
      "\t - Step 29: loss: 1.059 acc: 0.617\n",
      "\t - Step 30: loss: 1.261 acc: 0.516\n",
      "\t - Step 31: loss: 1.239 acc: 0.500\n",
      "\t - Step 32: loss: 1.074 acc: 0.625\n",
      "\t - Step 33: loss: 1.088 acc: 0.602\n",
      "\t - Step 34: loss: 1.325 acc: 0.500\n",
      "\t - Step 35: loss: 1.263 acc: 0.539\n",
      "\t - Step 36: loss: 1.282 acc: 0.461\n",
      "\t - Step 37: loss: 1.217 acc: 0.523\n",
      "\t - Step 38: loss: 1.191 acc: 0.578\n",
      "\t - Step 39: loss: 1.282 acc: 0.492\n",
      "\t - Step 40: loss: 1.208 acc: 0.547\n",
      "\t - Step 41: loss: 1.238 acc: 0.508\n",
      "\t - Step 42: loss: 1.129 acc: 0.586\n",
      "\t - Step 43: loss: 1.271 acc: 0.547\n",
      "\t - Step 44: loss: 1.104 acc: 0.570\n",
      "\t - Step 45: loss: 1.333 acc: 0.523\n",
      "\t - Step 46: loss: 1.248 acc: 0.516\n",
      "\t - Step 47: loss: 1.344 acc: 0.500\n",
      "\t - Step 48: loss: 1.121 acc: 0.594\n",
      "\t - Step 49: loss: 1.275 acc: 0.484\n",
      "\t - Step 50: loss: 1.309 acc: 0.523\n",
      "\t - Step 51: loss: 1.260 acc: 0.492\n",
      "\t - Step 52: loss: 1.300 acc: 0.562\n",
      "\t - Step 53: loss: 1.361 acc: 0.453\n",
      "\t - Step 54: loss: 1.217 acc: 0.578\n",
      "\t - Step 55: loss: 1.365 acc: 0.477\n",
      "\t - Step 56: loss: 1.198 acc: 0.555\n",
      "\t - Step 57: loss: 1.227 acc: 0.523\n",
      "\t - Step 58: loss: 1.355 acc: 0.523\n",
      "\t - Step 59: loss: 1.197 acc: 0.531\n",
      "\t - Step 60: loss: 1.133 acc: 0.562\n",
      "\t - Step 61: loss: 1.351 acc: 0.492\n",
      "\t - Step 62: loss: 1.299 acc: 0.492\n",
      "\t - Step 63: loss: 1.341 acc: 0.508\n",
      "\t - Step 64: loss: 1.244 acc: 0.477\n",
      "\t - Step 65: loss: 1.468 acc: 0.477\n",
      "\t - Step 66: loss: 1.453 acc: 0.422\n",
      "\t - Step 67: loss: 1.414 acc: 0.438\n",
      "\t - Step 68: loss: 1.175 acc: 0.547\n",
      "\t - Step 69: loss: 1.276 acc: 0.523\n",
      "\t - Step 70: loss: 1.243 acc: 0.539\n",
      "\t - Step 71: loss: 1.172 acc: 0.523\n",
      "\t - Step 72: loss: 1.294 acc: 0.516\n",
      "\t - Step 73: loss: 1.294 acc: 0.531\n",
      "\t - Step 74: loss: 1.389 acc: 0.461\n",
      "\t - Step 75: loss: 1.318 acc: 0.484\n",
      "\t - Step 76: loss: 1.180 acc: 0.609\n",
      "\t - Step 77: loss: 1.186 acc: 0.547\n",
      "\t - Step 78: loss: 1.304 acc: 0.484\n",
      "\t - Step 79: loss: 1.174 acc: 0.562\n",
      "\t - Step 80: loss: 1.359 acc: 0.469\n",
      "\t - Step 81: loss: 1.241 acc: 0.562\n",
      "\t - Step 82: loss: 1.192 acc: 0.547\n",
      "\t - Step 83: loss: 1.111 acc: 0.602\n",
      "\t - Step 84: loss: 1.372 acc: 0.438\n",
      "\t - Step 85: loss: 1.296 acc: 0.469\n",
      "\t - Step 86: loss: 1.311 acc: 0.484\n",
      "\t - Step 87: loss: 1.155 acc: 0.625\n",
      "\t - Step 88: loss: 1.345 acc: 0.539\n",
      "\t - Step 89: loss: 1.247 acc: 0.555\n",
      "\t - Step 90: loss: 1.274 acc: 0.516\n",
      "\t - Step 91: loss: 1.404 acc: 0.523\n",
      "\t - Step 92: loss: 1.384 acc: 0.492\n",
      "\t - Step 93: loss: 1.222 acc: 0.562\n",
      "\t - Step 94: loss: 1.201 acc: 0.531\n",
      "\t - Step 95: loss: 1.214 acc: 0.578\n",
      "\t - Step 96: loss: 1.319 acc: 0.477\n",
      "\t - Step 97: loss: 1.475 acc: 0.453\n",
      "\t - Step 98: loss: 1.189 acc: 0.570\n",
      "\t - Step 99: loss: 1.174 acc: 0.578\n",
      "\t - Step 100: loss: 1.352 acc: 0.484\n",
      "\t - Step 101: loss: 1.241 acc: 0.523\n",
      "\t - Step 102: loss: 1.192 acc: 0.594\n",
      "\t - Step 103: loss: 1.244 acc: 0.500\n",
      "\t - Step 104: loss: 1.274 acc: 0.500\n",
      "\t - Step 105: loss: 1.289 acc: 0.531\n",
      "\t - Step 106: loss: 1.287 acc: 0.516\n",
      "\t - Step 107: loss: 1.251 acc: 0.539\n",
      "\t - Step 108: loss: 1.377 acc: 0.484\n",
      "\t - Step 109: loss: 1.143 acc: 0.594\n",
      "\t - Step 110: loss: 1.305 acc: 0.508\n",
      "\t - Step 111: loss: 1.283 acc: 0.547\n",
      "\t - Step 112: loss: 1.282 acc: 0.531\n",
      "\t - Step 113: loss: 1.205 acc: 0.539\n",
      "\t - Step 114: loss: 1.232 acc: 0.516\n",
      "\t - Step 115: loss: 1.388 acc: 0.492\n",
      "\t - Step 116: loss: 1.354 acc: 0.547\n",
      "\t - Step 117: loss: 1.219 acc: 0.578\n",
      "\t - Step 118: loss: 1.364 acc: 0.438\n",
      "\t - Step 119: loss: 1.189 acc: 0.555\n",
      "\t - Step 120: loss: 1.300 acc: 0.531\n",
      "\t - Step 121: loss: 1.318 acc: 0.508\n",
      "\t - Step 122: loss: 1.254 acc: 0.555\n",
      "\t - Step 123: loss: 1.208 acc: 0.539\n",
      "\t - Step 124: loss: 1.332 acc: 0.430\n",
      "\t - Step 125: loss: 1.302 acc: 0.477\n",
      "\t - Step 126: loss: 1.309 acc: 0.523\n",
      "\t - Step 127: loss: 1.286 acc: 0.531\n",
      "\t - Step 128: loss: 1.285 acc: 0.492\n",
      "\t - Step 129: loss: 1.311 acc: 0.484\n",
      "\t - Step 130: loss: 1.196 acc: 0.531\n",
      "\t - Step 131: loss: 1.168 acc: 0.547\n",
      "\t - Step 132: loss: 1.356 acc: 0.484\n",
      "\t - Step 133: loss: 1.106 acc: 0.602\n",
      "\t - Step 134: loss: 1.332 acc: 0.500\n",
      "\t - Step 135: loss: 1.233 acc: 0.531\n",
      "\t - Step 136: loss: 1.259 acc: 0.516\n",
      "\t - Step 137: loss: 1.251 acc: 0.547\n",
      "\t - Step 138: loss: 1.272 acc: 0.508\n",
      "\t - Step 139: loss: 1.201 acc: 0.531\n",
      "\t - Step 140: loss: 1.134 acc: 0.594\n",
      "\t - Step 141: loss: 1.245 acc: 0.531\n",
      "\t - Step 142: loss: 1.164 acc: 0.562\n",
      "\t - Step 143: loss: 1.194 acc: 0.516\n",
      "\t - Step 144: loss: 1.277 acc: 0.539\n",
      "\t - Step 145: loss: 1.342 acc: 0.516\n",
      "\t - Step 146: loss: 1.184 acc: 0.523\n",
      "\t - Step 147: loss: 1.290 acc: 0.500\n",
      "\t - Step 148: loss: 1.387 acc: 0.500\n",
      "\t - Step 149: loss: 1.266 acc: 0.531\n",
      "\t - Step 150: loss: 1.299 acc: 0.547\n",
      "\t - Step 151: loss: 1.295 acc: 0.484\n",
      "\t - Step 152: loss: 1.154 acc: 0.602\n",
      "\t - Step 153: loss: 1.262 acc: 0.484\n",
      "\t - Step 154: loss: 1.295 acc: 0.531\n",
      "\t - Step 155: loss: 1.382 acc: 0.516\n",
      "\t - Step 156: loss: 1.163 acc: 0.555\n",
      "\t - Step 157: loss: 1.089 acc: 0.633\n",
      "\t - Step 158: loss: 1.221 acc: 0.555\n",
      "\t - Step 159: loss: 1.221 acc: 0.586\n",
      "\t - Step 160: loss: 1.223 acc: 0.586\n",
      "\t - Step 161: loss: 1.210 acc: 0.562\n",
      "\t - Step 162: loss: 1.298 acc: 0.508\n",
      "\t - Step 163: loss: 1.288 acc: 0.500\n",
      "\t - Step 164: loss: 1.315 acc: 0.492\n",
      "\t - Step 165: loss: 1.404 acc: 0.500\n",
      "\t - Step 166: loss: 1.256 acc: 0.516\n",
      "\t - Step 167: loss: 1.385 acc: 0.523\n",
      "\t - Step 168: loss: 1.384 acc: 0.516\n",
      "\t - Step 169: loss: 1.153 acc: 0.594\n",
      "\t - Step 170: loss: 1.306 acc: 0.484\n",
      "\t - Step 171: loss: 1.155 acc: 0.602\n",
      "\t - Step 172: loss: 1.243 acc: 0.539\n",
      "\t - Step 173: loss: 1.227 acc: 0.531\n",
      "\t - Step 174: loss: 1.349 acc: 0.445\n",
      "\t - Step 175: loss: 1.466 acc: 0.414\n",
      "\t - Step 176: loss: 1.344 acc: 0.523\n",
      "\t - Step 177: loss: 1.340 acc: 0.461\n",
      "\t - Step 178: loss: 1.141 acc: 0.570\n",
      "\t - Step 179: loss: 1.264 acc: 0.594\n",
      "\t - Step 180: loss: 1.332 acc: 0.461\n",
      "\t - Step 181: loss: 1.323 acc: 0.484\n",
      "\t - Step 182: loss: 1.277 acc: 0.477\n",
      "\t - Step 183: loss: 1.267 acc: 0.555\n",
      "\t - Step 184: loss: 1.260 acc: 0.508\n",
      "\t - Step 185: loss: 1.428 acc: 0.430\n",
      "\t - Step 186: loss: 1.327 acc: 0.523\n",
      "\t - Step 187: loss: 1.414 acc: 0.430\n",
      "\t - Step 188: loss: 1.239 acc: 0.523\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t - Step 189: loss: 1.314 acc: 0.508\n",
      "\t - Step 190: loss: 1.217 acc: 0.578\n",
      "\t - Step 191: loss: 1.331 acc: 0.508\n",
      "\t - Step 192: loss: 1.248 acc: 0.547\n",
      "\t - Step 193: loss: 1.319 acc: 0.484\n",
      "\t - Step 194: loss: 1.284 acc: 0.539\n",
      "\t - Step 195: loss: 1.338 acc: 0.523\n",
      "\t - Step 196: loss: 1.223 acc: 0.602\n",
      "\t - Step 197: loss: 1.171 acc: 0.555\n",
      "\t - Step 198: loss: 1.306 acc: 0.508\n",
      "\t - Step 199: loss: 1.179 acc: 0.523\n",
      "\t - Step 200: loss: 1.307 acc: 0.516\n",
      "\t - Step 201: loss: 1.213 acc: 0.523\n",
      "\t - Step 202: loss: 1.349 acc: 0.508\n",
      "\t - Step 203: loss: 1.241 acc: 0.531\n",
      "\t - Step 204: loss: 1.282 acc: 0.523\n",
      "\t - Step 205: loss: 1.361 acc: 0.461\n",
      "\t - Step 206: loss: 1.421 acc: 0.500\n",
      "\t - Step 207: loss: 1.345 acc: 0.430\n",
      "\t - Step 208: loss: 1.348 acc: 0.500\n",
      "\t - Step 209: loss: 1.254 acc: 0.547\n",
      "\t - Step 210: loss: 1.144 acc: 0.602\n",
      "\t - Step 211: loss: 1.200 acc: 0.578\n",
      "\t - Step 212: loss: 1.391 acc: 0.422\n",
      "\t - Step 213: loss: 1.343 acc: 0.531\n",
      "\t - Step 214: loss: 1.246 acc: 0.484\n",
      "\t - Step 215: loss: 1.257 acc: 0.539\n",
      "\t - Step 216: loss: 1.286 acc: 0.562\n",
      "\t - Step 217: loss: 1.403 acc: 0.477\n",
      "\t - Step 218: loss: 1.331 acc: 0.523\n",
      "\t - Step 219: loss: 1.275 acc: 0.523\n",
      "\t - Step 220: loss: 1.175 acc: 0.523\n",
      "\t - Step 221: loss: 1.421 acc: 0.406\n",
      "\t - Step 222: loss: 1.268 acc: 0.492\n",
      "\t - Step 223: loss: 1.253 acc: 0.562\n",
      "\t - Step 224: loss: 1.278 acc: 0.523\n",
      "\t - Step 225: loss: 1.469 acc: 0.405\n",
      "- Avg.loss: 1.268  | Avg.acc: 0.524\n",
      "- Avg. val_loss: 1.574  | Avg. val_acc: 0.409\n",
      "Epoch:  21\n",
      "\t - Step 1: loss: 1.268 acc: 0.500\n",
      "\t - Step 2: loss: 1.267 acc: 0.500\n",
      "\t - Step 3: loss: 1.193 acc: 0.547\n",
      "\t - Step 4: loss: 1.278 acc: 0.516\n",
      "\t - Step 5: loss: 1.250 acc: 0.562\n",
      "\t - Step 6: loss: 1.179 acc: 0.555\n",
      "\t - Step 7: loss: 1.212 acc: 0.516\n",
      "\t - Step 8: loss: 1.347 acc: 0.500\n",
      "\t - Step 9: loss: 1.176 acc: 0.555\n",
      "\t - Step 10: loss: 1.344 acc: 0.523\n",
      "\t - Step 11: loss: 1.331 acc: 0.547\n",
      "\t - Step 12: loss: 1.174 acc: 0.578\n",
      "\t - Step 13: loss: 1.150 acc: 0.594\n",
      "\t - Step 14: loss: 1.211 acc: 0.570\n",
      "\t - Step 15: loss: 1.165 acc: 0.570\n",
      "\t - Step 16: loss: 1.283 acc: 0.500\n",
      "\t - Step 17: loss: 1.099 acc: 0.508\n",
      "\t - Step 18: loss: 1.217 acc: 0.555\n",
      "\t - Step 19: loss: 1.330 acc: 0.492\n",
      "\t - Step 20: loss: 1.144 acc: 0.609\n",
      "\t - Step 21: loss: 1.175 acc: 0.594\n",
      "\t - Step 22: loss: 1.144 acc: 0.586\n",
      "\t - Step 23: loss: 1.308 acc: 0.508\n",
      "\t - Step 24: loss: 1.300 acc: 0.484\n",
      "\t - Step 25: loss: 1.097 acc: 0.570\n",
      "\t - Step 26: loss: 1.098 acc: 0.562\n",
      "\t - Step 27: loss: 1.356 acc: 0.531\n",
      "\t - Step 28: loss: 1.342 acc: 0.484\n",
      "\t - Step 29: loss: 1.337 acc: 0.453\n",
      "\t - Step 30: loss: 1.372 acc: 0.484\n",
      "\t - Step 31: loss: 1.168 acc: 0.594\n",
      "\t - Step 32: loss: 1.172 acc: 0.562\n",
      "\t - Step 33: loss: 1.416 acc: 0.453\n",
      "\t - Step 34: loss: 1.316 acc: 0.523\n",
      "\t - Step 35: loss: 1.218 acc: 0.523\n",
      "\t - Step 36: loss: 1.208 acc: 0.586\n",
      "\t - Step 37: loss: 1.265 acc: 0.531\n",
      "\t - Step 38: loss: 1.282 acc: 0.547\n",
      "\t - Step 39: loss: 1.224 acc: 0.555\n",
      "\t - Step 40: loss: 1.219 acc: 0.516\n",
      "\t - Step 41: loss: 1.402 acc: 0.469\n",
      "\t - Step 42: loss: 1.148 acc: 0.578\n",
      "\t - Step 43: loss: 1.312 acc: 0.508\n",
      "\t - Step 44: loss: 1.213 acc: 0.508\n",
      "\t - Step 45: loss: 1.320 acc: 0.477\n",
      "\t - Step 46: loss: 1.363 acc: 0.453\n",
      "\t - Step 47: loss: 1.203 acc: 0.547\n",
      "\t - Step 48: loss: 1.321 acc: 0.469\n",
      "\t - Step 49: loss: 1.303 acc: 0.516\n",
      "\t - Step 50: loss: 1.247 acc: 0.555\n",
      "\t - Step 51: loss: 1.249 acc: 0.508\n",
      "\t - Step 52: loss: 1.288 acc: 0.492\n",
      "\t - Step 53: loss: 1.227 acc: 0.531\n",
      "\t - Step 54: loss: 1.318 acc: 0.523\n",
      "\t - Step 55: loss: 1.216 acc: 0.594\n",
      "\t - Step 56: loss: 1.237 acc: 0.547\n",
      "\t - Step 57: loss: 1.194 acc: 0.539\n",
      "\t - Step 58: loss: 1.268 acc: 0.523\n",
      "\t - Step 59: loss: 1.212 acc: 0.516\n",
      "\t - Step 60: loss: 1.231 acc: 0.562\n",
      "\t - Step 61: loss: 1.182 acc: 0.555\n",
      "\t - Step 62: loss: 1.101 acc: 0.578\n",
      "\t - Step 63: loss: 1.228 acc: 0.531\n",
      "\t - Step 64: loss: 1.189 acc: 0.539\n",
      "\t - Step 65: loss: 1.200 acc: 0.477\n",
      "\t - Step 66: loss: 1.347 acc: 0.484\n",
      "\t - Step 67: loss: 1.333 acc: 0.547\n",
      "\t - Step 68: loss: 1.273 acc: 0.516\n",
      "\t - Step 69: loss: 1.220 acc: 0.578\n",
      "\t - Step 70: loss: 1.300 acc: 0.547\n",
      "\t - Step 71: loss: 1.256 acc: 0.531\n",
      "\t - Step 72: loss: 1.332 acc: 0.555\n",
      "\t - Step 73: loss: 1.235 acc: 0.508\n",
      "\t - Step 74: loss: 1.205 acc: 0.523\n",
      "\t - Step 75: loss: 1.273 acc: 0.508\n",
      "\t - Step 76: loss: 1.308 acc: 0.547\n",
      "\t - Step 77: loss: 1.097 acc: 0.617\n",
      "\t - Step 78: loss: 1.217 acc: 0.508\n",
      "\t - Step 79: loss: 1.174 acc: 0.578\n",
      "\t - Step 80: loss: 1.227 acc: 0.539\n",
      "\t - Step 81: loss: 1.198 acc: 0.531\n",
      "\t - Step 82: loss: 1.278 acc: 0.531\n",
      "\t - Step 83: loss: 1.262 acc: 0.547\n",
      "\t - Step 84: loss: 1.093 acc: 0.586\n",
      "\t - Step 85: loss: 1.210 acc: 0.555\n",
      "\t - Step 86: loss: 1.142 acc: 0.562\n",
      "\t - Step 87: loss: 1.242 acc: 0.523\n",
      "\t - Step 88: loss: 1.235 acc: 0.531\n",
      "\t - Step 89: loss: 1.236 acc: 0.555\n",
      "\t - Step 90: loss: 1.217 acc: 0.516\n",
      "\t - Step 91: loss: 1.330 acc: 0.539\n",
      "\t - Step 92: loss: 1.221 acc: 0.555\n",
      "\t - Step 93: loss: 1.158 acc: 0.555\n",
      "\t - Step 94: loss: 1.232 acc: 0.523\n",
      "\t - Step 95: loss: 1.255 acc: 0.555\n",
      "\t - Step 96: loss: 1.269 acc: 0.500\n",
      "\t - Step 97: loss: 1.147 acc: 0.609\n",
      "\t - Step 98: loss: 1.297 acc: 0.492\n",
      "\t - Step 99: loss: 1.301 acc: 0.500\n",
      "\t - Step 100: loss: 1.172 acc: 0.508\n",
      "\t - Step 101: loss: 1.202 acc: 0.562\n",
      "\t - Step 102: loss: 1.233 acc: 0.547\n",
      "\t - Step 103: loss: 1.336 acc: 0.469\n",
      "\t - Step 104: loss: 1.376 acc: 0.484\n",
      "\t - Step 105: loss: 1.177 acc: 0.508\n",
      "\t - Step 106: loss: 1.431 acc: 0.461\n",
      "\t - Step 107: loss: 1.277 acc: 0.516\n",
      "\t - Step 108: loss: 1.413 acc: 0.477\n",
      "\t - Step 109: loss: 1.433 acc: 0.453\n",
      "\t - Step 110: loss: 1.370 acc: 0.469\n",
      "\t - Step 111: loss: 1.222 acc: 0.508\n",
      "\t - Step 112: loss: 1.186 acc: 0.586\n",
      "\t - Step 113: loss: 1.176 acc: 0.609\n",
      "\t - Step 114: loss: 1.315 acc: 0.492\n",
      "\t - Step 115: loss: 1.130 acc: 0.578\n",
      "\t - Step 116: loss: 1.240 acc: 0.484\n",
      "\t - Step 117: loss: 1.125 acc: 0.602\n",
      "\t - Step 118: loss: 1.112 acc: 0.609\n",
      "\t - Step 119: loss: 1.288 acc: 0.516\n",
      "\t - Step 120: loss: 1.098 acc: 0.570\n",
      "\t - Step 121: loss: 1.270 acc: 0.570\n",
      "\t - Step 122: loss: 1.299 acc: 0.508\n",
      "\t - Step 123: loss: 1.250 acc: 0.516\n",
      "\t - Step 124: loss: 1.241 acc: 0.555\n",
      "\t - Step 125: loss: 1.358 acc: 0.461\n",
      "\t - Step 126: loss: 1.321 acc: 0.477\n",
      "\t - Step 127: loss: 1.326 acc: 0.469\n",
      "\t - Step 128: loss: 1.399 acc: 0.477\n",
      "\t - Step 129: loss: 1.173 acc: 0.609\n",
      "\t - Step 130: loss: 1.279 acc: 0.531\n",
      "\t - Step 131: loss: 1.285 acc: 0.516\n",
      "\t - Step 132: loss: 1.311 acc: 0.508\n",
      "\t - Step 133: loss: 1.400 acc: 0.484\n",
      "\t - Step 134: loss: 1.445 acc: 0.469\n",
      "\t - Step 135: loss: 1.326 acc: 0.484\n",
      "\t - Step 136: loss: 1.291 acc: 0.531\n",
      "\t - Step 137: loss: 1.270 acc: 0.547\n",
      "\t - Step 138: loss: 1.304 acc: 0.492\n",
      "\t - Step 139: loss: 1.258 acc: 0.492\n",
      "\t - Step 140: loss: 1.259 acc: 0.453\n",
      "\t - Step 141: loss: 1.329 acc: 0.508\n",
      "\t - Step 142: loss: 1.250 acc: 0.477\n",
      "\t - Step 143: loss: 1.307 acc: 0.492\n",
      "\t - Step 144: loss: 1.348 acc: 0.469\n",
      "\t - Step 145: loss: 1.324 acc: 0.492\n",
      "\t - Step 146: loss: 1.361 acc: 0.430\n",
      "\t - Step 147: loss: 1.439 acc: 0.438\n",
      "\t - Step 148: loss: 1.284 acc: 0.555\n",
      "\t - Step 149: loss: 1.311 acc: 0.477\n",
      "\t - Step 150: loss: 1.242 acc: 0.516\n",
      "\t - Step 151: loss: 1.268 acc: 0.508\n",
      "\t - Step 152: loss: 1.266 acc: 0.555\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-df0a0156e9d3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;31m# forward + backward + optimize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-52ce6552364d>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     63\u001b[0m                 \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msv_blocks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m             \u001b[0mouts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-11fd0e297c9c>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;31m# 1st\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatchnorm1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2d_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mconv2d_forward\u001b[0;34m(self, input, weight)\u001b[0m\n\u001b[1;32m    340\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    341\u001b[0m         return F.conv2d(input, weight, self.bias, self.stride,\n\u001b[0;32m--> 342\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = model.to(device)\n",
    "\n",
    "model_path = '/tf/data/Quan/fer2013/skippedvgg.pt'\n",
    "best_acc = 0.0\n",
    "hist = []\n",
    "\n",
    "for epoch in range(200):  # loop over the dataset multiple times\n",
    "    \n",
    "    print('Epoch: ', epoch + 1)\n",
    "    running_loss = 0.0\n",
    "    running_acc = 0.0\n",
    "\n",
    "    # TRAIN\n",
    "    model.train()\n",
    "    for i, data in enumerate(train_loader):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "        acc = float((torch.argmax(outputs, dim=1) == labels).float().sum()/labels.size(0))\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        running_acc += acc\n",
    "        print('\\t - Step %d: loss: %.3f acc: %.3f' % (i+1, loss.item(), acc))\n",
    "\n",
    "    print('- Avg.loss: %.3f  | Avg.acc: %.3f' % (running_loss / (i+1), running_acc / (i+1)))\n",
    "    avgloss = running_loss / (i+1)\n",
    "    avgacc = running_acc / (i+1)\n",
    "\n",
    "    # EVALUATE\n",
    "    model.eval()\n",
    "    running_valloss = 0.0\n",
    "    running_valacc = 0.0\n",
    "    for i,data in enumerate(val_loader):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        acc = float((torch.argmax(outputs, dim=1) == labels).float().sum()/labels.size(0))\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        running_valloss += loss.item()\n",
    "        running_valacc += acc\n",
    "\n",
    "    print('- Avg. val_loss: %.3f  | Avg. val_acc: %.3f' % (running_valloss / (i+1), running_valacc / (i+1)))\n",
    "\n",
    "    avgvalloss = running_valloss / (i+1)\n",
    "    avgvalcc = running_valacc / (i+1)\n",
    "\n",
    "    hist.append([avgloss, avgvalloss, avgacc, avgvalcc])\n",
    "    if best_acc < (running_valacc / (i+1)):\n",
    "        best_acc = (running_valacc / (i+1))\n",
    "        torch.save(model, model_path)\n",
    "        print('* Update optimal model')\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
