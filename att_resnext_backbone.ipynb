{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import transforms, datasets\n",
    "\n",
    "data_transform = transforms.Compose([\n",
    "        transforms.Grayscale(num_output_channels=1),\n",
    "        # transforms.RandomSizedCrop(224),\n",
    "#         transforms.RandomHorizontalFlip(),\n",
    "#         transforms.RandomVerticalFlip(),\n",
    "#         transforms.RandomRotation(degrees=180),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,), (0.5,))\n",
    "    ])\n",
    "\n",
    "train_fer = datasets.ImageFolder(root='/tf/data/Quan/fer2013/data/train', transform=data_transform)\n",
    "val_fer = datasets.ImageFolder(root='/tf/data/Quan/fer2013/data/val', transform=data_transform)\n",
    "test_fer = datasets.ImageFolder(root='/tf/data/Quan/fer2013/data/test', transform=data_transform)\n",
    "\n",
    "batch_size = 64\n",
    "train_loader = torch.utils.data.DataLoader(train_fer,\n",
    "                                             batch_size=batch_size, shuffle=True,\n",
    "                                             num_workers=8)\n",
    "val_loader = torch.utils.data.DataLoader(val_fer,\n",
    "                                             batch_size=batch_size, shuffle=True,\n",
    "                                             num_workers=8)\n",
    "test_loader = torch.utils.data.DataLoader(test_fer,\n",
    "                                             batch_size=batch_size, shuffle=True,\n",
    "                                             num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeightFeature(nn.Module):\n",
    "\n",
    "    def __init__(self, feature_depth, target_depth):\n",
    "        super(WeightFeature, self).__init__()\n",
    "\n",
    "        self.target_depth = target_depth\n",
    "#         self.conv1 = nn.Conv2d(feature_depth, feature_depth, kernel_size=feature_size, padding=0)\n",
    "#         self.bn = nn.BatchNorm2d(feature_depth)\n",
    "        self.fc1 = nn.Linear(feature_depth, target_depth)\n",
    "        self.bn1 = nn.BatchNorm1d(target_depth)\n",
    "        self.bn2 = nn.BatchNorm2d(target_depth)\n",
    "        \n",
    "    def forward(self, x1, x2):\n",
    "        '''\n",
    "        x1 -> GAP -> FC -> * with x2-> x2 --> out\n",
    "        x2 ----------------------------|\n",
    "        '''\n",
    "        x1 = nn.AvgPool2d(kernel_size=(x1.size(-2), x1.size(-1)))(x1)\n",
    "#         x1 = self.conv1(x1)\n",
    "#         x1 = self.bn(x1)\n",
    "#         x1 = nn.ReLU()(x1)\n",
    "        x1 = nn.Flatten()(x1)\n",
    "\n",
    "        x1 = self.fc1(x1)\n",
    "        x1 = nn.Dropout(0.6)(x1)\n",
    "        x1 = self.bn1(x1)\n",
    "        x1 = nn.Sigmoid()(x1)\n",
    "#         x1 = nn.ReLU()(x1)\n",
    "        x_out = x1.unsqueeze(-1).unsqueeze(-1)\n",
    "        # print(x1.size())\n",
    "        # x2 = self.conv1(x2)\n",
    "\n",
    "        x_out = torch.mul(x2, x_out)\n",
    "        x_out = x_out + x2 \n",
    "        x_out = self.bn2(x_out)\n",
    "\n",
    "        return x_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SVblock(nn.Module):\n",
    "    def __init__(self, in_neurons, nb_neurons, cardinality=4, kernel_size=(3,3), batch_norm=True, activation='relu', **kwargs):\n",
    "        '''\n",
    "    in_neurons: C_in\n",
    "    nb_neurons: n_filters of conv2d\n",
    "    '''\n",
    "        super(SVblock, self).__init__()\n",
    "        \n",
    "        self.device = torch.device('cpu') if not 'device' in kwargs else kwargs['device']\n",
    "        self.index = kwargs['index'] if 'index' in kwargs else None\n",
    "        self.card = cardinality\n",
    "        self.n_set = nb_neurons // self.card\n",
    "        \n",
    "        self.wf = WeightFeature(nb_neurons, nb_neurons)\n",
    "        \n",
    "        self.pre_convs = nn.Sequential(nn.Conv2d(in_neurons, nb_neurons, kernel_size=kernel_size, padding=1, stride=1),\n",
    "                                       nn.BatchNorm2d(nb_neurons),\n",
    "                                       nn.ReLU(inplace=True))\n",
    "        \n",
    "        self.convs = []\n",
    "        for i in range(self.n_set):\n",
    "            self.convs.append(nn.Sequential(nn.Conv2d(nb_neurons, self.card, kernel_size=(1,1), padding=0, stride=1),\n",
    "                                            nn.BatchNorm2d(self.card), nn.ReLU(inplace=True),\n",
    "                                            nn.Conv2d(self.card, self.card, kernel_size=kernel_size, padding=1, stride=1),\n",
    "                                            nn.BatchNorm2d(self.card), nn.ReLU(inplace=True),\n",
    "                                            nn.Conv2d(self.card, nb_neurons, kernel_size=(1,1), padding=0, stride=1),\n",
    "                                            nn.BatchNorm2d(nb_neurons), nn.ReLU(inplace=True)).to(self.device))      \n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        '''\n",
    "        x: single output layer of list \n",
    "        '''\n",
    "\n",
    "        x = self.pre_convs(x)\n",
    "        \n",
    "        out = self.convs[0](x)\n",
    "        for i in range(1, len(self.convs)):\n",
    "            out = out + self.convs[i](x)\n",
    "            \n",
    "        x_out = self.wf(x, out)\n",
    "\n",
    "        return x_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SVGG(nn.Module):\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super(SVGG, self).__init__()\n",
    "\n",
    "        self.device = torch.device('cpu') if not 'device' in kwargs else kwargs['device']\n",
    "\n",
    "        self.sv0 = SVblock(1,64).to(self.device)\n",
    "#         self.sv00 = SVblock(64,64).to(self.device)\n",
    "        self.sv1 = SVblock(64, 128).to(self.device)\n",
    "#         self.sv11 = SVblock(128, 128).to(self.device)\n",
    "        self.sv2 = SVblock(128, 256).to(self.device)\n",
    "#         self.sv22 = SVblock(256, 256).to(self.device)\n",
    "        self.sv3 = SVblock(256, 512).to(self.device)\n",
    "#         self.sv33 = SVblock(512, 512).to(self.device)\n",
    "        self.sv4 = SVblock(512, 1024, feature_size=3).to(self.device)\n",
    "#         self.sv44 = SVblock(1024, 1024).to(self.device)\n",
    "\n",
    "        self.bn_preout = nn.BatchNorm1d(3008)\n",
    "        self.fc1 = nn.Linear(3008, 512)\n",
    "        self.bn1 = nn.BatchNorm1d(512)\n",
    "        self.fc2 = nn.Linear(512, 7)\n",
    "        self.bn2 = nn.BatchNorm1d(7)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x0 = self.sv0(x)\n",
    "#         x0 = self.sv00(x0)\n",
    "        x0 = nn.MaxPool2d(kernel_size=(2,2), stride=2)(x0)\n",
    "        \n",
    "        x1 = self.sv1(x0)\n",
    "#         x1 = self.sv11(x1)\n",
    "        x1 = nn.MaxPool2d(kernel_size=(2,2), stride=2)(x1)\n",
    "        \n",
    "        x2 = self.sv2(x1)\n",
    "#         x2 = self.sv22(x2)\n",
    "        x2 = nn.MaxPool2d(kernel_size=(2,2), stride=2)(x2)\n",
    "        \n",
    "        x3 = self.sv3(x2)\n",
    "#         x3 = self.sv33(x3)\n",
    "        x3 = nn.MaxPool2d(kernel_size=(2,2), stride=2)(x3)\n",
    "        \n",
    "        x4 = self.sv4(x3)\n",
    "#         x = self.sv44(x)\n",
    "        x4 = nn.MaxPool2d(kernel_size=(2,2), stride=2)(x4)\n",
    "        \n",
    "        x4 = nn.AvgPool2d(kernel_size=(x4.size(-2), x4.size(-1)))(x4)\n",
    "        x4 = nn.Flatten()(x4)\n",
    "        \n",
    "#         x3 = nn.AvgPool2d(kernel_size=(x3.size(-2), x3.size(-1)))(x3)\n",
    "#         x3 = nn.Flatten()(x3)\n",
    "        \n",
    "#         x2 = nn.AvgPool2d(kernel_size=(x2.size(-2), x2.size(-1)))(x2)\n",
    "#         x2 = nn.Flatten()(x2)\n",
    "        \n",
    "#         x1 = nn.AvgPool2d(kernel_size=(x1.size(-2), x1.size(-1)))(x1)\n",
    "#         x1 = nn.Flatten()(x1)\n",
    "        \n",
    "#         x0 = nn.AvgPool2d(kernel_size=(x0.size(-2), x0.size(-1)))(x0)\n",
    "#         x0 = nn.Flatten()(x0)\n",
    "        \n",
    "#         x_out = torch.cat([x4, x3, x2, x1, x0], dim=1)\n",
    "\n",
    "        x_out = torch.cat([gap0, gap1, gap2, gap3, gap4, x4], dim=1)\n",
    "        \n",
    "\n",
    "        x_out = self.fc1(x_out)\n",
    "        x_out = self.bn1(x_out)\n",
    "        x_out = nn.Dropout(0.6)(x_out)\n",
    "        x_out = self.fc2(x_out)\n",
    "        x_out = self.bn2(x_out)\n",
    "\n",
    "        return x_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')\n",
    "print(device)\n",
    "\n",
    "model = SVGG(device=device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "\n",
    "# model.train()\n",
    "\n",
    "# model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SVGG()\n",
    "model(torch.rand(128, 1, 48, 48))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
