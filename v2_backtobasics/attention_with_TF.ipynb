{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import time\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.lines import Line2D      \n",
    "\n",
    "def plot_grad_flow(named_parameters, epoch, loss, acc, savepath):\n",
    "    '''Plots the gradients flowing through different layers in the net during training.\n",
    "    Can be used for checking for possible gradient vanishing / exploding problems.\n",
    "    \n",
    "    Usage: Plug this function in Trainer class after loss.backwards() as \n",
    "    \"plot_grad_flow(self.model.named_parameters())\" to visualize the gradient flow'''\n",
    "    ave_grads = []\n",
    "    max_grads= []\n",
    "    layers = []\n",
    "    for n, p in named_parameters:\n",
    "        if(p.requires_grad) and (\"bias\" not in n):\n",
    "\n",
    "            try:\n",
    "                ave_grads.append(p.grad.abs().mean())\n",
    "                max_grads.append(p.grad.abs().max())\n",
    "                layers.append(n)\n",
    "            except:\n",
    "                continue\n",
    "#                 ave_grads.append(0.)\n",
    "#                 max_grads.append(0.)\n",
    "#                 layers.append(n)\n",
    "                \n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.bar(np.arange(len(max_grads)), max_grads, alpha=0.5, lw=1, color=\"c\")\n",
    "    plt.bar(np.arange(len(max_grads)), ave_grads, alpha=0.5, lw=1, color=\"b\")\n",
    "    plt.hlines(0, 0, len(ave_grads)+1, lw=2, color=\"k\" )\n",
    "    plt.xticks(range(0,len(ave_grads), 1), layers, rotation=\"vertical\")\n",
    "    plt.xlim(left=0, right=len(ave_grads))\n",
    "    plt.ylim(bottom = -0.001, top=0.02) # zoom in on the lower gradient regions\n",
    "    plt.xlabel(\"Layers\")\n",
    "    plt.ylabel(\"average gradient\")\n",
    "    plt.title(\"Gradient flow | Epoch \" + str(epoch) + \" | ls: \" + str(loss) + \" | ac: \" + str(acc))\n",
    "    plt.tight_layout()\n",
    "    plt.grid(True)\n",
    "    plt.legend([Line2D([0], [0], color=\"c\", lw=4),\n",
    "                Line2D([0], [0], color=\"b\", lw=4),\n",
    "                Line2D([0], [0], color=\"k\", lw=4)], ['max-gradient', 'mean-gradient', 'zero-gradient'])\n",
    "    \n",
    "    if not savepath is None:\n",
    "        plt.savefig(savepath)\n",
    "        \n",
    "    plt.close()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import transforms, datasets\n",
    "\n",
    "train_data_transform = transforms.Compose([\n",
    "        \n",
    "#         transforms.Lambda(lbp_transform),\n",
    "#         transforms.Lambda(combine_lbp_hog),\n",
    "#         transforms.ToPILImage(),\n",
    "        # transforms.RandomSizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "#         transforms.RandomVerticalFlip(),\n",
    "        transforms.RandomRotation(degrees=150),\n",
    "        transforms.Grayscale(num_output_channels=1),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,), (0.5,))\n",
    "    ])\n",
    "\n",
    "test_data_transform = transforms.Compose([\n",
    "        transforms.Grayscale(num_output_channels=1),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,), (0.5,))\n",
    "    ])\n",
    "\n",
    "train_fer = datasets.ImageFolder(root='/tf/data/Quan/fer2013/cleaned_data/fer2013-clean/Training', transform=train_data_transform)\n",
    "val_fer = datasets.ImageFolder(root='/tf/data/Quan/fer2013/cleaned_data/fer2013-clean/PublicTest', transform=test_data_transform)\n",
    "test_fer = datasets.ImageFolder(root='/tf/data/Quan/fer2013/cleaned_data/fer2013-clean/PrivateTest/', transform=test_data_transform)\n",
    "\n",
    "batch_size = 128\n",
    "train_loader = torch.utils.data.DataLoader(train_fer,\n",
    "                                             batch_size=batch_size, shuffle=True,\n",
    "                                             num_workers=8)\n",
    "val_loader = torch.utils.data.DataLoader(val_fer,\n",
    "                                             batch_size=batch_size, shuffle=True,\n",
    "                                             num_workers=8)\n",
    "test_loader = torch.utils.data.DataLoader(test_fer,\n",
    "                                             batch_size=batch_size, shuffle=True,\n",
    "                                             num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    \n",
    "    def __init__(self, feature_depth, target_depth, emb_dim):\n",
    "        super(Attention, self).__init__()\n",
    "        self.emb_dim = emb_dim\n",
    "        self.iconv1 = nn.Conv2d(feature_depth, emb_dim, kernel_size=1)\n",
    "        self.iconv2 = nn.Conv2d(target_depth, emb_dim, kernel_size=1)\n",
    "        self.iconv3 = nn.Conv2d(target_depth, emb_dim, kernel_size=1)\n",
    "        self.iconv_out = nn.Conv2d(emb_dim, target_depth, kernel_size=1)\n",
    "        self.bn_out = nn.BatchNorm2d(target_depth)\n",
    "        \n",
    "        # ensure the init stage is the indentical mapping\n",
    "#         nn.init.zeros_(self.iconv_out.weight)\n",
    "#         nn.init.zeros_(self.iconv_out.bias)\n",
    "#         nn.init.zeros_(self.bn_out.weight)\n",
    "#         nn.init.zeros_(self.bn_out.bias)\n",
    "        \n",
    "    def forward(self, x1, x2):\n",
    "        x1_emb = self.iconv1(x1)\n",
    "        _x1 = nn.Flatten(-2)(x1_emb)\n",
    "        \n",
    "        x2_emb = self.iconv2(x2)\n",
    "        _x2 = nn.Flatten(-2)(x2_emb)\n",
    "        \n",
    "        x3_emb = self.iconv3(x2)\n",
    "        _x3 = nn.Flatten(-2)(x3_emb)\n",
    "        \n",
    "        QK = torch.matmul(_x1, _x2.permute(0,2,1))\n",
    "        QK = QK - QK.mean()\n",
    "        QK = QK / QK.std()\n",
    "#         QK = QK / math.sqrt(_x1.size(2))\n",
    "#         QK = nn.Softmax()(QK)\n",
    "        \n",
    "#         if self.training is False:\n",
    "#             print(QK.mean(), QK.var())\n",
    "\n",
    "        x_out = torch.matmul(QK, _x3)\n",
    "        x_out = x_out.reshape(x3_emb.size())\n",
    "        \n",
    "        x_out = self.iconv_out(x_out)\n",
    "        x_out = self.bn_out(x_out)\n",
    "        x_out = nn.LeakyReLU()(x_out)\n",
    "        \n",
    "        x_out = x_out + x2 #residual\n",
    "        \n",
    "        return x_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SVGG(nn.Module):\n",
    "    \n",
    "    def __init__(self, **kwargs):\n",
    "        super(SVGG, self).__init__()\n",
    "\n",
    "        self.device = torch.device('cpu') if not 'device' in kwargs else kwargs['device']\n",
    "\n",
    "        self.sv0 = SVblock(1, 64).to(self.device)\n",
    "        self.sv1 = SVblock(64, 128).to(self.device)\n",
    "        self.sv2 = SVblock(128, 256).to(self.device)\n",
    "        self.sv3 = SVblock(256, 512).to(self.device)\n",
    "        self.sv4 = SVblock(512, 1024).to(self.device)\n",
    "\n",
    "        self.wf0 = Attention(64, 64, emb_dim=32).to(self.device)\n",
    "        self.wf1 = Attention(128, 128, emb_dim=64).to(self.device)\n",
    "        self.wf2 = Attention(256, 256, emb_dim=128).to(self.device)\n",
    "        self.wf3 = Attention(512, 512, emb_dim=256).to(self.device)\n",
    "        self.wf4 = Attention(1024, 1024, emb_dim=512).to(self.device)\n",
    "        \n",
    "        self.iconv_out = nn.Conv2d(1024, 1024, kernel_size=1)\n",
    "        self.bn_out = nn.BatchNorm2d(1024)\n",
    "\n",
    "        self.fc0 = nn.Linear(2560, 2560)\n",
    "        self.bn0 = nn.BatchNorm1d(2560)\n",
    "        self.fc1 = nn.Linear(2560, 1024)\n",
    "        self.bn1 = nn.BatchNorm1d(1024)\n",
    "        self.fc2 = nn.Linear(1024, 7)\n",
    "        self.bn2 = nn.BatchNorm1d(7)\n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        x0 = self.sv0(x)\n",
    "        x_wf0 = self.wf0(x0, x0)\n",
    "\n",
    "        x1 = self.sv1(x_wf0)\n",
    "        x_wf1 = self.wf1(x1, x1)\n",
    "\n",
    "        x2 = self.sv2(x_wf1)\n",
    "        x_wf2 = self.wf2(x2, x2)\n",
    "\n",
    "        x3 = self.sv3(x_wf2)\n",
    "        x_wf3 = self.wf3(x3, x3)\n",
    "\n",
    "        x4 = self.sv4(x_wf3)\n",
    "        x_wf4 = self.wf4(x4, x4)\n",
    "        \n",
    "        x_wf4 = self.iconv_out(x_wf4)\n",
    "        x_wf4 = self.bn_out(x_wf4)\n",
    "\n",
    "        x_wf4 = nn.AvgPool2d(kernel_size=(x_wf4.size(-2), x_wf4.size(-1)))(x_wf4)\n",
    "        x_wf4 = nn.Flatten()(x_wf4)\n",
    "        # additional output from sv3 and sv4\n",
    "        x_sub_3 = nn.AvgPool2d(kernel_size=(x3.size(-2), x3.size(-1)))(x3)\n",
    "        x_sub_3 = nn.Flatten()(x_sub_3)\n",
    "        x_sub_4 = nn.AvgPool2d(kernel_size=(x4.size(-2), x4.size(-1)))(x4)\n",
    "        x_sub_4 = nn.Flatten()(x_sub_4)\n",
    "        \n",
    "        x = torch.cat([x_wf4, x_sub_3, x_sub_4], dim=1)\n",
    "\n",
    "        x = self.fc0(x)\n",
    "        x = self.bn0(x)\n",
    "        x = nn.LeakyReLU()(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = nn.LeakyReLU()(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.bn2(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SVGG(nn.Module):\n",
    "    \n",
    "    def __init__(self, **kwargs):\n",
    "        super(SVGG, self).__init__()\n",
    "\n",
    "        self.device = torch.device('cpu') if not 'device' in kwargs else kwargs['device']\n",
    "\n",
    "        self.sv0 = SVblock(1, 64).to(self.device)\n",
    "        self.sv1 = SVblock(64, 128).to(self.device)\n",
    "        self.sv2 = SVblock(128, 256).to(self.device)\n",
    "        self.sv3 = SVblock(256, 512).to(self.device)\n",
    "        self.sv4 = SVblock(512, 1024).to(self.device)\n",
    "\n",
    "        self.wf0 = Attention(64, 64, emb_dim=32).to(self.device)\n",
    "        self.wf1 = Attention(128, 128, emb_dim=64).to(self.device)\n",
    "        self.wf2 = Attention(256, 256, emb_dim=128).to(self.device)\n",
    "        self.wf3 = Attention(512, 512, emb_dim=256).to(self.device)\n",
    "        self.wf4 = Attention(1024, 1024, emb_dim=512).to(self.device)\n",
    "        \n",
    "        self.iconv_out = nn.Conv2d(1024, 1024, kernel_size=1)\n",
    "        self.bn_out = nn.BatchNorm2d(1024)\n",
    "\n",
    "        self.fc0 = nn.Linear(2560, 2560)\n",
    "        self.bn0 = nn.BatchNorm1d(2560)\n",
    "        self.fc1 = nn.Linear(2560, 1024)\n",
    "        self.bn1 = nn.BatchNorm1d(1024)\n",
    "        self.fc2 = nn.Linear(1024, 7)\n",
    "        self.bn2 = nn.BatchNorm1d(7)\n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        x0 = self.sv0(x)\n",
    "        x_wf0 = self.wf0(x0, x0)\n",
    "\n",
    "        x1 = self.sv1(x_wf0)\n",
    "        x_wf1 = self.wf1(x1, x1)\n",
    "\n",
    "        x2 = self.sv2(x_wf1)\n",
    "        x_wf2 = self.wf2(x2, x2)\n",
    "\n",
    "        x3 = self.sv3(x_wf2)\n",
    "        x_wf3 = self.wf3(x3, x3)\n",
    "\n",
    "        x4 = self.sv4(x_wf3)\n",
    "        x_wf4 = self.wf4(x4, x4)\n",
    "        \n",
    "        x_wf4 = self.iconv_out(x_wf4)\n",
    "        x_wf4 = self.bn_out(x_wf4)\n",
    "\n",
    "        x_wf4 = nn.AvgPool2d(kernel_size=(x_wf4.size(-2), x_wf4.size(-1)))(x_wf4)\n",
    "        x_wf4 = nn.Flatten()(x_wf4)\n",
    "        # additional output from sv3 and sv4\n",
    "        x_sub_3 = nn.AvgPool2d(kernel_size=(x3.size(-2), x3.size(-1)))(x3)\n",
    "        x_sub_3 = nn.Flatten()(x_sub_3)\n",
    "        x_sub_4 = nn.AvgPool2d(kernel_size=(x4.size(-2), x4.size(-1)))(x4)\n",
    "        x_sub_4 = nn.Flatten()(x_sub_4)\n",
    "        \n",
    "        x = torch.cat([x_wf4, x_sub_3, x_sub_4], dim=1)\n",
    "\n",
    "        x = self.fc0(x)\n",
    "        x = self.bn0(x)\n",
    "        x = nn.LeakyReLU()(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = nn.LeakyReLU()(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.bn2(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda')\n",
    "print(device)\n",
    "\n",
    "model = SVGG(device=device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "learning_rate = 0.008\n",
    "reduce_factor = 5\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transfer learning from VGG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "VGG19 = models.vgg19(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg19bn = models.vgg19_bn(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "vgg19bn_clone = copy.deepcopy(vgg19bn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (12): ReLU(inplace=True)\n",
       "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (16): ReLU(inplace=True)\n",
       "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (19): ReLU(inplace=True)\n",
       "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (22): ReLU(inplace=True)\n",
       "    (23): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (24): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (25): ReLU(inplace=True)\n",
       "    (26): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (27): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (29): ReLU(inplace=True)\n",
       "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (32): ReLU(inplace=True)\n",
       "    (33): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (34): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (35): ReLU(inplace=True)\n",
       "    (36): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (37): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (38): ReLU(inplace=True)\n",
       "    (39): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (42): ReLU(inplace=True)\n",
       "    (43): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (44): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (45): ReLU(inplace=True)\n",
       "    (46): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (47): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (48): ReLU(inplace=True)\n",
       "    (49): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (50): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (51): ReLU(inplace=True)\n",
       "    (52): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): Dropout(p=0.5, inplace=False)\n",
       "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vgg19bn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SVGG(nn.Module):\n",
    "    \n",
    "    def __init__(self, **kwargs):\n",
    "        super(SVGG, self).__init__()\n",
    "\n",
    "        self.device = torch.device('cpu') if not 'device' in kwargs else kwargs['device']\n",
    "\n",
    "        self.sv0 = vgg19bn_clone.features[:6]\n",
    "        self.sv0[0].in_channels = 1\n",
    "        self.sv0[0].weight = nn.Parameter(vgg19bn.features[0].weight.mean(1).unsqueeze(1))\n",
    "        \n",
    "        self.sv1 = vgg19bn_clone.features[7:14]\n",
    "        self.sv2 = vgg19bn_clone.features[14:27]\n",
    "        self.sv3 = vgg19bn_clone.features[27:53]\n",
    "\n",
    "        self.wf0 = Attention(64, 64, emb_dim=32).to(self.device)\n",
    "        self.wf1 = Attention(128, 128, emb_dim=64).to(self.device)\n",
    "        self.wf2 = Attention(256, 256, emb_dim=128).to(self.device)\n",
    "        self.wf3 = Attention(512, 512, emb_dim=256).to(self.device)\n",
    "        \n",
    "        self.iconv_out = nn.Conv2d(512, 512, kernel_size=1)\n",
    "        self.bn_out = nn.BatchNorm2d(512)\n",
    "\n",
    "\n",
    "        self.fc1 = nn.Linear(512, 512)\n",
    "        self.bn1 = nn.BatchNorm1d(512)\n",
    "        self.fc2 = nn.Linear(512, 7)\n",
    "        self.bn2 = nn.BatchNorm1d(7)\n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        x0 = self.sv0(x)\n",
    "        x_wf0 = self.wf0(x0, x0)\n",
    "        \n",
    "        x1 = self.sv1(x0)\n",
    "        x_wf1 = self.wf1(x1, x1)\n",
    "\n",
    "        x2 = self.sv2(x_wf1)\n",
    "        x_wf2 = self.wf2(x2, x2)\n",
    "\n",
    "        x3 = self.sv3(x_wf2)\n",
    "        x_wf3 = self.wf3(x3, x3)\n",
    "\n",
    "        x_wf3 = self.iconv_out(x_wf3)\n",
    "        x_wf3 = self.bn_out(x_wf3)\n",
    "\n",
    "        x_wf3 = nn.AvgPool2d(kernel_size=(x_wf3.size(-2), x_wf3.size(-1)))(x_wf3)\n",
    "    \n",
    "        x = nn.Flatten()(x_wf3)\n",
    "\n",
    "        x = self.fc1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = nn.LeakyReLU()(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.bn2(x)\n",
    "\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda')\n",
    "print(device)\n",
    "\n",
    "model = SVGG(device=device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "learning_rate = 0.008\n",
    "reduce_factor = 5\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1\n",
      "- Avg.loss: 1.905  | Avg.acc: 0.236\n",
      "- Avg. val_loss: 1.814  | Avg. val_acc: 0.261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:360: UserWarning: Couldn't retrieve source code for container of type SVGG. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:360: UserWarning: Couldn't retrieve source code for container of type Attention. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Update optimal model\n",
      "Epoch:  2\n",
      "- Avg.loss: 1.811  | Avg.acc: 0.255\n",
      "- Avg. val_loss: 1.805  | Avg. val_acc: 0.258\n",
      "Epoch:  3\n",
      "- Avg.loss: 1.807  | Avg.acc: 0.256\n",
      "- Avg. val_loss: 1.809  | Avg. val_acc: 0.262\n",
      "* Update optimal model\n",
      "Epoch:  4\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-b95b2287c872>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    193\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \"\"\"\n\u001b[0;32m--> 195\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = model.to(device)\n",
    "\n",
    "model_folder = '/tf/data/Quan/fer2013/backtobasics/attention_TF/'\n",
    "model_name = 'svgg_vgg19'\n",
    "model_path = os.path.join(model_folder, model_name + '.pt')\n",
    "\n",
    "best_acc = 0.0\n",
    "curloss = 0.0\n",
    "hist = []\n",
    "\n",
    "for epoch in range(300):  # loop over the dataset multiple times\n",
    "    \n",
    "    \n",
    "    \n",
    "#     if (epoch % 60) == 0 and epoch != 0:\n",
    "#         learning_rate /= reduce_factor\n",
    "#         print('Decrese learning rate to: ', learning_rate)\n",
    "#         optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
    "    \n",
    "    print('Epoch: ', epoch + 1)\n",
    "    running_loss = 0.0\n",
    "    running_acc = 0.0\n",
    "\n",
    "    # TRAIN\n",
    "    model.train()\n",
    "    for i, data in enumerate(train_loader):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "        acc = float((torch.argmax(outputs, dim=1) == labels).float().sum()/labels.size(0))\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        running_acc += acc\n",
    "#         print('\\t - Step %d: loss: %.3f acc: %.3f' % (i+1, loss.item(), acc))\n",
    "\n",
    "    print('- Avg.loss: %.3f  | Avg.acc: %.3f' % (running_loss / (i+1), running_acc / (i+1)))\n",
    "    avgloss = running_loss / (i+1)\n",
    "    avgacc = running_acc / (i+1)\n",
    "    \n",
    "    # print gradient flow figure\n",
    "    plot_grad_flow(model.named_parameters(), epoch, avgloss, avgacc,\n",
    "                   savepath=os.path.join(model_folder, model_name + '_gf' + '_' + str(epoch) + '.png'))\n",
    "\n",
    "    # EVALUATE\n",
    "    model.eval()\n",
    "    running_valloss = 0.0\n",
    "    running_valacc = 0.0\n",
    "    for i,data in enumerate(val_loader):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        acc = float((torch.argmax(outputs, dim=1) == labels).float().sum()/labels.size(0))\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        running_valloss += loss.item()\n",
    "        running_valacc += acc\n",
    "\n",
    "    print('- Avg. val_loss: %.3f  | Avg. val_acc: %.3f' % (running_valloss / (i+1), running_valacc / (i+1)))\n",
    "\n",
    "    avgvalloss = running_valloss / (i+1)\n",
    "    avgvalcc = running_valacc / (i+1)\n",
    "\n",
    "    hist.append([avgloss, avgvalloss, avgacc, avgvalcc])\n",
    "    \n",
    "    if best_acc < (running_valacc / (i+1)):\n",
    "        best_acc = (running_valacc / (i+1))\n",
    "        curloss = (running_valloss / (i+1))\n",
    "        torch.save(model, model_path)\n",
    "        print('* Update optimal model')\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(hist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Right way to custom forward on pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyResnet50(models.resnet.ResNet):\n",
    "    def __init__(self, pretrained=False):\n",
    "        # Pass default resnet50 arguments to super init\n",
    "        # https://github.com/pytorch/vision/blob/e130c6cca88160b6bf7fea9b8bc251601a1a75c5/torchvision/models/resnet.py#L260\n",
    "        super(MyResnet50, self).__init__(models.resnet.Bottleneck, [3, 4, 6, 3])\n",
    "        if pretrained:\n",
    "            self.load_state_dict(models.resnet50(pretrained=True).state_dict())\n",
    "\n",
    "    def _forward_impl(self, x):\n",
    "        # See note [TorchScript super()]\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self._forward_impl(x)\n",
    "\n",
    "\n",
    "model = MyResnet50(pretrained=True)\n",
    "x = torch.randn(2, 3, 224, 224)\n",
    "output = model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
