{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import time\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.lines import Line2D      \n",
    "\n",
    "def plot_grad_flow(named_parameters, epoch, loss, acc, savepath):\n",
    "    '''Plots the gradients flowing through different layers in the net during training.\n",
    "    Can be used for checking for possible gradient vanishing / exploding problems.\n",
    "    \n",
    "    Usage: Plug this function in Trainer class after loss.backwards() as \n",
    "    \"plot_grad_flow(self.model.named_parameters())\" to visualize the gradient flow'''\n",
    "    ave_grads = []\n",
    "    max_grads= []\n",
    "    layers = []\n",
    "    for n, p in named_parameters:\n",
    "        if(p.requires_grad) and (\"bias\" not in n):\n",
    "\n",
    "            try:\n",
    "                ave_grads.append(p.grad.abs().mean())\n",
    "                max_grads.append(p.grad.abs().max())\n",
    "                layers.append(n)\n",
    "            except:\n",
    "                continue\n",
    "#                 ave_grads.append(0.)\n",
    "#                 max_grads.append(0.)\n",
    "#                 layers.append(n)\n",
    "                \n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.bar(np.arange(len(max_grads)), max_grads, alpha=0.5, lw=1, color=\"c\")\n",
    "    plt.bar(np.arange(len(max_grads)), ave_grads, alpha=0.5, lw=1, color=\"b\")\n",
    "    plt.hlines(0, 0, len(ave_grads)+1, lw=2, color=\"k\" )\n",
    "    plt.xticks(range(0,len(ave_grads), 1), layers, rotation=\"vertical\")\n",
    "    plt.xlim(left=0, right=len(ave_grads))\n",
    "    plt.ylim(bottom = -0.001, top=0.02) # zoom in on the lower gradient regions\n",
    "    plt.xlabel(\"Layers\")\n",
    "    plt.ylabel(\"average gradient\")\n",
    "    plt.title(\"Gradient flow | Epoch \" + str(epoch) + \" | ls: \" + str(loss) + \" | ac: \" + str(acc))\n",
    "    plt.tight_layout()\n",
    "    plt.grid(True)\n",
    "    plt.legend([Line2D([0], [0], color=\"c\", lw=4),\n",
    "                Line2D([0], [0], color=\"b\", lw=4),\n",
    "                Line2D([0], [0], color=\"k\", lw=4)], ['max-gradient', 'mean-gradient', 'zero-gradient'])\n",
    "    \n",
    "    if not savepath is None:\n",
    "        plt.savefig(savepath)\n",
    "        \n",
    "    plt.close()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import transforms, datasets\n",
    "\n",
    "train_data_transform = transforms.Compose([\n",
    "        \n",
    "#         transforms.Lambda(lbp_transform),\n",
    "#         transforms.Lambda(combine_lbp_hog),\n",
    "#         transforms.ToPILImage(),\n",
    "        # transforms.RandomSizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "#         transforms.RandomVerticalFlip(),\n",
    "        transforms.RandomRotation(degrees=150),\n",
    "        transforms.Grayscale(num_output_channels=1),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,), (0.5,))\n",
    "    ])\n",
    "\n",
    "test_data_transform = transforms.Compose([\n",
    "        transforms.Grayscale(num_output_channels=1),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,), (0.5,))\n",
    "    ])\n",
    "\n",
    "train_fer = datasets.ImageFolder(root='/tf/data/Quan/fer2013/data/train', transform=train_data_transform)\n",
    "val_fer = datasets.ImageFolder(root='/tf/data/Quan/fer2013/data/val', transform=test_data_transform)\n",
    "test_fer = datasets.ImageFolder(root='/tf/data/Quan/fer2013/data/test', transform=test_data_transform)\n",
    "\n",
    "batch_size = 128\n",
    "train_loader = torch.utils.data.DataLoader(train_fer,\n",
    "                                             batch_size=batch_size, shuffle=True,\n",
    "                                             num_workers=8)\n",
    "val_loader = torch.utils.data.DataLoader(val_fer,\n",
    "                                             batch_size=batch_size, shuffle=True,\n",
    "                                             num_workers=8)\n",
    "test_loader = torch.utils.data.DataLoader(test_fer,\n",
    "                                             batch_size=batch_size, shuffle=True,\n",
    "                                             num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SVblock(nn.Module):\n",
    "    def __init__(self, in_neurons, nb_neurons, kernel_size=(3,3), batch_norm=True, activation='relu', **kwargs):\n",
    "        '''\n",
    "    in_neurons: C_in\n",
    "    nb_neurons: n_filters of conv2d\n",
    "    '''\n",
    "        super(SVblock, self).__init__()\n",
    "\n",
    "        self.index = kwargs['index'] if 'index' in kwargs else None\n",
    "        self.conv1 = nn.Conv2d(in_neurons, nb_neurons, kernel_size=kernel_size, padding=1, stride=1)\n",
    "        self.conv2 = nn.Conv2d(nb_neurons, nb_neurons, kernel_size=kernel_size, padding=1, stride=1)\n",
    "        self.conv3 = nn.Conv2d(nb_neurons, nb_neurons, kernel_size=kernel_size, padding=1, stride=1)\n",
    "        \n",
    "        self.bn1 = nn.BatchNorm2d(nb_neurons)\n",
    "        self.bn2 = nn.BatchNorm2d(nb_neurons)\n",
    "        self.bn3 = nn.BatchNorm2d(nb_neurons)\n",
    "        \n",
    "        self.preconv1 = nn.Conv2d(in_neurons, nb_neurons, kernel_size=1)\n",
    "        self.preconv2 = nn.Conv2d(nb_neurons, nb_neurons, kernel_size=1)\n",
    "        self.preconv3 = nn.Conv2d(nb_neurons, nb_neurons, kernel_size=1)\n",
    "        self.bn1_ = nn.BatchNorm2d(nb_neurons)\n",
    "        self.bn2_ = nn.BatchNorm2d(nb_neurons)\n",
    "        self.bn3_ = nn.BatchNorm2d(nb_neurons)\n",
    "        \n",
    "        self.relu = nn.LeakyReLU()\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=(2,2), stride=2)\n",
    "     \n",
    "\n",
    "\n",
    "    def forward(self, x):        \n",
    "        \n",
    "        x0_res = self.preconv1(x)\n",
    "        x0_res = self.bn1_(x0_res)\n",
    "        \n",
    "        # 1st\n",
    "        x1 = self.conv1(x)\n",
    "        x1 = self.bn1(x1)\n",
    "        x1 = self.relu(x1)\n",
    "        \n",
    "        x1 = x1 + x0_res\n",
    "        x1_res = self.preconv2(x1)\n",
    "        x1_res = self.bn2_(x1_res)\n",
    "\n",
    "        # 2nd\n",
    "        x2 = self.conv2(x1)\n",
    "        x2 = self.bn2(x2)\n",
    "        x2 = self.relu(x2)\n",
    "        \n",
    "        x2 = x2 + x1_res\n",
    "        x2_res = self.preconv3(x2)\n",
    "        x2_res = self.bn3_(x2_res)\n",
    "        \n",
    "        # 3rd\n",
    "        x3 = self.conv3(x2)\n",
    "        x3 = self.bn3(x3)\n",
    "        x3 = self.relu(x3)\n",
    "        \n",
    "        x3 = x3 + x2_res\n",
    "\n",
    "        # maxpooling\n",
    "        x_out = self.maxpool(x3)\n",
    "\n",
    "        return x_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    \n",
    "    def __init__(self, feature_depth, target_depth, emb_dim):\n",
    "        super(Attention, self).__init__()\n",
    "        self.emb_dim = emb_dim\n",
    "        self.sub_conv1 = nn.Conv2d(feature_depth, feature_depth, kernel_size=2, padding=0, stride=2)\n",
    "        self.iconv1 = nn.Conv2d(feature_depth, emb_dim, kernel_size=1)\n",
    "        self.iconv2 = nn.Conv2d(target_depth, emb_dim, kernel_size=1)\n",
    "        \n",
    "        self.iconv_in_1 = nn.Conv2d(feature_depth, emb_dim, kernel_size=1)\n",
    "        self.iconv_in_2 = nn.Conv2d(target_depth, emb_dim, kernel_size=1)\n",
    "        \n",
    "        self.iconv_out = nn.Conv2d(2*emb_dim, target_depth, kernel_size=1)\n",
    "        self.bn_out = nn.BatchNorm2d(target_depth)\n",
    "        \n",
    "        \n",
    "    def forward(self, x1, x2):\n",
    "        x1_sampling = self.sub_conv1(x1)\n",
    "        x1_emb = self.iconv1(x1_sampling)\n",
    "        _x1 = nn.Flatten(-2)(x1_emb)\n",
    "        \n",
    "        x2_emb = self.iconv2(x2)\n",
    "        _x2 = nn.Flatten(-2)(x2_emb)\n",
    "        \n",
    "        in_x2_emb = self.iconv_in_2(x2)\n",
    "        _in_x2 = nn.Flatten(-2)(in_x2_emb)\n",
    "        \n",
    "        in_x1_emb = self.iconv_in_1(x1_sampling)\n",
    "        _in_x1 = nn.Flatten(-2)(in_x1_emb)\n",
    "\n",
    "        QK = torch.matmul(_x1, _x2.permute(0,2,1))\n",
    "        QK = QK / math.sqrt(_x1.size(2))\n",
    "\n",
    "        x_out_2 = torch.matmul(QK, _in_x2)\n",
    "        x_out_2 = x_out_2.reshape(in_x2_emb.size())\n",
    "        \n",
    "        x_out_1 = torch.matmul(QK.permute(0,2,1), _in_x1)\n",
    "        x_out_1 = x_out_1.reshape(in_x1_emb.size())\n",
    "\n",
    "        x_out = torch.cat([x_out_2, x_out_1], dim=1)\n",
    "        x_out = self.iconv_out(x_out)\n",
    "        x_out = self.bn_out(x_out)\n",
    "        x_out = nn.LeakyReLU()(x_out)\n",
    "        \n",
    "        return x_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SVGG(nn.Module):\n",
    "    \n",
    "    def __init__(self, **kwargs):\n",
    "        super(SVGG, self).__init__()\n",
    "\n",
    "        self.device = torch.device('cpu') if not 'device' in kwargs else kwargs['device']\n",
    "\n",
    "        self.sv0 = SVblock(1, 64).to(self.device)\n",
    "        self.sv1 = SVblock(64, 128).to(self.device)\n",
    "        self.sv2 = SVblock(128, 256).to(self.device)\n",
    "        self.sv3 = SVblock(256, 512).to(self.device)\n",
    "        self.sv4 = SVblock(512, 1024).to(self.device)\n",
    "\n",
    "#         self.wf0 = Attention(1, 64, emb_dim=32).to(self.device)\n",
    "        self.wf1 = Attention(64, 128, emb_dim=64).to(self.device)\n",
    "        self.wf2 = Attention(128, 256, emb_dim=128).to(self.device)\n",
    "        self.wf3 = Attention(256, 512, emb_dim=256).to(self.device)\n",
    "        self.wf4 = Attention(512, 1024, emb_dim=512).to(self.device)\n",
    "        \n",
    "        self.iconv_out = nn.Conv2d(1024, 1024, kernel_size=1)\n",
    "        self.bn_out = nn.BatchNorm2d(1024)\n",
    "\n",
    "        self.fc0 = nn.Linear(2560, 2560)\n",
    "        self.bn0 = nn.BatchNorm1d(2560)\n",
    "        self.fc1 = nn.Linear(2560, 1024)\n",
    "        self.bn1 = nn.BatchNorm1d(1024)\n",
    "        self.fc2 = nn.Linear(1024, 7)\n",
    "        self.bn2 = nn.BatchNorm1d(7)\n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        x0 = self.sv0(x)\n",
    "#         x_wf0 = self.wf0(x, x0)\n",
    "\n",
    "        x1 = self.sv1(x0)\n",
    "        x_wf1 = self.wf1(x0, x1)\n",
    "\n",
    "        x2 = self.sv2(x_wf1)\n",
    "        x_wf2 = self.wf2(x1, x2)\n",
    "\n",
    "        x3 = self.sv3(x_wf2)\n",
    "        x_wf3 = self.wf3(x2, x3)\n",
    "\n",
    "        x4 = self.sv4(x_wf3)\n",
    "        x_wf4 = self.wf4(x3, x4)\n",
    "        \n",
    "        x_wf4 = self.iconv_out(x_wf4)\n",
    "        x_wf4 = self.bn_out(x_wf4)\n",
    "\n",
    "        x_wf4 = nn.AvgPool2d(kernel_size=(x_wf4.size(-2), x_wf4.size(-1)))(x_wf4)\n",
    "        x_wf4 = nn.Flatten()(x_wf4)\n",
    "        # additional output from sv3 and sv4\n",
    "        x_sub_3 = nn.AvgPool2d(kernel_size=(x3.size(-2), x3.size(-1)))(x3)\n",
    "        x_sub_3 = nn.Flatten()(x_sub_3)\n",
    "        x_sub_4 = nn.AvgPool2d(kernel_size=(x4.size(-2), x4.size(-1)))(x4)\n",
    "        x_sub_4 = nn.Flatten()(x_sub_4)\n",
    "        \n",
    "        x = torch.cat([x_wf4, x_sub_3, x_sub_4], dim=1)\n",
    "\n",
    "        x = self.fc0(x)\n",
    "        x = self.bn0(x)\n",
    "        x = nn.LeakyReLU()(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = nn.LeakyReLU()(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.bn2(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda')\n",
    "print(device)\n",
    "\n",
    "model = SVGG(device=device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "learning_rate = 0.01\n",
    "reduce_factor = 10\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1\n",
      "- Avg.loss: 1.851  | Avg.acc: 0.243\n",
      "- Avg. val_loss: 1.803  | Avg. val_acc: 0.254\n",
      "* Update optimal model\n",
      "Epoch:  2\n",
      "- Avg.loss: 1.793  | Avg.acc: 0.252\n",
      "- Avg. val_loss: 1.849  | Avg. val_acc: 0.256\n",
      "* Update optimal model\n",
      "Epoch:  3\n",
      "- Avg.loss: 1.783  | Avg.acc: 0.253\n",
      "- Avg. val_loss: 1.849  | Avg. val_acc: 0.263\n",
      "* Update optimal model\n",
      "Epoch:  4\n",
      "- Avg.loss: 1.779  | Avg.acc: 0.255\n",
      "- Avg. val_loss: 20.595  | Avg. val_acc: 0.253\n",
      "Epoch:  5\n",
      "- Avg.loss: 1.776  | Avg.acc: 0.258\n",
      "- Avg. val_loss: 1.921  | Avg. val_acc: 0.265\n",
      "* Update optimal model\n",
      "Epoch:  6\n",
      "- Avg.loss: 1.773  | Avg.acc: 0.261\n",
      "- Avg. val_loss: 1.809  | Avg. val_acc: 0.244\n",
      "Epoch:  7\n",
      "- Avg.loss: 1.767  | Avg.acc: 0.267\n",
      "- Avg. val_loss: 1.796  | Avg. val_acc: 0.259\n",
      "Epoch:  8\n",
      "- Avg.loss: 1.749  | Avg.acc: 0.280\n",
      "- Avg. val_loss: 1.809  | Avg. val_acc: 0.262\n",
      "Epoch:  9\n",
      "- Avg.loss: 1.729  | Avg.acc: 0.292\n",
      "- Avg. val_loss: 1.753  | Avg. val_acc: 0.275\n",
      "* Update optimal model\n",
      "Epoch:  10\n",
      "- Avg.loss: 1.709  | Avg.acc: 0.303\n",
      "- Avg. val_loss: 1.770  | Avg. val_acc: 0.253\n",
      "Epoch:  11\n",
      "- Avg.loss: 1.690  | Avg.acc: 0.315\n",
      "- Avg. val_loss: 1.786  | Avg. val_acc: 0.282\n",
      "* Update optimal model\n",
      "Epoch:  12\n",
      "- Avg.loss: 1.677  | Avg.acc: 0.319\n",
      "- Avg. val_loss: 1.678  | Avg. val_acc: 0.316\n",
      "* Update optimal model\n",
      "Epoch:  13\n",
      "- Avg.loss: 1.670  | Avg.acc: 0.327\n",
      "- Avg. val_loss: 1.738  | Avg. val_acc: 0.310\n",
      "Epoch:  14\n",
      "- Avg.loss: 1.661  | Avg.acc: 0.331\n",
      "- Avg. val_loss: 1.751  | Avg. val_acc: 0.318\n",
      "* Update optimal model\n",
      "Epoch:  15\n",
      "- Avg.loss: 1.630  | Avg.acc: 0.352\n",
      "- Avg. val_loss: 1.681  | Avg. val_acc: 0.342\n",
      "* Update optimal model\n",
      "Epoch:  16\n",
      "- Avg.loss: 1.618  | Avg.acc: 0.355\n",
      "- Avg. val_loss: 1.692  | Avg. val_acc: 0.320\n",
      "Epoch:  17\n",
      "- Avg.loss: 1.602  | Avg.acc: 0.366\n",
      "- Avg. val_loss: 2.170  | Avg. val_acc: 0.273\n",
      "Epoch:  18\n",
      "- Avg.loss: 1.584  | Avg.acc: 0.376\n",
      "- Avg. val_loss: 1.843  | Avg. val_acc: 0.246\n",
      "Epoch:  19\n",
      "- Avg.loss: 1.568  | Avg.acc: 0.384\n",
      "- Avg. val_loss: 1.717  | Avg. val_acc: 0.345\n",
      "* Update optimal model\n",
      "Epoch:  20\n",
      "- Avg.loss: 1.546  | Avg.acc: 0.396\n",
      "- Avg. val_loss: 1.693  | Avg. val_acc: 0.288\n",
      "Epoch:  21\n",
      "- Avg.loss: 1.538  | Avg.acc: 0.398\n",
      "- Avg. val_loss: 1.699  | Avg. val_acc: 0.294\n",
      "Epoch:  22\n",
      "- Avg.loss: 1.523  | Avg.acc: 0.407\n",
      "- Avg. val_loss: 1.567  | Avg. val_acc: 0.378\n",
      "* Update optimal model\n",
      "Epoch:  23\n",
      "- Avg.loss: 1.519  | Avg.acc: 0.410\n",
      "- Avg. val_loss: 1.713  | Avg. val_acc: 0.283\n",
      "Epoch:  24\n",
      "- Avg.loss: 1.506  | Avg.acc: 0.416\n",
      "- Avg. val_loss: 1.648  | Avg. val_acc: 0.366\n",
      "Epoch:  25\n",
      "- Avg.loss: 1.497  | Avg.acc: 0.420\n",
      "- Avg. val_loss: 1.539  | Avg. val_acc: 0.387\n",
      "* Update optimal model\n",
      "Epoch:  26\n",
      "- Avg.loss: 1.489  | Avg.acc: 0.422\n",
      "- Avg. val_loss: 1.573  | Avg. val_acc: 0.380\n",
      "Epoch:  27\n",
      "- Avg.loss: 1.483  | Avg.acc: 0.426\n",
      "- Avg. val_loss: 1.894  | Avg. val_acc: 0.305\n",
      "Epoch:  28\n",
      "- Avg.loss: 1.474  | Avg.acc: 0.427\n",
      "- Avg. val_loss: 1.754  | Avg. val_acc: 0.261\n",
      "Epoch:  29\n",
      "- Avg.loss: 1.469  | Avg.acc: 0.431\n",
      "- Avg. val_loss: 1.731  | Avg. val_acc: 0.305\n",
      "Epoch:  30\n",
      "- Avg.loss: 1.460  | Avg.acc: 0.433\n",
      "- Avg. val_loss: 1.563  | Avg. val_acc: 0.366\n",
      "Decrese learning rate to:  0.001\n",
      "Epoch:  31\n",
      "- Avg.loss: 1.396  | Avg.acc: 0.463\n",
      "- Avg. val_loss: 1.373  | Avg. val_acc: 0.470\n",
      "* Update optimal model\n",
      "Epoch:  32\n",
      "- Avg.loss: 1.374  | Avg.acc: 0.472\n",
      "- Avg. val_loss: 1.348  | Avg. val_acc: 0.481\n",
      "* Update optimal model\n",
      "Epoch:  33\n",
      "- Avg.loss: 1.357  | Avg.acc: 0.478\n",
      "- Avg. val_loss: 1.368  | Avg. val_acc: 0.474\n",
      "Epoch:  34\n",
      "- Avg.loss: 1.343  | Avg.acc: 0.484\n",
      "- Avg. val_loss: 1.342  | Avg. val_acc: 0.479\n",
      "Epoch:  35\n",
      "- Avg.loss: 1.337  | Avg.acc: 0.482\n",
      "- Avg. val_loss: 1.349  | Avg. val_acc: 0.478\n",
      "Epoch:  36\n",
      "- Avg.loss: 1.324  | Avg.acc: 0.493\n",
      "- Avg. val_loss: 1.355  | Avg. val_acc: 0.471\n",
      "Epoch:  37\n",
      "- Avg.loss: 1.315  | Avg.acc: 0.494\n",
      "- Avg. val_loss: 1.413  | Avg. val_acc: 0.468\n",
      "Epoch:  38\n",
      "- Avg.loss: 1.305  | Avg.acc: 0.502\n",
      "- Avg. val_loss: 1.406  | Avg. val_acc: 0.460\n",
      "Epoch:  39\n",
      "- Avg.loss: 1.293  | Avg.acc: 0.503\n",
      "- Avg. val_loss: 1.355  | Avg. val_acc: 0.473\n",
      "Epoch:  40\n",
      "- Avg.loss: 1.290  | Avg.acc: 0.504\n",
      "- Avg. val_loss: 1.283  | Avg. val_acc: 0.503\n",
      "* Update optimal model\n",
      "Epoch:  41\n",
      "- Avg.loss: 1.282  | Avg.acc: 0.507\n",
      "- Avg. val_loss: 1.315  | Avg. val_acc: 0.500\n",
      "Epoch:  42\n",
      "- Avg.loss: 1.270  | Avg.acc: 0.513\n",
      "- Avg. val_loss: 1.381  | Avg. val_acc: 0.475\n",
      "Epoch:  43\n",
      "- Avg.loss: 1.265  | Avg.acc: 0.513\n",
      "- Avg. val_loss: 1.328  | Avg. val_acc: 0.493\n",
      "Epoch:  44\n",
      "- Avg.loss: 1.253  | Avg.acc: 0.519\n",
      "- Avg. val_loss: 1.402  | Avg. val_acc: 0.448\n",
      "Epoch:  45\n",
      "- Avg.loss: 1.255  | Avg.acc: 0.516\n",
      "- Avg. val_loss: 1.290  | Avg. val_acc: 0.497\n",
      "Epoch:  46\n",
      "- Avg.loss: 1.237  | Avg.acc: 0.527\n",
      "- Avg. val_loss: 1.308  | Avg. val_acc: 0.487\n",
      "Epoch:  47\n",
      "- Avg.loss: 1.240  | Avg.acc: 0.525\n",
      "- Avg. val_loss: 1.424  | Avg. val_acc: 0.457\n",
      "Epoch:  48\n",
      "- Avg.loss: 1.229  | Avg.acc: 0.528\n",
      "- Avg. val_loss: 1.353  | Avg. val_acc: 0.490\n",
      "Epoch:  49\n",
      "- Avg.loss: 1.222  | Avg.acc: 0.531\n",
      "- Avg. val_loss: 1.281  | Avg. val_acc: 0.492\n",
      "Epoch:  50\n",
      "- Avg.loss: 1.221  | Avg.acc: 0.529\n",
      "- Avg. val_loss: 1.545  | Avg. val_acc: 0.398\n",
      "Epoch:  51\n",
      "- Avg.loss: 1.211  | Avg.acc: 0.537\n",
      "- Avg. val_loss: 1.233  | Avg. val_acc: 0.535\n",
      "* Update optimal model\n",
      "Epoch:  52\n",
      "- Avg.loss: 1.206  | Avg.acc: 0.542\n",
      "- Avg. val_loss: 1.346  | Avg. val_acc: 0.501\n",
      "Epoch:  53\n",
      "- Avg.loss: 1.201  | Avg.acc: 0.543\n",
      "- Avg. val_loss: 1.261  | Avg. val_acc: 0.509\n",
      "Epoch:  54\n",
      "- Avg.loss: 1.198  | Avg.acc: 0.543\n",
      "- Avg. val_loss: 1.197  | Avg. val_acc: 0.539\n",
      "* Update optimal model\n",
      "Epoch:  55\n",
      "- Avg.loss: 1.194  | Avg.acc: 0.541\n",
      "- Avg. val_loss: 1.297  | Avg. val_acc: 0.508\n",
      "Epoch:  56\n",
      "- Avg.loss: 1.188  | Avg.acc: 0.549\n",
      "- Avg. val_loss: 1.263  | Avg. val_acc: 0.530\n",
      "Epoch:  57\n",
      "- Avg.loss: 1.183  | Avg.acc: 0.546\n",
      "- Avg. val_loss: 1.224  | Avg. val_acc: 0.538\n",
      "Epoch:  58\n",
      "- Avg.loss: 1.178  | Avg.acc: 0.549\n",
      "- Avg. val_loss: 1.163  | Avg. val_acc: 0.548\n",
      "* Update optimal model\n",
      "Epoch:  59\n",
      "- Avg.loss: 1.177  | Avg.acc: 0.553\n",
      "- Avg. val_loss: 1.234  | Avg. val_acc: 0.525\n",
      "Epoch:  60\n",
      "- Avg.loss: 1.171  | Avg.acc: 0.552\n",
      "- Avg. val_loss: 1.243  | Avg. val_acc: 0.537\n",
      "Decrese learning rate to:  0.0001\n",
      "Epoch:  61\n",
      "- Avg.loss: 1.127  | Avg.acc: 0.572\n",
      "- Avg. val_loss: 1.158  | Avg. val_acc: 0.567\n",
      "* Update optimal model\n",
      "Epoch:  62\n",
      "- Avg.loss: 1.112  | Avg.acc: 0.579\n",
      "- Avg. val_loss: 1.123  | Avg. val_acc: 0.567\n",
      "* Update optimal model\n",
      "Epoch:  63\n",
      "- Avg.loss: 1.103  | Avg.acc: 0.584\n",
      "- Avg. val_loss: 1.150  | Avg. val_acc: 0.564\n",
      "Epoch:  64\n",
      "- Avg.loss: 1.099  | Avg.acc: 0.582\n",
      "- Avg. val_loss: 1.126  | Avg. val_acc: 0.566\n",
      "Epoch:  65\n",
      "- Avg.loss: 1.096  | Avg.acc: 0.586\n",
      "- Avg. val_loss: 1.142  | Avg. val_acc: 0.556\n",
      "Epoch:  66\n",
      "- Avg.loss: 1.093  | Avg.acc: 0.585\n",
      "- Avg. val_loss: 1.131  | Avg. val_acc: 0.569\n",
      "* Update optimal model\n",
      "Epoch:  67\n",
      "- Avg.loss: 1.088  | Avg.acc: 0.591\n",
      "- Avg. val_loss: 1.117  | Avg. val_acc: 0.572\n",
      "* Update optimal model\n",
      "Epoch:  68\n",
      "- Avg.loss: 1.088  | Avg.acc: 0.588\n",
      "- Avg. val_loss: 1.131  | Avg. val_acc: 0.569\n",
      "Epoch:  69\n",
      "- Avg.loss: 1.083  | Avg.acc: 0.588\n",
      "- Avg. val_loss: 1.110  | Avg. val_acc: 0.572\n",
      "* Update optimal model\n",
      "Epoch:  70\n",
      "- Avg.loss: 1.084  | Avg.acc: 0.589\n",
      "- Avg. val_loss: 1.151  | Avg. val_acc: 0.568\n",
      "Epoch:  71\n",
      "- Avg.loss: 1.078  | Avg.acc: 0.591\n",
      "- Avg. val_loss: 1.116  | Avg. val_acc: 0.572\n",
      "Epoch:  72\n",
      "- Avg.loss: 1.073  | Avg.acc: 0.594\n",
      "- Avg. val_loss: 1.115  | Avg. val_acc: 0.571\n",
      "Epoch:  73\n",
      "- Avg.loss: 1.076  | Avg.acc: 0.594\n",
      "- Avg. val_loss: 1.119  | Avg. val_acc: 0.577\n",
      "* Update optimal model\n",
      "Epoch:  74\n",
      "- Avg.loss: 1.070  | Avg.acc: 0.594\n",
      "- Avg. val_loss: 1.113  | Avg. val_acc: 0.579\n",
      "* Update optimal model\n",
      "Epoch:  75\n",
      "- Avg.loss: 1.073  | Avg.acc: 0.594\n",
      "- Avg. val_loss: 1.100  | Avg. val_acc: 0.589\n",
      "* Update optimal model\n",
      "Epoch:  76\n",
      "- Avg.loss: 1.069  | Avg.acc: 0.593\n",
      "- Avg. val_loss: 1.134  | Avg. val_acc: 0.571\n",
      "Epoch:  77\n",
      "- Avg.loss: 1.065  | Avg.acc: 0.597\n",
      "- Avg. val_loss: 1.125  | Avg. val_acc: 0.568\n",
      "Epoch:  78\n",
      "- Avg.loss: 1.066  | Avg.acc: 0.595\n",
      "- Avg. val_loss: 1.133  | Avg. val_acc: 0.567\n",
      "Epoch:  79\n",
      "- Avg.loss: 1.063  | Avg.acc: 0.597\n",
      "- Avg. val_loss: 1.110  | Avg. val_acc: 0.576\n",
      "Epoch:  80\n",
      "- Avg.loss: 1.064  | Avg.acc: 0.597\n",
      "- Avg. val_loss: 1.123  | Avg. val_acc: 0.570\n",
      "Epoch:  81\n",
      "- Avg.loss: 1.060  | Avg.acc: 0.598\n",
      "- Avg. val_loss: 1.113  | Avg. val_acc: 0.571\n",
      "Epoch:  82\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Avg.loss: 1.055  | Avg.acc: 0.600\n",
      "- Avg. val_loss: 1.094  | Avg. val_acc: 0.588\n",
      "Epoch:  83\n",
      "- Avg.loss: 1.056  | Avg.acc: 0.601\n",
      "- Avg. val_loss: 1.121  | Avg. val_acc: 0.576\n",
      "Epoch:  84\n",
      "- Avg.loss: 1.053  | Avg.acc: 0.602\n",
      "- Avg. val_loss: 1.085  | Avg. val_acc: 0.591\n",
      "* Update optimal model\n",
      "Epoch:  85\n",
      "- Avg.loss: 1.057  | Avg.acc: 0.599\n",
      "- Avg. val_loss: 1.112  | Avg. val_acc: 0.578\n",
      "Epoch:  86\n",
      "- Avg.loss: 1.051  | Avg.acc: 0.600\n",
      "- Avg. val_loss: 1.099  | Avg. val_acc: 0.589\n",
      "Epoch:  87\n",
      "- Avg.loss: 1.050  | Avg.acc: 0.604\n",
      "- Avg. val_loss: 1.096  | Avg. val_acc: 0.587\n",
      "Epoch:  88\n",
      "- Avg.loss: 1.050  | Avg.acc: 0.605\n",
      "- Avg. val_loss: 1.107  | Avg. val_acc: 0.590\n",
      "Epoch:  89\n",
      "- Avg.loss: 1.047  | Avg.acc: 0.603\n",
      "- Avg. val_loss: 1.122  | Avg. val_acc: 0.577\n",
      "Epoch:  90\n",
      "- Avg.loss: 1.048  | Avg.acc: 0.603\n",
      "- Avg. val_loss: 1.119  | Avg. val_acc: 0.589\n",
      "Decrese learning rate to:  1e-05\n",
      "Epoch:  91\n",
      "- Avg.loss: 1.036  | Avg.acc: 0.610\n",
      "- Avg. val_loss: 1.092  | Avg. val_acc: 0.588\n",
      "Epoch:  92\n",
      "- Avg.loss: 1.035  | Avg.acc: 0.606\n",
      "- Avg. val_loss: 1.106  | Avg. val_acc: 0.582\n",
      "Epoch:  93\n",
      "- Avg.loss: 1.033  | Avg.acc: 0.610\n",
      "- Avg. val_loss: 1.124  | Avg. val_acc: 0.586\n",
      "Epoch:  94\n",
      "- Avg.loss: 1.036  | Avg.acc: 0.608\n",
      "- Avg. val_loss: 1.087  | Avg. val_acc: 0.591\n",
      "* Update optimal model\n",
      "Epoch:  95\n",
      "- Avg.loss: 1.031  | Avg.acc: 0.611\n",
      "- Avg. val_loss: 1.104  | Avg. val_acc: 0.576\n",
      "Epoch:  96\n",
      "- Avg.loss: 1.034  | Avg.acc: 0.610\n",
      "- Avg. val_loss: 1.098  | Avg. val_acc: 0.582\n",
      "Epoch:  97\n",
      "- Avg.loss: 1.032  | Avg.acc: 0.609\n",
      "- Avg. val_loss: 1.100  | Avg. val_acc: 0.584\n",
      "Epoch:  98\n",
      "- Avg.loss: 1.033  | Avg.acc: 0.610\n",
      "- Avg. val_loss: 1.090  | Avg. val_acc: 0.582\n",
      "Epoch:  99\n",
      "- Avg.loss: 1.032  | Avg.acc: 0.611\n",
      "- Avg. val_loss: 1.140  | Avg. val_acc: 0.578\n",
      "Epoch:  100\n",
      "- Avg.loss: 1.033  | Avg.acc: 0.608\n",
      "- Avg. val_loss: 1.094  | Avg. val_acc: 0.588\n",
      "Epoch:  101\n",
      "- Avg.loss: 1.033  | Avg.acc: 0.608\n",
      "- Avg. val_loss: 1.097  | Avg. val_acc: 0.574\n",
      "Epoch:  102\n",
      "- Avg.loss: 1.033  | Avg.acc: 0.611\n",
      "- Avg. val_loss: 1.098  | Avg. val_acc: 0.574\n",
      "Epoch:  103\n",
      "- Avg.loss: 1.032  | Avg.acc: 0.611\n",
      "- Avg. val_loss: 1.091  | Avg. val_acc: 0.583\n",
      "Epoch:  104\n",
      "- Avg.loss: 1.033  | Avg.acc: 0.609\n",
      "- Avg. val_loss: 1.108  | Avg. val_acc: 0.583\n",
      "Epoch:  105\n",
      "- Avg.loss: 1.030  | Avg.acc: 0.610\n",
      "- Avg. val_loss: 1.107  | Avg. val_acc: 0.585\n",
      "Epoch:  106\n",
      "- Avg.loss: 1.029  | Avg.acc: 0.609\n",
      "- Avg. val_loss: 1.089  | Avg. val_acc: 0.587\n",
      "Epoch:  107\n",
      "- Avg.loss: 1.027  | Avg.acc: 0.612\n",
      "- Avg. val_loss: 1.111  | Avg. val_acc: 0.578\n",
      "Epoch:  108\n",
      "- Avg.loss: 1.028  | Avg.acc: 0.613\n",
      "- Avg. val_loss: 1.102  | Avg. val_acc: 0.585\n",
      "Epoch:  109\n",
      "- Avg.loss: 1.031  | Avg.acc: 0.609\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 128.00 MiB (GPU 0; 7.79 GiB total capacity; 5.39 GiB already allocated; 108.69 MiB free; 5.96 GiB reserved in total by PyTorch)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-126692b0178f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m         \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-520949e9438d>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mx4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msv4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_wf3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0mx_wf4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwf4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mx_wf4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miconv_out\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_wf4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-f38e03819ee5>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x1, x2)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mQK\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_x1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_x2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0mQK\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mQK\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_x1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mx_out_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mQK\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_in_x2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 128.00 MiB (GPU 0; 7.79 GiB total capacity; 5.39 GiB already allocated; 108.69 MiB free; 5.96 GiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "model = model.to(device)\n",
    "\n",
    "model_folder = '/tf/data/Quan/fer2013/backtobasics/attention_v2/'\n",
    "model_name = 'svgg_resnet'\n",
    "model_path = os.path.join(model_folder, model_name + '.pt')\n",
    "\n",
    "best_acc = 0.0\n",
    "curloss = 0.0\n",
    "hist = []\n",
    "\n",
    "for epoch in range(350):  # loop over the dataset multiple times\n",
    "    \n",
    "    \n",
    "    \n",
    "    if (epoch % 30) == 0 and epoch != 0 and learning_rate > 1e-6:\n",
    "        learning_rate /= reduce_factor\n",
    "        print('Decrese learning rate to: ', learning_rate)\n",
    "        optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
    "    \n",
    "    print('Epoch: ', epoch + 1)\n",
    "    running_loss = 0.0\n",
    "    running_acc = 0.0\n",
    "\n",
    "    # TRAIN\n",
    "    model.train()\n",
    "    for i, data in enumerate(train_loader):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "        acc = float((torch.argmax(outputs, dim=1) == labels).float().sum()/labels.size(0))\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        running_acc += acc\n",
    "#         print('\\t - Step %d: loss: %.3f acc: %.3f' % (i+1, loss.item(), acc))\n",
    "\n",
    "    print('- Avg.loss: %.3f  | Avg.acc: %.3f' % (running_loss / (i+1), running_acc / (i+1)))\n",
    "    avgloss = running_loss / (i+1)\n",
    "    avgacc = running_acc / (i+1)\n",
    "    \n",
    "    # print gradient flow figure\n",
    "    plot_grad_flow(model.named_parameters(), epoch, avgloss, avgacc,\n",
    "                   savepath=os.path.join(model_folder, model_name + '_gf' + '_' + str(epoch) + '.png'))\n",
    "\n",
    "    # EVALUATE\n",
    "    model.eval()\n",
    "    running_valloss = 0.0\n",
    "    running_valacc = 0.0\n",
    "    for i,data in enumerate(val_loader):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        acc = float((torch.argmax(outputs, dim=1) == labels).float().sum()/labels.size(0))\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        running_valloss += loss.item()\n",
    "        running_valacc += acc\n",
    "\n",
    "    print('- Avg. val_loss: %.3f  | Avg. val_acc: %.3f' % (running_valloss / (i+1), running_valacc / (i+1)))\n",
    "\n",
    "    avgvalloss = running_valloss / (i+1)\n",
    "    avgvalcc = running_valacc / (i+1)\n",
    "\n",
    "    hist.append([avgloss, avgvalloss, avgacc, avgvalcc])\n",
    "    \n",
    "    if best_acc < (running_valacc / (i+1)):\n",
    "        best_acc = (running_valacc / (i+1))\n",
    "        curloss = (running_valloss / (i+1))\n",
    "        torch.save(model, model_path)\n",
    "        print('* Update optimal model')\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([<matplotlib.lines.Line2D at 0x7f9c07c48080>,\n",
       "  <matplotlib.lines.Line2D at 0x7f9c07c48208>,\n",
       "  <matplotlib.lines.Line2D at 0x7f9c07c48358>,\n",
       "  <matplotlib.lines.Line2D at 0x7f9c07c484a8>],\n",
       " 0.5911637935145148,\n",
       " 1.0871883281346024)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(hist[5:]), best_acc, curloss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio\n",
    "images = []\n",
    "for i in range(109):\n",
    "    images.append(imageio.imread('/tf/data/Quan/fer2013/backtobasics/attention_v2/svgg_resnet_gf_' + str(i) + '.png'))\n",
    "imageio.mimsave('/tf/data/Quan/fer2013/backtobasics/attention_v2/svgg_resnet_gf.gif', images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
